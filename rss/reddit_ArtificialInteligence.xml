<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、人工智能在商业中的应用、人工智能如何影响我们的生活、未来可能会发生什么，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sun, 23 Jul 2023 12:29:16 GMT</lastBuildDate>
    <item>
      <title>谁可以帮助我将我的高级 ChatGPT 连接到互联网并连接插件？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/157dk1n/anyone_who_can_assist_me_in_connecting_my_premium/</link>
      <description><![CDATA[所以我对 ChatGPT 感到惊讶，并注册了付费 ChatGPT-4 版本。然而，我确实觉得有点受限，因为只能访问 2021 年之前的数据。我知道有一些方法可以将其连接到互联网以及添加某些插件来增强体验，但我无法从 google 找到任何指南或教程......我使用 Apple iPhone 来运行应用程序，使用 MacBook Pro 笔记本电脑来浏览网页   由   提交 /u/Kennyg39   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/157dk1n/anyone_who_can_assist_me_in_connecting_my_premium/</guid>
      <pubDate>Sun, 23 Jul 2023 12:25:55 GMT</pubDate>
    </item>
    <item>
      <title>在 GitHub 上开发 ACE 模型 Python 实现 - 你们觉得怎么样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/157ayn8/working_on_an_ace_model_python_implementation_on/</link>
      <description><![CDATA[所以，我一直在熬夜研究 Dave Shapiro 的自主认知实体 (ACE) 模型的 Python 实现。希望通过使用多态性，使 AI 能够动态地创建新的资源、功能和产品，打造一个像体操运动员一样灵活、像变色龙一样适应性强的 AI 系统。 /master 我把它扔在那里是因为我渴望听到你的想法。如果您愿意，总是有空间让您参与并做出贡献 - 您知道，如果您喜欢与认知层基类搏斗或对用户友好的界面有一些好主意。但绝对没有义务。请随意浏览并让我知道您的想法。   由   提交 /u/Si1Fei1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/157ayn8/working_on_an_ace_model_python_implementation_on/</guid>
      <pubDate>Sun, 23 Jul 2023 10:07:56 GMT</pubDate>
    </item>
    <item>
      <title>AI 每周摘要（7 月 15 日至 7 月 21 日）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/157ak06/ai_weekly_rundown_july_15_to_july_21/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/157ak06/ai_weekly_rundown_july_15_to_july_21/</guid>
      <pubDate>Sun, 23 Jul 2023 09:45:28 GMT</pubDate>
    </item>
    <item>
      <title>NAMSI：解决对齐问题的一种有前途的方法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1576ogj/namsi_a_promising_approach_to_solving_the/</link>
      <description><![CDATA[媒体驱动的对人工智能造成包括人类灭绝在内的重大破坏的恐惧，其基础是担心我们在达到 AGI 之前无法解决对齐问题，而当我们达到 ASI 时，威胁将变得更加险恶。人工智能开发人员尚未充分认识到，一致性问题从根本上来说是一个道德问题。  这就是专门致力于通过更好地理解道德来解决一致性问题的狭义人工智能系统的开发前景广阔的地方。我们人类可能没有解决一致性问题的智能，但如果我们创造出致力于理解和推进解决这一挑战所需的道德的狭义人工智能，我们就可以更有效地依靠它，而不是依靠我们自己，在最短的时间内提供最有前途的解决方案。 由于对破坏性人工智能的恐惧主要集中在我们达到 ASI（或人工超级智能）时，也许开发致力于道德的狭义 ASI 应该成为我们一致性工作的重点。狭义人工智能系统现在正在接近一流的法律和医学专业知识，并且由于这两个领域已经以如此快的速度取得了如此多的进展，我们可以期待在未来几年内取得实质性进展。 如果我们开发一个狭义人工智能系统，不专门用于法律或医学，而是专门用于更好地理解处于一致性问题核心的道德，会怎么样？这样的系统可以被称为狭义人工道德超级智能（NAMSI）。 像 Stability AI 的 Emad Mostaque 这样的人工智能开发人员了解追求狭义人工智能应用相对于更雄心勃勃但难以实现的 AGI 的优势。事实上，Stability 的商业模式专注于为其企业客户开发非常具体的狭义人工智能应用程序。 作为一个全球社会，我们面临的问题之一是我们应该最大程度地应用我们正在开发的人工智能的哪些方面？考虑到解决对齐问题的绝对必要性，以及对道德是该解决方案的核心挑战的理解，在我们达到 AGI 和 ASI 之前，开发 NAMSI 可能是解决对齐问题的最佳机会。 但是为什么要选择狭隘的人工道德超级智能而不是简单的人工道德智能呢？因为这在我们的掌握之中。虽然道德具有挑战人类的巨大复杂性，但我们在狭隘的法律和医疗人工智能应用方面取得的成功，可能在几年内超过各个狭隘领域的顶级律师和医生的专业知识，这告诉我们一些事情。我们有理由相信，如果我们训练人工智能系统更好地理解道德的运作方式，我们可以预期它们迟早会在这个狭窄的领域达到远远超过人类的专业水平。一旦我们到达那里，我们在到达 AGI 和 ASI 之前解决对齐问题的可能性就会变得更大，因为我们将依赖人工智能而不是我们自己较弱的智能作为我们选择的工具。   由   提交/u/Georgeo57  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1576ogj/namsi_a_promising_approach_to_solving_the/</guid>
      <pubDate>Sun, 23 Jul 2023 06:06:05 GMT</pubDate>
    </item>
    <item>
      <title>用于 LLM 模型加载/训练的 PCI-E SSD</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/157484k/pcie_ssds_for_llm_model_loadingtraining/</link>
      <description><![CDATA[我知道显卡及其显存大部分时间用于 LLM，而显存是加载较大模型的限制。为什么不使用 M.2 固态硬盘（例如带有 DRAM 的非常快的 PCIe 第 4 代固态硬盘）以及诸如显卡 VRAM 的扩展存储？我的猜测是，这是一个延迟问题，以及必须在 SSD 上完成多少读写操作，这可能会使其性能快速下降，而导致其无法使用。  你对此有何看法或者你知道它是否已经完成了？  快速搜索后，我还没有看到任何相关内容。就像您可以插入真正高端的 m.2 250gb ssd 甚至英特尔傲腾存储、gtx 1070 并加载一些非常大的型号。   由   提交/u/LordMunchu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/157484k/pcie_ssds_for_llm_model_loadingtraining/</guid>
      <pubDate>Sun, 23 Jul 2023 03:53:39 GMT</pubDate>
    </item>
    <item>
      <title>我正在寻找免费的 Ai 网站/服务来转换 mp3 或其他音频文件并将它们转录成低音吉他标签。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15740ya/i_am_seeking_free_ai_websitesservices_to_convert/</link>
      <description><![CDATA[我是一名初学者到中级贝斯手，我想播放一些我喜欢的歌曲，但其中一些歌曲不是很受欢迎，并且没有任何标签。我理想中想要一个可以转录低音音符的人工智能工具。   由   提交 /u/GenuineElf80093   [链接]   ; [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15740ya/i_am_seeking_free_ai_websitesservices_to_convert/</guid>
      <pubDate>Sun, 23 Jul 2023 03:43:05 GMT</pubDate>
    </item>
    <item>
      <title>补充人工智能对齐研究系统的想法：试图关闭自己的人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1570m7a/idea_for_a_supplemental_ai_alignment_research/</link>
      <description><![CDATA[我对于额外的一致 AI 训练模型的一个想法是创建一个严格隔离和受限的关闭子系统，并采取严格的安全预防措施。  该模块将被设计为对可逆关闭不感兴趣，而不是对其错位。除了其狭窄的功能和单向信息流之外，它不会了解任何其他功能。  该模块将从最小的功能开始逐步激活，同时进行广泛的监控。关闭信号将具有冗余的验证机制。保守的奖励模型将用于防止意外的行为激励。  最初将在模拟气隙环境中进行测试。父人工智能系统将通过 RLHF 和宪法人工智能原则等标准对齐技术来开发。多种透明方法将有利于可分析性。  经过模拟测试后，关闭模块可以在持续监督下逐渐暴露于现实世界的激活状态。如果出现任何风险或副作用，它将被停用并重新设计。  一旦主动关闭，将离线分析全面的痕迹，以编录通过其关闭策略发现的对齐漏洞。父系统将与该进程保持隔离。  吸取的经验教训将为对齐技术的迭代改进提供信息，以提高针对潜在解决方法漏洞的鲁棒性。这项目标明确的研究可以补充更广泛的协调工作，同时注意积极最大限度地减少随之而来的风险。  关闭模块需要按照与整个系统相同的安全标准进行设计。模块化设计、不关心关闭、可逆停用、气隙和增量推出等技术都是为了防止意外行为或信息泄漏。 我相信这种方法可以提供有用的见解，但需要在实际激活系统之前首先进行全面的安全实践和预防措施，并进行多次审查和分析，即使是以有限和受限的方式。  欢迎任何批评和分析！抱歉，标题有点标题党的意思。   由   提交/u/RamazanBlack  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1570m7a/idea_for_a_supplemental_ai_alignment_research/</guid>
      <pubDate>Sun, 23 Jul 2023 00:54:41 GMT</pubDate>
    </item>
    <item>
      <title>“它几乎使我们的工作量增加了一倍”：人工智能应该让工作变得更容易。这些工人不同意。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156umlt/it_almost_doubled_our_workload_ai_is_supposed_to/</link>
      <description><![CDATA[虽然人工智能有望简化工作并提高效率，但一些工人报告工作量增加了一倍，挑战了这项技术的感知优势。 为什么这很重要：  人工智能对工作量的影响可能不会普遍受益 人工智能在工作场所的广告优势与实际体验之间可能存在差异 对比体验结果强调需要批判性地评估人工智能的实施情况  期望与现实：工作量困境  与预期的工作量减少相反，人工智能导致了一些工作量的显着增加，例如 Clarkesworld 杂志的 Neil Clarke 团队。 问题主要是由于人工智能生成的内容提交质量差但数量大，迫使团队手动解析每个内容。 &gt;  人工智能的影响因行业而异  虽然技术领导者将人工智能视为提高生产力的工具，但工人的现实往往有所不同，特别是对于非人工智能专家和非管理人员来说，他们报告人工智能采用后工作强度增加。 媒体行业的经验凸显了人工智能采用的混合结果，事实证明人工智能对某些任务很有用，但在其他情况下会产生额外的工作，特别是当它生成需要广泛审查和纠正的内容时。   寻找解决方案：未来的挑战  一些人正在转向人工智能来解决人工智能产生的问题，例如使用人工智能驱动的探测器来过滤人工智能生成的内容。 然而，这些工具目前被证明是不可靠的，导致误报和误报，从而增加而不是减少工作量。 这凸显了需要更细致、更有效的人工智能解决方案，考虑到考虑不同行业工人的不同经历和需求。  来源 (CNN)  PS: 我运行一个机器学习驱动的新闻聚合器，它总结了来自 50 多家媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156umlt/it_almost_doubled_our_workload_ai_is_supposed_to/</guid>
      <pubDate>Sat, 22 Jul 2023 20:38:42 GMT</pubDate>
    </item>
    <item>
      <title>我是一名语言学家，我想攻读人工智能硕士学位，有什么建议吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156u02p/im_a_linguist_and_i_would_like_to_study_a_masters/</link>
      <description><![CDATA[所以我 (24m) 是一名语言学家和会议口译员。我最近决定继续学业并攻读硕士学位，这将使我在市场上占据一席之地，或者至少专业化一点。所以，基本上，就是拓宽我的选择范围，让我的个人资料令人满意。 我在攻读学位时一直想学习一些与人工智能相关的东西，但当时它还没有那么受欢迎，而且没有太多选择。有人有什么建议/建议吗？我的国家提供的学位非常有限，所以我只是好奇你们中的一个人是否可以推荐这一领域的优秀硕士学位。我理想地想要一门强调语言学的课程，这样它会更适合我的个人资料。谢谢！！   由   提交 /u/CuratusDefixus   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156u02p/im_a_linguist_and_i_would_like_to_study_a_masters/</guid>
      <pubDate>Sat, 22 Jul 2023 20:12:26 GMT</pubDate>
    </item>
    <item>
      <title>人工智能。创造者。创建。谁控制谁？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156tm62/ai_creator_creation_who_controls_who/</link>
      <description><![CDATA[我最近制作了一部关于人工智能的发人深省的电影。 https://youtu.be/ffa0bS8taZs 随着 GPT-4 等技术所体现的人工智能的快速进步，继续重塑我们的世界并重新定义就业市场，我的电影深入探讨了人类及其创造物之间的复杂关系。在这个独特的人工智能传奇故事中，我们探索了创造一个能够超越其创造者的先进人工智能 Ava 的不可预见的后果。这是对人工智能潜在影响的一次激动人心、发人深省的探索，引发了我们与这些数字实体关于未来的对话。   由   提交 /u/blakeridder   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156tm62/ai_creator_creation_who_controls_who/</guid>
      <pubDate>Sat, 22 Jul 2023 19:56:52 GMT</pubDate>
    </item>
    <item>
      <title>格莱美奖将允许人工智能“辅助”歌曲获得未来的格莱美提名</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156p439/the_grammys_will_allow_ai_assisted_songs_for/</link>
      <description><![CDATA[今天， 录音学院首席执行官确认了允许人工智能辅助音乐获得 2024 年格莱美提名的决定。即使在人工智能抢走工作方面好莱坞也面临着这样的麻烦。 原因是什么？ 格莱美希望保持技术领先，但这可能会适得其反。 格莱美更新允许人工智能协作的规则：  部分由人工智能工具贡献的歌曲现在有资格获得提名，但纯粹由人工智能创作的音乐仍然不符合资格。 人类创造力必须在任何提交的创作过程中发挥实质性和有意义的作用。 录音学院正在探索检测合格歌曲中人工智能工具使用情况的方法。  对人工智能采用的行业强烈反对的回应：  其他娱乐联盟，如 SAG-AFTRA ，对人工智能和自动化影响的担忧表示担忧。 但格莱美奖相信，如果使用得当，人工智能可以在增强人类创造力方面发挥作用。 公平的补偿仍然需要对人工智能的使用进行适当的归因和批准。  关于人工智能在音乐中的地位的持续争论：  格莱美奖表示，他们将逐年监测人工智能合作对音乐的影响。 他们对未来调整提名规则持开放态度如果人工智能的参与被证明存在问题。 目前，重点仍然是庆祝人类创造力、原创性和表达方面的卓越表现。  TL;DR 尽管好莱坞对人工智能发起了攻击，格莱美奖仍将允许人工智能辅助的歌曲有资格获得 2024 年提名。但纯粹由人工智能创作的音乐仍然达不到资格。录音学院目前支持这一决定，但正在研究人工智能检测和监控的影响。他们的目标是平衡创新和创造性的人类表达。 P.S. 通过加入增长最快的 AI 时事通讯之一，您可以在 3 分钟内获得有关 AI 的更多知识。加入我们由来自 Open AI、Google、Meta 等的 1000 名专业人士组成的大家庭。   由   提交 /u/Ok-Feeling-1743   [链接]  2； [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156p439/the_grammys_will_allow_ai_assisted_songs_for/</guid>
      <pubDate>Sat, 22 Jul 2023 16:51:06 GMT</pubDate>
    </item>
    <item>
      <title>Shopify员工违反保密协议，揭露公司秘密使用AI取代下岗员工！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156m9fo/shopify_employee_violates_nda_to_reveal_company/</link>
      <description><![CDATA[https://thedeepdive.ca/shopify-employee-breaks-nda-to-reveal-firm-quietly-replacing-laid-off-work ers-with-ai/   由   提交/u/GaindDho   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156m9fo/shopify_employee_violates_nda_to_reveal_company/</guid>
      <pubDate>Sat, 22 Jul 2023 14:56:28 GMT</pubDate>
    </item>
    <item>
      <title>克里斯托弗·诺兰表示人工智能创造者正面临“奥本海默时刻”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156esu8/christopher_nolan_says_ai_creators_are_facing/</link>
      <description><![CDATA[克里斯托弗·诺兰的新片《奥本海默》罗伯特·奥本海默在开发原子弹时面临的道德问题与当前围绕人工智能的挑战相似。导演和专家将创造强大人工智能技术的困境以及潜在的意想不到的后果与奥本海默的历史处境进行了比较。 原子弹和人工智能：   诺兰表示，领先的人工智能研究人员将当前形势称为“奥本海默时刻”，这与奥本海默在开发原子弹时面临的道德问题相似。 理论物理学家Carlo Rovelli 补充道，这些伦理问题不仅适用于过去，而且也是“当今的紧迫问题”。 随着人工智能的快速发展，人们越来越担心人工智能潜在的武器化，这可能会导致无法控制的自主武器系统。  人工智能和潜在风险：   斯特拉斯堡大学教授 Birgitta Dresp-Langley法国警告称，由于人工智能的进步，可能会出现新型、更先进的大规模杀伤性武器。 其他风险包括环境成本、极端主义意识形态可能增加、成见、诽谤和错误逮捕。一组研究人员在 2021 年的一份报告中强调了这些风险。  人工智能、武器和企业责任：   诺兰强调，随着人工智能和武器之间的关系变得更加密切，企业责任的必要性。 导演将人们在没有充分理解其影响的情况下生产或使用人工智能技术的想法描述为“可怕”。  来源 (NBC) PS： 我运行一个机器学习驱动的新闻聚合器，它总结了来自 50 多家媒体的最佳科技新闻（TheVerge、TechCrunch...）。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156esu8/christopher_nolan_says_ai_creators_are_facing/</guid>
      <pubDate>Sat, 22 Jul 2023 08:51:56 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则[请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 一如既往，请向我们提供反馈，如果您有兴趣帮助该子版块，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！ 我们的目标是为所有被视为人工智能的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 作为理解和理解人工智能的起点了解 AI 主题 提供技术论文演示和讨论 展示高质量的 AI/ML 应用程序 提供培训和学习资源 引导用户访问更具体的信息和 subreddits 列出 AI/ML 应用程序、其用途、成本和访问信息 其他 AI 相关内容。 ...以及更多  此子版块的审核团队是进行重新洗牌，这将导致子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“请求评论”进行的。 (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新应用程序/自我推销/AI 生成内容的规则 由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的置顶线程中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的置顶线程中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用才华来组织帖子。请注意，已经添加了新功能，我们愿意接受更多建议。 关于 AI/ML 应用程序的 NSFW 应用程序和技术的子政策应该是什么？ 我们希望包括对 mod-bots 有想法的社区。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能提出哪些有趣的东西？ 培养初级、中级和高级资源，以帮助人们查找他们正在寻找的信息、培训、模型、技术数据等 启动子堆栈/播客来采访整个 AI/ML 领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>