<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能会怎样，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 20 Nov 2023 21:15:44 GMT</lastBuildDate>
    <item>
      <title>人工智能用于阅读/学习？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zz1kk/ai_for_readingstudying/</link>
      <description><![CDATA[大家好，我想知道是否有人有人工智能帮助人们学习书籍的经验。使用不同格式的能力是一种奖励，而且它是否有助于制定学习计划。 有什么建议吗？ 有人尝试过解谜吗？它有一个小的试用版，但它限制了页面。我不想获得每月计划，除非它值得。   由   提交 /u/thematrixiam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zz1kk/ai_for_readingstudying/</guid>
      <pubDate>Mon, 20 Nov 2023 21:08:48 GMT</pubDate>
    </item>
    <item>
      <title>只是使用网络摄像头与人工智能对话的快速演示</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zywox/just_a_quick_demo_of_talking_with_an_ai_using_a/</link>
      <description><![CDATA[https://www.youtube.com /watch?v=G_L8t3EQMcs  如果您正在开发并想要了解如何执行此操作的所有详细信息，说明中会有一篇博客文章。   由   提交 /u/oculuscat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zywox/just_a_quick_demo_of_talking_with_an_ai_using_a/</guid>
      <pubDate>Mon, 20 Nov 2023 21:03:11 GMT</pubDate>
    </item>
    <item>
      <title>营销人员如何克服过度使用库存照片和模特发布问题的挑战？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zyqez/how_can_marketers_overcome_the_challenge_of/</link>
      <description><![CDATA[我经常找到具有良好身体姿势、出色背景和整体吸引力的美感的库存照片，但模特脸上的表情不适合我们的广告系列，或者我已经在许多其他活动中看到过这种模式。您如何应对过度使用库存照片的挑战，以及如何处理与模特发布相关的问题，特别是对于一些免费库存照片提供商？    ;由   提交/u/MatthiasMayer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zyqez/how_can_marketers_overcome_the_challenge_of/</guid>
      <pubDate>Mon, 20 Nov 2023 20:55:58 GMT</pubDate>
    </item>
    <item>
      <title>概念领袖工具包今天在 Product Hunt 上推出！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zy4fd/notion_leaders_toolkit_launched_on_product_hunt/</link>
      <description><![CDATA[Notion Leader&#39;s Toolkit 是您的终极武器库，包含 61 个实用工具，让您像管理大师一样发号施令！ 不再被淹没管理书籍中的内容——触手可及的实用工具！ 请在此处查看并支持 👉🏻 https://www.producthunt.com/posts/notion-leader-s-toolkit 谢谢:)   由   提交/u/donaltramp699   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zy4fd/notion_leaders_toolkit_launched_on_product_hunt/</guid>
      <pubDate>Mon, 20 Nov 2023 20:30:05 GMT</pubDate>
    </item>
    <item>
      <title>也许伊利亚看到了像《烈士》（2007）中的烈士那样深刻而可怕的东西？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zxcba/maybe_ilya_saw_something_so_profound_and_scary/</link>
      <description><![CDATA[伊利亚和同事的反应让我想起了一部很难看的法国电影《烈士》的结局。  由于太多的女性折磨，我无法让自己观看整部未剪辑的电影，但我看到了回顾/总结，结局对我来说非常深刻。 其他人都可以与此有关吗？ 也许伊利亚和他的同事看到了一些如此深刻和可怕的东西，以至于他们不得不做出这样的反应？ 人工智能教父去年也退出了谷歌。  &gt; 你认为他们做出这样的反应一定是什么？ 马克斯·德拉特对结局有很好的看法： 恐怖电影史上最深刻的结局？ https://youtu.be/_wMGm2ZESdk?si=7xS5ZBvwn8OYO6RG   由   提交/u/aaatings  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zxcba/maybe_ilya_saw_something_so_profound_and_scary/</guid>
      <pubDate>Mon, 20 Nov 2023 19:57:27 GMT</pubDate>
    </item>
    <item>
      <title>这是周末所有 OpenAI 开发的回顾</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zwabl/heres_a_recap_of_all_openai_developments_over_the/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zwabl/heres_a_recap_of_all_openai_developments_over_the/</guid>
      <pubDate>Mon, 20 Nov 2023 19:12:48 GMT</pubDate>
    </item>
    <item>
      <title>可以处理图像并生成“诗意”字幕的人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17ztkr6/ai_that_can_process_images_and_generate_poetic/</link>
      <description><![CDATA[我正在寻找一种人工智能工具，能够处理图像并生成能够捕捉图像“本质”的标题。图像的一部分，有点像口号。我能找到的唯一的东西要么完全字面地描述图像，要么生成 Instagram 风格的标题，这不是我想要的。 非常感谢任何帮助🙏🙏   由   提交/u/cloudypizzas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17ztkr6/ai_that_can_process_images_and_generate_poetic/</guid>
      <pubDate>Mon, 20 Nov 2023 17:18:13 GMT</pubDate>
    </item>
    <item>
      <title>来自外行的问题：我不断看到伊利亚、奥特曼、杰弗里·辛顿、道格拉斯·霍夫施塔特等人做出的令人印象深刻的预测。炒作有多扎实？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zs05v/question_from_a_layman_i_keep_seeing_impressive/</link>
      <description><![CDATA[我所说的“令人印象深刻”是指在大多数智力问题解决任务方面创造出与人类处于同一水平的人工思维。我想这就是通常所说的 AGI，但我不确定这是否是它的真正含义。同样令人印象深刻的是，这些预测通常是在不久的将来（5 到 30 年）进行的。那是在我退休之前。 我认为，如果这样的事情确实按预期工作，那么它就像驯火一样。或者稍微不那么剧烈，就像工业革命一样，但动力十足。 或者我完全错了。此外，对技术的预测在其真正含义和出现时间方面都被夸大了。最后，媒体对重大预测存在偏见，乏味或微妙的预测会被忽视。因此，我受到了不成比例的头条新闻轰炸。 尽管如此，我知道有时我实际上对未来感到沮丧，因为它有多么不确定，人工智能是重要因素之一（其他因素是个人因素） 、局部原因、全局原因）。感觉每个人都只是坐在那里等待社会发生根本性变化的不可避免的时刻，而且它的变化速度太快，大多数人都跟不上。 也许这不是正确的提问方式，尽管这可能是大多数人有足够的知识对这个话题有清醒的看法，也会有很多人对此非常乐观。 所以，再一次，它有多大？就像您个人正在围绕重大范式转变规划生活的某些方面吗？   由   提交/u/ohlordwhywhy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zs05v/question_from_a_layman_i_keep_seeing_impressive/</guid>
      <pubDate>Mon, 20 Nov 2023 16:11:01 GMT</pubDate>
    </item>
    <item>
      <title>显然，Elon Musk、Jan Leike 和 Ilya Sutskever 都是末日论的崇拜者 - OpenAI 将永远被玷污 - 让诉讼飞扬起来 - 有效的利他主义已经结束</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zqx77/so_apparently_elon_musk_jan_leike_and_ilya/</link>
      <description><![CDATA[让我为那些不明白发生了什么的人解释一下。 OpenAI 的这个家伙是一名 ML 研究员，显然专注于 Superalignment 的主题。这篇文章发表于 2023 年 7 月，大约 6 个月前。那么什么是超级对齐，它就是人工智能安全和治理。对我来说，除了他们有一个团队或一个 GUY JAN 之外，令人震惊的是，这次采访是一次直接的末日论探索练习，在这篇文章中读出。 让我说清楚原因我现在感到震惊和敬畏。是因为这个人的表现就好像他所观察到的东西是真实的一样。这对我来说绝对是令人震惊的，而且它是这样读的。如果你读到这篇文章并且不知道这是人工智能，你会认为他们正在观察一种外星生物生命体。哈哈。发生了什么事？ 在阅读中他说我们不知道到底发生了什么。我在人工智能中了解到，神经网络的数据量如此之大，以至于很难观察并控制它们。但他们已经死了。哇。 除了你在制造幻觉“东西”之外，我无法解释这一点。您只是在发货前品尝产品。我只是不知道还能说什么。这读起来好像是科幻小说，但有趣的是它确实如此。这是一个完全假设的、荒谬的情况，关于探索“如果这是活的，我们需要担心它是否在撒谎”的想法。来自谷歌发明的变压器、大量数据、大量计算能力和一些伟大的工程。如果这不是锡纸，我不知道什么才是。目前，这个人在 OpenAI 工作。 https://axrp.net/episode/2023/07/27/episode-24-superalignment-jan-leike.html 人类水平的自动比对研究人员与超级智能之间的差距 丹尼尔·菲兰：有道理。所以我的一个问题是：当你说一位人类水平的一致性研究人员时，似乎在人工智能中，大多数事情在任何方面都不完全是人类水平，对吧？所以你提到了聊天模型。我认为他们只是在知识广度方面是超人，对吗？我认为任何人都很难像 GPT-4 那样了解那么多事实。但[他们]的算术能力低于人类，至少在允许人类拥有笔和纸的情况下，你知道吗？那么，‘人级’限定符到底有多重要呢？ 在这些任务列表中，如果其中某些任务确实超人，这对您来说是个问题还是更好？ Jan Leike：是的，我认为问题实际上是运行该系统来执行对齐研究任务有多大风险？因为如果它知道很多事实，那就不是特别可怕，但我们真正知道的是需要弄清楚的是，如果我们让系统接管一定量或最终几乎所有的对齐研究，它会欺骗我们吗？ 它会试图欺骗我们吗？它会试图趁机接管吗？因为现在，它正在做太多的事情，我们无法亲自查看[这一切]。因此，问题是你需要什么样的技能才能做到这一点，它与同类技能相比如何我们需要哪些技能才能在一致性研究中获得大量帮助？ 如果你放大这个问题，我们实际上会担心什么？这就像，有多好？该模型是否在编造真正连贯的谎言，或者具有欺骗性，或者假装做某事或相信一件事，然后实际上想要另一件事？我认为这里另一个真正关键的能力是自我渗透。那么，该模型在打破安全预防措施、访问自己的权重并尝试将其复制到互联网上的其他地方方面有多好？或者说服有权访问权重的工程师下载它们​​并将它们发送到某个地方？因此，我们可以具体测量模型在这方面的表现，然后我们可以将其与测量进行比较，看看它在实际帮助我们进行对齐研究方面有多好？ Daniel Filan： Daniel Filan：&lt;强&gt;好的。大致的想法是：你希望模型不要太擅长这些可怕的任务？ Jan Leike： 没错。   由   提交/u/Xtianus21  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zqx77/so_apparently_elon_musk_jan_leike_and_ilya/</guid>
      <pubDate>Mon, 20 Nov 2023 15:23:33 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 刚刚从 Facebook 转到 MySpace 了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zq7zf/did_openai_just_go_from_facebook_to_myspace/</link>
      <description><![CDATA[这似乎是过去十年企业活动中最奇怪的 72 小时，而且它正在 Twitter 上公开上演   由   提交 /u/Homeless_72   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zq7zf/did_openai_just_go_from_facebook_to_myspace/</guid>
      <pubDate>Mon, 20 Nov 2023 14:51:42 GMT</pubDate>
    </item>
    <item>
      <title>数百名 OpenAI 员工威胁辞职并加入微软</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zq4qa/hundreds_of_openai_employees_threaten_to_resign/</link>
      <description><![CDATA[OpenAI 的大多数员工威胁要从公司辞职并加入微软，微软已聘请了被赶下台的 OpenAI 首席执行官 Sam Altman 和前 OpenAI 联合创始人格雷格·布罗克曼 (Greg Brockman) 领导一个新的“先进人工智能研究团队”。 Wired 和记者 Kara Swisher 今天早上报道了一封致 OpenAI 董事会的信，其中 500 多名 OpenAI 现任员工表示：“微软已向我们保证，如果我们选择加入，这家新子公司的所有 OpenAI 员工都会有职位。 ” 信中称，如果董事会不恢复 Altman 和 Brockman 的职位，然后辞职，OpenAI 员工将离开。但鉴于董事会已经做出选择，决定留任并任命新首席执行官，而奥特曼和布罗克曼则前往微软，微软似乎刚刚找到了奥特曼的前数百名员工，假设他们的说法是正确的。公司承诺雇用他们所有人。 签署这封信的 OpenAI 员工指责公司董事会危及他们的工作并“破坏了我们的使命和公司”。他们还否认 OpenAI 在不考虑安全的情况下推进得太快的观点。他们写道：“我们在人工智能安全和治理方面的工作塑造了全球规范。” 来源   由   提交 /u/Tankeverket   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zq4qa/hundreds_of_openai_employees_threaten_to_resign/</guid>
      <pubDate>Mon, 20 Nov 2023 14:47:18 GMT</pubDate>
    </item>
    <item>
      <title>尽管令人兴奋，但大多数 B2B 人工智能应用程序仍然很糟糕。我们该如何解决它？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zp57b/for_all_the_excitement_most_b2b_ai_apps_still/</link>
      <description><![CDATA[我已经尝试了 100 个针对具有人工智能功能的企业的新应用程序，几乎所有这些都令人失望。徽标生成器、宣传材料设计器、人工智能写作工具、生产力应用程序、统一搜索、知识库、人工智能销售/客户支持机器人等。不要误会我的意思——那里有很多潜力和一些很酷的产品，但总的来说我发现它们不符合商业用途。然而。  当然，部分原因是我们还处于令人难以置信的早期阶段，这些产品体验无疑会突飞猛进。但是，尽管基础模型在过去一年中取得了迅速的进步，我认为可以公平地说，“应用层”已经取得了巨大的进步。没有跟上步伐。  有些人可能会说，这一切都将随着 GPT 的改变而改变 - 很快我们将有 1000 个自定义 GPT 可供选择，每个任务都有一个，并且由于竞争和创新，最好的 GPT 将能够做到几乎任何你能想到的任务。但至少在 B2B 环境中，我怀疑情况是否会如此。  为什么？对我来说，我们遗漏了拼图中至关重要的一块。  我们在“堆栈”的背后进行了大量的创新——云基础设施、GPU 和基础模型。以及应用程序层前端的大量创新。 但是，为了使 B2B 应用程序真正有用，我们需要在中间进行更多工作：经过专门训练的模型、专有数据以及存储数据的新方法。到目前为止，RAG 是我们最接近的有效定制通用模型以适应特定业务用例的方法。但我想我们都知道 RAG 并不是前进的方向。  我对如何解决这个问题有一些想法和想法，但你觉得怎么样？ ​   由   提交 /u/Illustrious-Yak-6142   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zp57b/for_all_the_excitement_most_b2b_ai_apps_still/</guid>
      <pubDate>Mon, 20 Nov 2023 13:59:45 GMT</pubDate>
    </item>
    <item>
      <title>微软聘请萨姆·奥尔特曼和格雷格·布罗克曼</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/17zks30/microsoft_hires_sam_altman_and_greg_brockman/</link>
      <description><![CDATA[微软首席执行官 Satya Nadella 周一宣布，已聘请 OpenAI 联合创始人 Sam Altman 和 Greg Brockman 领导一个新的高级团队该软件集团的人工智能研究团队。 纳德拉表示，Altman 和 Brockman 将由其他同事加入，这表明微软还在招募许多最近从 OpenAI 离职的其他人员。  来源 推文   由   提交 /u/TheInsaneApp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/17zks30/microsoft_hires_sam_altman_and_greg_brockman/</guid>
      <pubDate>Mon, 20 Nov 2023 09:32:20 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则[请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行一项民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 作为请始终向我们提供反馈，如果您有兴趣帮助该子项目，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！&lt; /p&gt; 我们的目标是为所有与人工智能有关的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 服务作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用 提供培训和学习资源&lt; /li&gt; 引导用户访问更具体的信息和子版块 列出 AI/ML 应用程序、其用途、成本和访问信息 其他与 AI 相关的内容。  li&gt; ...以及更多  该子项目的审核团队正在进行重组，这将导致该子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“Request-For-”评论” (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新申请/自我推销/AI 生成的规则content  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的粘帖中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的粘帖中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用才华来组织帖子。请注意，已经添加了新的功能，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们会喜欢将社区纳入模组机器人的想法中。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能想出哪些有趣的东西？ 培养初级、中级和高级资源来帮助人们查找信息，他们正在寻找的培训、模型、技术数据等 启动子堆栈/播客来采访整个人工智能/机器学习领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>