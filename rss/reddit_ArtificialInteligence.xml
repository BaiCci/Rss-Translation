<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、人工智能在商业中的应用、人工智能如何影响我们的生活、未来可能会发生什么，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 25 Jul 2023 03:16:43 GMT</lastBuildDate>
    <item>
      <title>获取您最喜欢的AI播客的个性化摘要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158saq9/get_personalized_summaries_of_your_favorite_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     ydb.ai 提供了针对用户兴趣的新播客剧集的简明摘要。每当发行相关情节时，它会提供个性化的每日简报。该工具对繁忙的专业人士特别有益，他们重视播客中的见解，但没有时间听完整的情节。 这里涵盖了一些以AI为注重的播客： - 没有PRIORS-上周在AI-AI-AI-AI-Awmants aignown-ai the Business-Uneperper-Perper-Perper-Perper-Pervised-unupured Learning       &lt;！由   提交/u/u/u/g_pal      [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158saq9/get_personalized_summaries_of_your_favorite_ai/</guid>
      <pubDate>Tue, 25 Jul 2023 00:30:08 GMT</pubDate>
    </item>
    <item>
      <title>最近升级的GPU...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158ru8x/recently_upgraded_gpu/</link>
      <description><![CDATA[我做的第一件事是什么？在运行基准测试并首先进行烧录后，直接开始训练 Real-ESRGAN 模型。 多么惊人的差异和生存时间：D 从 1050gtx 到 3080ti 就像下马跳进赛车......甚至在限制 vram 之前设法将批量大小提高到 64，但已将其买回以进行扩展训练。  使用 traiNNer 没有问题，但仍然不确定哪些选项最适合使用我自己的数据集微调模型。我知道它们在数据集和预期用途之间有所不同，但经过一些研究，我认为 traiNNer 中的默认 SR 超参数有点过时了？也许我还不够了解。 我应该启用可微增强和混合增强吗？目前仅使用默认的翻转和旋转，但我觉得这些还不够。训练时间并不是太重要，但目前我可以在 512px HR 下完成大约 10k iters/hr，在 8 个批次和 12nworkers 下使用 40k 图像数据集完成 128 LR/crop size。 我有兴趣听到其他 SRGAN 培训师的意见，因为我在 Google 上找不到太多关于它的讨论，只有技术论文或有技术问题的人...   由   提交/u/Jenkins87  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158ru8x/recently_upgraded_gpu/</guid>
      <pubDate>Tue, 25 Jul 2023 00:10:53 GMT</pubDate>
    </item>
    <item>
      <title>AI可以增强相机录制的电影吗</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158r7ue/can_ai_enhance_cam_recorded_movies/</link>
      <description><![CDATA[只是想知道是否有一款软件可以提高音质并使图片高清（如果是这样的话）   由   提交/u/Ok-Grass4165   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158r7ue/can_ai_enhance_cam_recorded_movies/</guid>
      <pubDate>Mon, 24 Jul 2023 23:45:16 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158qk82/openais_upcoming_opensource_llm_is_named_g3po_but/</link>
      <description><![CDATA[OpenAI 面临着回应 Meta 开源人工智能技术战略的压力，报告了信息（注意：付费文章）。 但有一个问题：OpenAI 不是尚未准备好承诺发布自己的开源模型，目前代号为“G3PO”，内部尚未决定启动或确认时间表。 为什么这很重要：  Meta 上周发布的 Llama 2 LLM 给提供闭源模型的 OpenAI 和 Google 带来了压力。 Llama 2 附带商业许可证，使大多数企业能够利用 Meta 的开源人工智能技术并从中获利。 OpenAI 显然正在关注开源的威胁。两个月前，有消息称他们打算发布自己的开源模型以避免竞争。现在，我们知道该模型的代号为“G3PO”。 Meta 的开源策略在软件世界的其他领域取得了成功。值得注意的是，Meta 内部发起的开源软件项目包括 React、PyTorch、GraphQL 等。  为什么 OpenAI 推迟发布？该信息在此引用了两个可能的驱动因素：  &lt; OpenAI 的团队规模较小，并不专注于推出应用商店，该商店将为客户提供销售定制人工智能模型的市场。这将是创建开发者锁定并抵御 Meta 和 Google 的另一种途径。 OpenAI 也有创建个性化 ChatGPT 助手的雄心。将使 OpenAI 与微软直接竞争，据消息人士透露，这一努力“可能需要数年时间”。  开源 OpenAI 模型仍然有可能，但《信息报》认为： “OpenAI 仍然相信开发先进的专有模型将产生收入，而不太先进的开源模型将保持开发者的长尾效应，并且可能更容易吸引这些开发者支付最先进的模型的费用。” 主要结论：   Meta 的 Llama 2 发布预示着 LLM 领域的潜在重组，因为利用其 LLM（及其衍生变体）的商业应用程序开始传播。  开发人员快速采用开源模型在 OpenAI 眼中已经被视为一种威胁，问题是他们是否能够足够快地采取行动来锁定开发人员。 我们还处于生成式 AI 竞赛的早期阶段，开源是否会获胜还远未确定。  P.S.如果您喜欢这种分析，我会写免费时事通讯，跟踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。 ​   由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158qk82/openais_upcoming_opensource_llm_is_named_g3po_but/</guid>
      <pubDate>Mon, 24 Jul 2023 23:18:45 GMT</pubDate>
    </item>
    <item>
      <title>用什么软件来用人工智能声音翻唱所有这些歌曲？我很想开始创造这些。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158lsbz/what_is_the_software_being_used_to_do_all_these/</link>
      <description><![CDATA[我将附上一些示例的链接 https://youtu.be/CdJ944NMGlg https://youtu.be/EHAkm-r5tS8 如果您对此有所了解并可以分享，请先致谢！   由   提交/u/PetMyPeePeePlease   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158lsbz/what_is_the_software_being_used_to_do_all_these/</guid>
      <pubDate>Mon, 24 Jul 2023 20:18:52 GMT</pubDate>
    </item>
    <item>
      <title>🧒 Marc Andreessen 如何使用 ChatGPT</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158lnwu/how_marc_andreessen_uses_chatgpt/</link>
      <description><![CDATA[🧒 Marc Andreessen 如何使用 ChatGPT 风险投资家 Marc Andreessen 正在教他的小儿子如何利用人工智能诸如 ChatGPT 之类的工具，相信在不断接触 AI 的环境中成长的孩子将拥有正常化的观点，并最终受益于了解自己优缺点的定制 AI 盟友。 Andreessen 让他 8 岁的孩子接触 ChatGPT 的解释能力，并对他儿子漫不经心的耸肩反应感到惊讶，这强调了他的观点，即 AI 将成为未来几代人工作和生活的无缝工具，而不是新奇或令人恐惧的东西。 所有父母都应该这样做开始教他们的孩子有关人工智能以及如何使用它吗？ 我们今天使用它的方式，1、3、5 或 10 年后还会使用这种方式吗？ 该图像是由 MidJourney 生成的。   由   提交/u/Yavero   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158lnwu/how_marc_andreessen_uses_chatgpt/</guid>
      <pubDate>Mon, 24 Jul 2023 20:14:30 GMT</pubDate>
    </item>
    <item>
      <title>人工智能系统通过分析毒贩的驾驶模式帮助警察识别毒贩</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158kmwg/ai_system_helped_cops_identify_a_drug_trafficker/</link>
      <description><![CDATA[纽约警方最近成功逮捕了一名毒贩 David Zayas，他被发现持有大量强效可卡因、一把枪和超过 34,000 美元的现金。 《福布斯》报道称，当局利用一家名为 Rekor（一家专门从事道路情报的公司）的服务抓获了犯罪者。警方通过从地区道路收集的庞大信息数据库分析扎亚斯的驾驶模式后，确定他为可疑人员。 该数据库源自由 480 个自动车牌识别 (ALPR) 摄像头组成的网络，每周扫描 1600 万辆汽车，以获取车牌号、车辆品牌和型号等数据。 多年来，警方一直使用车牌读取系统来寻找可能驾照过期或因之前​​违规而被通缉的司机。然而，现在，人工智能集成似乎使该技术能够通过观察驾驶员行为来识别其他类型的犯罪行为。 这一事件凸显了人工智能在执法中日益复杂的使用。 来源：Gizmodo 如果如果您喜欢此类新闻报道并希望了解人工智能和技术领域的最新消息，请考虑订阅免费新闻通讯（链接）。   由   提交 /u/nerdninja08   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158kmwg/ai_system_helped_cops_identify_a_drug_trafficker/</guid>
      <pubDate>Mon, 24 Jul 2023 19:37:34 GMT</pubDate>
    </item>
    <item>
      <title>Opentensor 和 Cerebras 宣布推出 BTLM-3B-8K，这是一种适用于移动设备的 30 亿参数最先进的开源语言模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158kf0z/opentensor_and_cerebras_announce_btlm3b8k_a_3/</link>
      <description><![CDATA[[注：我在 Cerebras 工作] Cerebras 和 Opentensor 今天在 ICML 上宣布推出 BTLM-3B-8K（Bittensor 语言模型），这是一种最先进的新型 30 亿参数开源语言模型，在十几个 AI 基准测试中实现了领先的准确性。 BTLM 适用于内存低至 3GB 的移动和边缘设备，有助于实现人工智能对全球数十亿设备的民主化。 BTLM-3B-8K 亮点：  3B 模型中的 7B 级模型性能 最先进的 3B 参数模型 针对 8K 或更长的长序列长度推理进行了优化 第一个在最大的完全去重开放数据集 SlimPajama 上训练的模型 运行于量化为 4 位时内存低至 3GB 的设备 用于商业用途的 Apache 2.0 许可证。  BTLM 受 Opentensor 基金会委托在 Bittensor 网络上使用。 Bittensor 是一个基于区块链的网络，任何人都可以贡献 AI 模型进行推理，为 OpenAI 和 Google 等集中式模型提供商提供了去中心化的替代方案。 Bittensor 在网络上为超过 4,000 个人工智能模型提供服务，模型参数超过 10 万亿个。 BTLM 在新推出的 Condor Galaxy 1 (CG-1) 超级计算机上进行训练，这是 G42 Cerebras 战略合作伙伴关系的第一个公开交付成果。我们衷心感谢 G42 Cloud 和 Inception Institute of Artificial Intelligence 的慷慨支持。我们还要感谢我们的合作伙伴 Cirrascale，他们首先向 Cerebras 引入了 Opentensor 并提供了额外的技术支持。最后，我们要感谢 Together AI 团队提供的 RedPajama 数据集。 要了解更多信息，请查看以下内容：  博客：https://www.cerebras.net/blog/btlm-3b-8k-7b-performance -in-a-3-billion-parameter-model/ 拥抱脸部模型：https://huggingface.co/cerebras/btlm-3b-8k-base  ​  &amp;# 32；由   提交 /u/CS-fan-101   [链接]   ; [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158kf0z/opentensor_and_cerebras_announce_btlm3b8k_a_3/</guid>
      <pubDate>Mon, 24 Jul 2023 19:29:42 GMT</pubDate>
    </item>
    <item>
      <title>人工智能根据人类大脑活动重建音乐，被称为“Brain2Music”，由谷歌研究人员创建</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158gjly/ai_reconstructs_music_from_human_brain_activity/</link>
      <description><![CDATA[一项名为 Brain2Music 的新研究展示了根据人类大脑模式重建音乐这项工作为了解大脑如何解释和表现音乐提供了一个独特的窗口。 Brain2Music 简介 核心方法论涉及：  通过以下任一方式重建原始剪辑： 根据预测的嵌入检索类似的音乐。 使用 MusicLM（一种基于变压器的尖端生成模型）生成以嵌入为条件的新音乐。  使用线性回归从捕获正在聆听音乐刺激的受试者的 fMRI 数据中预测高级音乐嵌入。  &lt; strong&gt;关键技术发现  语义重建成功：  重建的音乐在流派、乐器、基于人类评估和定量指标的情绪方面在语义上类似于原始剪辑。  模型-大脑表示对齐：  MusicLM 的不同组件与不同的大脑区域相关，表明 AI 表示部分反映了人类的表示听觉系统。  文本嵌入-听觉皮层链接：  纯文本衍生的嵌入与听觉皮层活动密切相关，表明这些区域代表了抽象信息。   局限性和未来工作 当前方法的局限性包括：   粗时间 fMRI 分辨率限制了重建质量。 嵌入和生成模型的选择限制了结果。  未来的工作可能涉及：  重建想象或回忆的音乐。 比较音乐家等不同学科群体的重建结果。  启示  这种人工智能驱动的重建方法可以对以下方面产生新的见解：  音乐的不同方面（例如流派和乐器）如何在大脑中表示。 人工智能模型表示和生物听觉处理之间的相似性。 非侵入性大脑扫描中包含的信息深度。  TL;DR 研究人员介绍了 Brain2Mus ic 使用人工智能从大脑扫描中重建音乐。 MusicLM 根据功能磁共振成像数据预测的嵌入生成音乐。重建在语义上类似于原始剪辑，但面临嵌入选择和功能磁共振成像数据的限制。这项工作提供了有关 AI 表征如何与大脑活动保持一致的见解。 完整的 21 页论文：（链接） PS：加入发展最快的 AI 时事通讯之一，您可以在 3 分钟内获得有关 AI 的更多知识。 加入我们的大家庭 &lt; strong&gt; 来自 Open AI、Google、Meta 等的 1000 名专业人士。   由   提交 /u/saffronfan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158gjly/ai_reconstructs_music_from_human_brain_activity/</guid>
      <pubDate>Mon, 24 Jul 2023 17:07:38 GMT</pubDate>
    </item>
    <item>
      <title>如何通过几次点击在混乱的现实数据上训练和部署可靠的模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158g1be/how_to_train_and_deploy_reliable_models_on_messy/</link>
      <description><![CDATA[新功能警报：自动训练和自动训练在混乱的现实数据上部署可靠的 ML 模型（比微调的 OpenAI LLM 更准确）——只需几次点击！ 公司难以快速部署良好的 ML 模型并产生业务价值的常见原因包括：充满问题的混乱数据、需要探索许多 ML 模型来训练一个好的模型，以及从模型进行预测时面临基础设施挑战。现在，您可以使用 Cleanlab Studio 在几分钟内处理所有这一切。 对于产品评论分类，部署的 Cleanlab Studio 模型比在相同数据上进行微调的 OpenAI LLM 更准确。生成此模型只需要在平台中自动点击几下：检测/纠正数据集中的问题以生成更好的版本，识别和训练针对该特定数据的最佳机器学习模型，并将其部署以在应用程序中提供预测服务。 每个步骤通常都需要团队编写大量代码和工作，但如果您使用 Cleanlab，则不需要！几个小时内，我们的尖端 AutoML 与 Foundation 模型就可以为几乎任何数据集生成高度准确的模型。 Cleanlab Studio 允许您通过自动化所有必要步骤，快速将原始图像/文本/表格数据转换为可靠的 ML 模型部署。没有其他工具可以使完整的端到端管道变得如此简单和高效！ 有关我们如何实现这一目标以及模型性能基准的详细信息，请参阅我们的新博文：http://cleanlab.ai/blog/model-deployment/   由   提交 /u/jonas__m   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158g1be/how_to_train_and_deploy_reliable_models_on_messy/</guid>
      <pubDate>Mon, 24 Jul 2023 16:49:32 GMT</pubDate>
    </item>
    <item>
      <title>请给我推荐一个AI工具</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158eldc/please_recommend_me_an_ai_tool/</link>
      <description><![CDATA[嘿，我有一个想法，拍摄屏幕截图和电影海报，通过人工智能编辑器/生成器来调整图像，然后将它们放在衣服上。 唯一的问题是，我能找到的唯一人工智能工具是文本到图像生成器，但我想从图像开始，然后从那里开始。 有人可以推荐一些我可以使用的工具吗？ 提前致谢   由   提交/u/-Old-Mate-  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158eldc/please_recommend_me_an_ai_tool/</guid>
      <pubDate>Mon, 24 Jul 2023 15:56:22 GMT</pubDate>
    </item>
    <item>
      <title>Sam Altman 的“世界币”今天发布以及人工智能如何融入其中</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158cnbx/sam_altmans_worldcoin_releases_today_and_how_ai/</link>
      <description><![CDATA[世界币有着雄心勃勃的使命，即建立一个由人类拥有的全球包容性身份和金融网络。他们的策略以建立“人格证明”为中心。验证个人是否是独特的人类。 这听起来类似于 Open AI 创建 ASI 的使命。 Sam 凌晨 4 点发布了此公告 世界币项目 世界币由三个主要组成部分组成： 世界 ID： 建立在人格证明之上的隐私保护身份网络 它使用称为 Orb 的定制生物识别硬件进行验证个人也是人，同时通过零知识证明保护隐私。 World ID 的目标是“以人为本”，含义与发行的特定个人相关。 Worldcoin 代币：发行是为了激励网络发展并调整激励措施。广泛发行的目的是引导采用并克服“冷启动问题”。如果成功，它可能会成为分布最广的数字资产。 World App： 第一个可以创建 World ID 并与 Worldcoin 协议集成的软件钱包 最终，许多钱包都可以集成 World ID 支持。 - 为什么人格证明很重要 - 人格证明是指可靠地证明一个人是一个独特的人。 Worldcoin 认为这是一个必要的先决条件： -区分真实的人和真实的人日益复杂的机器人和在线人工智能 - 实现公平价值分配并防止女巫攻击 - 促进民主治理和数字身份。 - 可能促进 UBI 等资源的分配。 根据 Worldcoin 的说法，随着人工智能的进步，人格证明只会变得越来越重要。 WorldCoin 的工作原理 为了获得 World ID，个人使用 Orb 设备，该设备通过生物识别来验证人性和唯一性传感器。 World 应用程序引导用户完成此过程。然后，经过验证的个人可以在任何集成世界币协议的平台上私下证明他们是人类。他们还获得参与参与的 WorldCoin 代币。 宏伟愿景 完全实现的 Worldcoin 网络旨在推进： - 普遍获得去中心化金融，实现即时、无边界交易。 - 数字交互中可靠的机器人过滤 - 全球参与的新颖民主治理机制 - 更公平地分配资源和经济机会。 TL;DV 加密初创公司 Worldcoin 旨在通过新颖的“人格证明”创建一个全球身份和金融网络。它使用定制硬件来私下验证个人。世界币代币激励与网络增长保持一致。潜在的应用包括机器人过滤、去中心化金融访问和全球治理。来源：（链接） PS：通过加入增长最快的人工智能新闻通讯，您可以在 3 分钟内获得关于人工智能的更多知识。加入我们由来自 Open AI、Google、Meta、等等。   由   提交/u/saffronfan  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158cnbx/sam_altmans_worldcoin_releases_today_and_how_ai/</guid>
      <pubDate>Mon, 24 Jul 2023 14:42:45 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的最终目标</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1585ncv/end_goal_of_ai/</link>
      <description><![CDATA[所以我注意到数十亿美元被投入到人工智能的开发中，对于那些知道的人来说这个问题 人工智能的主要应用是什么？理想是什么，我们希望达到什么？   由   提交 /u/Human_Number56884322   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1585ncv/end_goal_of_ai/</guid>
      <pubDate>Mon, 24 Jul 2023 09:31:27 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则[请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 一如既往，请向我们提供反馈，如果您有兴趣帮助该子版块，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！ 我们的目标是为所有被视为人工智能的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 作为理解和理解人工智能的起点了解 AI 主题 提供技术论文演示和讨论 展示高质量的 AI/ML 应用程序 提供培训和学习资源 引导用户访问更具体的信息和 subreddits 列出 AI/ML 应用程序、其用途、成本和访问信息 其他 AI 相关内容。 ...以及更多  此子版块的审核团队是进行重新洗牌，这将导致子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“请求评论”进行的。 (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新应用程序/自我推销/AI 生成内容的规则 由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的置顶线程中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的置顶线程中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用才华来组织帖子。请注意，已经添加了新功能，我们愿意接受更多建议。 关于 AI/ML 应用程序的 NSFW 应用程序和技术的子政策应该是什么？ 我们希望包括对 mod-bots 有想法的社区。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能提出哪些有趣的东西？ 培养初级、中级和高级资源，以帮助人们查找他们正在寻找的信息、培训、模型、技术数据等 启动子堆栈/播客来采访整个 AI/ML 领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>