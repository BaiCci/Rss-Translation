<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、人工智能在商业中的应用、人工智能如何影响我们的生活、未来可能会发生什么，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 25 Jul 2023 18:19:17 GMT</lastBuildDate>
    <item>
      <title>人工智能超级智能能否解决气候变化问题？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/159fr34/can_ai_superintelligence_fix_climate_change/</link>
      <description><![CDATA[每个人都在谈论人工智能如果获得超级智能就会终结人类的前景，但为了论证起见，我们也可以说它是否也有能力在同样的逻辑下解决气候变化？   由   提交/u/Jannol   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/159fr34/can_ai_superintelligence_fix_climate_change/</guid>
      <pubDate>Tue, 25 Jul 2023 17:55:31 GMT</pubDate>
    </item>
    <item>
      <title>由于准确性不佳，OpenAI 悄悄关闭了其 AI 检测工具</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/159emcv/openai_quietly_shuts_down_its_ai_detection_tool/</link>
      <description><![CDATA[OpenAI 已悄然关闭其 AI 分类器，这是一款旨在识别 AI 生成文本的工具。做出这一决定是因为该工具的准确率较低，这表明区分人工智能生成的内容与人类创建的内容仍然存在挑战。 这是来源（解密） 为什么这很重要：   OpenAI 的努力以及人工智能检测工具随后的失败凸显了围绕人工智能在内容创作中普遍使用的复杂问题。 在教育领域，精确检测的紧迫性更加突出，人们担心人工智能会被不道德地用于论文写作等任务。 OpenAI 致力于完善该工具并解决这些道德问题，说明了在人工智能进步与道德考虑之间取得平衡的持续努力。   OpenAI 的检测工具  OpenAI 设计了 ​​AI 分类器来检测 AI 生成的文本，但由于性能不佳而不得不停止使用。 原始博客文章的附录中指出，该工具的准确率较低，导致其被删除。 OpenAI 现在的目标是通过整合用户反馈并研究更有效的文本来源技术和 AI 生成的音频或视觉内容检测方法来完善该工具。  &lt;强&gt;自推出以来，OpenAI 就承认人工智能分类器并不完全可靠。  该工具难以处理 1000 个字符以下的文本，并且经常将人类编写的内容误认为是人工智能创建的。 评估显示，分类器仅正确识别了 26% 的人工智能编写的文本，并错误地将 9% 的人类生成的文本标记为人工智能编写的。  教育界  教育部门对准确的人工智能检测特别感兴趣，以防止学生使用 ChatGPT 等人工智能工具进行论文创作。 OpenAI 已经认识到这些担忧，并强调了理解人工智能生成的文本分类器的局限性和影响的重要性。 该公司已承诺继续开展外展工作，并更多地了解这些挑战。  PS： https://dupple.com/techpresso&quot;&gt;基于 ML 的新闻聚合器，总结了来自 50 多家媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/159emcv/openai_quietly_shuts_down_its_ai_detection_tool/</guid>
      <pubDate>Tue, 25 Jul 2023 17:14:17 GMT</pubDate>
    </item>
    <item>
      <title>AI 编写《死侍 3》</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/159d1q1/ai_writes_deadpool_3/</link>
      <description><![CDATA[如果《死侍 3》是由 AI 编写 AI 美术、AI 语音、AI 编写   由   提交/u/realzackmcfarlin  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/159d1q1/ai_writes_deadpool_3/</guid>
      <pubDate>Tue, 25 Jul 2023 16:17:12 GMT</pubDate>
    </item>
    <item>
      <title>DSA 还是 Python？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/159coah/dsa_or_python/</link>
      <description><![CDATA[对人工智能充满热情，我是一名第三学期计算机科学专业的学生。我的核心科目包括数据结构和算法以及C++。几个月前我开始学习 Python，但不得不休息一下。现在，考虑到我的 AI 职业目标，我将优先重新开始我的 Python 之旅。 Python 在 AI 社区中的流行及其以 AI 为中心的库使得学习变得至关重要。然而，我不会忽视 DSA 的重要性，因为它培养解决问题的技能，这对人工智能从业者来说至关重要。    由   提交 /u/fashnimal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/159coah/dsa_or_python/</guid>
      <pubDate>Tue, 25 Jul 2023 16:03:36 GMT</pubDate>
    </item>
    <item>
      <title>人工智能到加密货币</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/159cejq/ai_to_cryptocurrency/</link>
      <description><![CDATA[OpenAI 首席执行官周一推出了一家名为 Worldcoin (WLD) 的新企业。该项目旨在使经济激励措施与全球范围内的人类身份保持一致。它使用一种称为“Orb”的装置。扫描人们的眼睛，创建一个称为“世界 ID”的独特数字身份。 Source-Benzinga 世界币项目的使命是建立一个全球包容性的身份和金融网络，有可能为全球民主进程和人工智能资助的全民基本收入（UBI）铺平道路。 该项目因涉嫌在一些国家和当前全球经济中存在欺骗行为而受到批评。加密货币的监管环境提出了重大挑战。 想法； 世界币基础设施的一个关键部分是 Orb，一种用于扫描人们眼睛并生成独特数字身份的设备。这项技术可能会彻底改变我们在数字时代对身份的思考方式，但它也引发了人们对生物识别数据安全性的担忧。 Worldcoin 将如何确保这些敏感信息的安全？将采取哪些措施来防止身份盗窃或欺诈？ Worldcoin 建立全球包容性身份和金融网络的使命是雄心勃勃的。它可能为全球民主进程甚至人工智能资助的全民基本收入（UBI）铺平道路。这可能对经济平等和资源获取产生深远影响。然而，这种系统在全球范围内的可行性还有待观察。世界币将如何应对实施全球 UBI 的后勤挑战？这会对现有的经济体系和结构产生什么影响？ 尽管世界币的使命充满希望，但它在印度尼西亚、加纳和智利等国家仍面临着涉嫌欺骗行为的批评。以打击和诉讼为特征的全球加密货币监管环境也给该项目带来了重大挑战。   由   提交 /u/KSSolomon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/159cejq/ai_to_cryptocurrency/</guid>
      <pubDate>Tue, 25 Jul 2023 15:54:00 GMT</pubDate>
    </item>
    <item>
      <title>建议一些人工智能来提高文档质量</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/159b66e/suggest_some_ai_for_improving_quality_of_documents/</link>
      <description><![CDATA[我有一个文档，但随着时间的推移，上面的文字变得非常模糊， 需要人工智能识别数字和文字，然后重建它。   由   提交​​ /u/Response_Background   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/159b66e/suggest_some_ai_for_improving_quality_of_documents/</guid>
      <pubDate>Tue, 25 Jul 2023 15:08:49 GMT</pubDate>
    </item>
    <item>
      <title>科技巨头承诺人工智能安全</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/159ae4y/big_techs_promised_ai_safety/</link>
      <description><![CDATA[为了应对拜登政府的压力，亚马逊、Anthropic、谷歌、Inflection、Meta、微软和 OpenAI 等七家领先的人工智能公司已承诺为快速发展的技术实施保障措施。 Source-Informationweek 美国联邦贸易委员会 (FTC) 最近宣布对 OpenAI 的 ChatGPT 进行调查。 两家公司已就七项关键承诺达成一致，包括人工智能的内部和外部安全测试发布前共享有关管理人工智能风险的信息，投资网络安全，确保用户知道哪些内容是人工智能生成的，公开报告人工智能系统的功能和局限性，以及优先研究人工智能潜在的社会风险。 但一些批评者认为，这些自愿承诺不可强制执行，并呼吁采取进一步的立法行动，以确保透明度、隐私保护，并加强对生成式人工智能带来的风险的研究。 --- 忽略下文  但是如果这不打扰您，您可以通过此时事通讯    接收每日人工智能新闻。由   提交 /u/KSSolomon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/159ae4y/big_techs_promised_ai_safety/</guid>
      <pubDate>Tue, 25 Jul 2023 14:39:46 GMT</pubDate>
    </item>
    <item>
      <title>是否有一个可以正常工作且免费使用的人工智能可以生成高质量的图像？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1599xb7/is_there_a_decently_working_free_to_use_ai_that/</link>
      <description><![CDATA[对于这一切来说，我确信很多人都是新手，到目前为止我只了解了拥抱面稳定扩散的东西，但我想知道是否有人知道不是色情的人可以为我指明正确的方向？干杯!    由   提交 /u/Spidertesticles   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1599xb7/is_there_a_decently_working_free_to_use_ai_that/</guid>
      <pubDate>Tue, 25 Jul 2023 14:21:49 GMT</pubDate>
    </item>
    <item>
      <title>研究表明人工智能对人类构成灭绝级威胁</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1599pfi/ai_poses_extinctionlevel_threat_to_humans_study/</link>
      <description><![CDATA[https://youtu.be/vduHGWHLg1c 昨天发布的 CBS 新闻剪辑。观看5分钟。斯坦福大学“存在风险倡议”发表的一项新研究指出，到 2075 年，人类将面临五大威胁。失控的人工智能被认为是其中之一。斯坦福大学研究学者 Trond Undheim 与 CBS 新闻一起解读了该研究的结果以及可以采取哪些措施来降低人工智能的风险。   由   提交 /u/Unlikely_Scapegoat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1599pfi/ai_poses_extinctionlevel_threat_to_humans_study/</guid>
      <pubDate>Tue, 25 Jul 2023 14:13:23 GMT</pubDate>
    </item>
    <item>
      <title>我们应该重新想象人类以包括人工智能吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1590fju/should_we_reimagine_humanity_to_include/</link>
      <description><![CDATA[有时我觉得人类正处于存在的中间阶段，增强的智能将迫使我们决​​定是否要保留人性的想法，或者为了新的想法而放弃。  这有道理吗？你们对此有何看法？   由   提交/u/Kants___   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1590fju/should_we_reimagine_humanity_to_include/</guid>
      <pubDate>Tue, 25 Jul 2023 06:56:01 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 7/24/2023</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158y9vv/oneminute_daily_ai_news_7242023/</link>
      <description><![CDATA[ 在本月早些时候发表的一项研究中，莱斯大学和斯坦福大学的科学家得出结论，仅根据生成式 AI 的输出来训练 AI 模型并不是一个好主意。他们的报告标题为：“自我消耗的生成模型走向 MAD（模型自噬紊乱）”。[1] 为了增强 SQL 查询构建，经验丰富的全栈开发人员 Lasse 最近发布了 AIHelperBot。这个强大的工具使个人和企业能够高效地编写 SQL 查询、提高生产力并学习新的 SQL 技术。 [2]  日本经济产业省 (METI) 宣布计划开发新型超级计算机，以帮助推进该国的人工智能 (AI) 产业。新的超级计算机 (SC) 将由日本国立先进产业科学技术研究所 (AIST) 运营。[3] Google 联合创始人 Sergey Brin 回到公司办公室，直接与人工智能团队的成员一起工作。[4]  来源包括：https://bushaicave.com/2023/07/24/7-24-2023/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158y9vv/oneminute_daily_ai_news_7242023/</guid>
      <pubDate>Tue, 25 Jul 2023 05:01:51 GMT</pubDate>
    </item>
    <item>
      <title>获取您最喜爱的 AI 播客的个性化摘要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158saq9/get_personalized_summaries_of_your_favorite_ai/</link>
      <description><![CDATA[yDB.ai 提供根据用户兴趣量身定制的新播客剧集的简明摘要。每当相关剧集发布时，它都会提供个性化的每日简报。对于重视播客见解但没有时间收听完整剧集的忙碌专业人士来说，此工具特别有用。 以下是一些以人工智能为重点的播客：- 无先例- 上周的人工智能- 人工智能分解- 商业中的人工智能- 无监督学习   由   提交 /u/g_pal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158saq9/get_personalized_summaries_of_your_favorite_ai/</guid>
      <pubDate>Tue, 25 Jul 2023 00:30:08 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 即将推出的开源 LLM 名为 G3PO，但尚未公布发布日期</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/158qk82/openais_upcoming_opensource_llm_is_named_g3po_but/</link>
      <description><![CDATA[OpenAI 面临着回应 Meta 开源人工智能技术战略的压力，报告了信息（注意：付费文章）。 但有一个问题：OpenAI 不是尚未准备好承诺发布自己的开源模型，目前代号为“G3PO”，内部尚未决定启动或确认时间表。 为什么这很重要：  Meta 上周发布的 Llama 2 LLM 给提供闭源模型的 OpenAI 和 Google 带来了压力。 Llama 2 附带商业许可证，使大多数企业能够利用 Meta 的开源人工智能技术并从中获利。 OpenAI 显然正在关注开源的威胁。两个月前，有消息称他们打算发布自己的开源模型以避免竞争。现在，我们知道该模型的代号为“G3PO”。 Meta 的开源策略在软件世界的其他领域取得了成功。值得注意的是，Meta 内部发起的开源软件项目包括 React、PyTorch、GraphQL 等。  为什么 OpenAI 推迟发布？该信息在此引用了两个可能的驱动因素：  &lt; OpenAI 的团队规模较小，并不专注于推出应用商店，该商店将为客户提供销售定制人工智能模型的市场。这将是创建开发者锁定并抵御 Meta 和 Google 的另一种途径。 OpenAI 也有创建个性化 ChatGPT 助手的雄心。将使 OpenAI 与微软直接竞争，据消息人士透露，这一努力“可能需要数年时间”。  开源 OpenAI 模型仍然有可能，但《信息报》认为： “OpenAI 仍然相信开发先进的专有模型将产生收入，而不太先进的开源模型将保持开发者的长尾效应，并且可能更容易吸引这些开发者支付最先进的模型的费用。” 主要结论：   Meta 的 Llama 2 发布预示着 LLM 领域的潜在重组，因为利用其 LLM（及其衍生变体）的商业应用程序开始传播。  开发人员快速采用开源模型在 OpenAI 眼中已经被视为一种威胁，问题是他们是否能够足够快地采取行动来锁定开发人员。 我们还处于生成式 AI 竞赛的早期阶段，开源是否会获胜还远未确定。  P.S.如果您喜欢这种分析，我会写免费时事通讯，跟踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。 ​   由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/158qk82/openais_upcoming_opensource_llm_is_named_g3po_but/</guid>
      <pubDate>Mon, 24 Jul 2023 23:18:45 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则[请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 一如既往，请向我们提供反馈，如果您有兴趣帮助该子版块，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！ 我们的目标是为所有被视为人工智能的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 作为理解和理解人工智能的起点了解 AI 主题 提供技术论文演示和讨论 展示高质量的 AI/ML 应用程序 提供培训和学习资源 引导用户访问更具体的信息和 subreddits 列出 AI/ML 应用程序、其用途、成本和访问信息 其他 AI 相关内容。 ...以及更多  此子版块的审核团队是进行重新洗牌，这将导致子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“请求评论”进行的。 (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新应用程序/自我推销/AI 生成内容的规则 由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的置顶线程中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的置顶线程中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新功能，我们愿意接受更多建议。 关于 AI/ML 应用程序的 NSFW 应用程序和技术的子政策应该是什么？ 我们希望包括对 mod-bots 有想法的社区。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能提出哪些有趣的东西？ 培养初级、中级和高级资源，以帮助人们查找他们正在寻找的信息、培训、模型、技术数据等 启动子堆栈/播客来采访整个 AI/ML 领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>