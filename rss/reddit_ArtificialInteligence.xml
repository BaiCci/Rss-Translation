<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、人工智能在商业中的应用、人工智能如何影响我们的生活、未来可能会发生什么，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sun, 23 Jul 2023 03:16:49 GMT</lastBuildDate>
    <item>
      <title>补充人工智能对齐研究系统的想法：试图关闭自己的人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1570m7a/idea_for_a_supplemental_ai_alignment_research/</link>
      <description><![CDATA[我对于额外的一致 AI 训练模型的一个想法是创建一个严格隔离和受限的关闭子系统，并采取严格的安全预防措施。  该模块将被设计为对可逆关闭不感兴趣，而不是对其错位。除了其狭窄的功能和单向信息流之外，它不会了解任何其他功能。  该模块将从最小的功能开始逐步激活，同时进行广泛的监控。关闭信号将具有冗余的验证机制。保守的奖励模型将用于防止意外的行为激励。  最初将在模拟气隙环境中进行测试。父人工智能系统将通过 RLHF 和宪法人工智能原则等标准对齐技术来开发。多种透明方法将有利于可分析性。  经过模拟测试后，关闭模块可以在持续监督下逐渐暴露于现实世界的激活状态。如果出现任何风险或副作用，它将被停用并重新设计。  一旦主动关闭，将离线分析全面的痕迹，以编录通过其关闭策略发现的对齐漏洞。父系统将与该进程保持隔离。  吸取的经验教训将为对齐技术的迭代改进提供信息，以提高针对潜在解决方法漏洞的鲁棒性。这项目标明确的研究可以补充更广泛的协调工作，同时注意积极最大限度地减少随之而来的风险。  关闭模块需要按照与整个系统相同的安全标准进行设计。模块化设计、不关心关闭、可逆停用、气隙和增量推出等技术都是为了防止意外行为或信息泄漏。 我相信这种方法可以提供有用的见解，但需要在实际激活系统之前首先进行全面的安全实践和预防措施，并进行多次审查和分析，即使是以有限和受限的方式。  欢迎任何批评和分析！抱歉，标题有点标题党的意思。   由   提交/u/RamazanBlack  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1570m7a/idea_for_a_supplemental_ai_alignment_research/</guid>
      <pubDate>Sun, 23 Jul 2023 00:54:41 GMT</pubDate>
    </item>
    <item>
      <title>白宫称亚马逊、谷歌、Meta、微软同意人工智能保障措施</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156zqad/white_house_says_amazon_google_meta_microsoft/</link>
      <description><![CDATA[美国政府最近宣布，它已与大型人工智能公司达成协议，围绕该技术设置更多防护措施，其中包括开发水印系统，以帮助用户识别由人工智能生成的内容人工智能系统。这是监管人工智能的努力的一部分，以防止虚假新闻的传播以及快速发展的技术带来的其他风险。 白宫表示，7家主要人工智能公司还自愿承诺开发测试系统，以在向公众发布之前规范人工智能的安全和能力。这些公司包括：  亚马逊 谷歌 Meta 微软 OpenAI Anthropic Inflection  随着越来越多的机构熟悉这项技术的广泛采用和力量，更需要号召采取行动来监管这项技术。其中许多公司都发布了关于如何努力确保其系统道德标准的声明，但目前尚未制定正式准则。  OpenAI 表示，它与外部专家一起测试了 GPT-4，这些专家试图刺激 GPT-4 生成有害或种族主义内容，然后将其向公众发布。 OpenAI 还在 4 月份推出了一项错误赏金计划，以奖励发现公司系统漏洞的安全研究人员。 Anthropic在学术论文中讨论其安全测试方法，并为用户提供标记有问题的响应的方法。 谷歌今年春天表示，它将在其人工智能模型创建的图像中嵌入数据，以表明它们是合成的。  如果您喜欢此类新闻报道，并希望了解人工智能和技术的最新新闻，请考虑注册 免费新闻通讯（链接）。   由   提交/u/nerdninja08  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156zqad/white_house_says_amazon_google_meta_microsoft/</guid>
      <pubDate>Sun, 23 Jul 2023 00:13:51 GMT</pubDate>
    </item>
    <item>
      <title>“它几乎使我们的工作量增加了一倍”：人工智能应该让工作变得更容易。这些工人不同意。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156umlt/it_almost_doubled_our_workload_ai_is_supposed_to/</link>
      <description><![CDATA[虽然人工智能有望简化工作并提高效率，但一些工人报告工作量增加了一倍，挑战了这项技术的感知优势。 为什么这很重要：  人工智能对工作量的影响可能不会普遍受益 人工智能在工作场所的广告优势与实际体验之间可能存在差异 对比体验结果强调需要批判性地评估人工智能的实施情况  期望与现实：工作量困境  与预期的工作量减少相反，人工智能导致了一些工作量的显着增加，例如 Clarkesworld 杂志的 Neil Clarke 团队。 问题主要是由于人工智能生成的内容提交质量差但数量大，迫使团队手动解析每个内容。 &gt;  人工智能的影响因行业而异  虽然技术领导者将人工智能视为提高生产力的工具，但工人的现实往往有所不同，特别是对于非人工智能专家和非管理人员来说，他们报告人工智能采用后工作强度增加。 媒体行业的经验凸显了人工智能采用的混合结果，事实证明人工智能对某些任务很有用，但在其他情况下会产生额外的工作，特别是当它生成需要广泛审查和纠正的内容时。   寻找解决方案：未来的挑战  一些人正在转向人工智能来解决人工智能产生的问题，例如使用人工智能驱动的探测器来过滤人工智能生成的内容。 然而，这些工具目前被证明是不可靠的，导致误报和误报，从而增加而不是减少工作量。 这凸显了需要更细致、更有效的人工智能解决方案，考虑到考虑不同行业工人的不同经历和需求。  来源 (CNN)  PS: 我运行一个机器学习驱动的新闻聚合器，它总结了来自 50 多家媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156umlt/it_almost_doubled_our_workload_ai_is_supposed_to/</guid>
      <pubDate>Sat, 22 Jul 2023 20:38:42 GMT</pubDate>
    </item>
    <item>
      <title>我是一名语言学家，我想攻读人工智能硕士学位，有什么建议吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156u02p/im_a_linguist_and_i_would_like_to_study_a_masters/</link>
      <description><![CDATA[所以我 (24m) 是一名语言学家和会议口译员。我最近决定继续学业并攻读硕士学位，这将使我在市场上占据一席之地，或者至少专业化一点。所以，基本上，就是拓宽我的选择范围，让我的个人资料令人满意。 我在攻读学位时一直想学习一些与人工智能相关的东西，但当时它还没有那么受欢迎，而且没有太多选择。有人有什么建议/建议吗？我的国家提供的学位非常有限，所以我只是好奇你们中的一个人是否可以推荐这一领域的优秀硕士学位。我理想地想要一门强调语言学的课程，这样它会更适合我的个人资料。谢谢！！   由   提交 /u/CuratusDefixus   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156u02p/im_a_linguist_and_i_would_like_to_study_a_masters/</guid>
      <pubDate>Sat, 22 Jul 2023 20:12:26 GMT</pubDate>
    </item>
    <item>
      <title>人工智能。创造者。创建。谁控制谁？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156tm62/ai_creator_creation_who_controls_who/</link>
      <description><![CDATA[我最近制作了一部关于人工智能的发人深省的电影。 https://youtu.be/ffa0bS8taZs 随着 GPT-4 等技术所体现的人工智能的快速进步，继续重塑我们的世界并重新定义就业市场，我的电影深入探讨了人类及其创造物之间的复杂关系。在这个独特的人工智能传奇故事中，我们探索了创造一个能够超越其创造者的先进人工智能 Ava 的不可预见的后果。这是对人工智能潜在影响的一次激动人心、发人深省的探索，引发了我们与这些数字实体关于未来的对话。   由   提交 /u/blakeridder   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156tm62/ai_creator_creation_who_controls_who/</guid>
      <pubDate>Sat, 22 Jul 2023 19:56:52 GMT</pubDate>
    </item>
    <item>
      <title>我对意识的看法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156t3ly/my_take_on_consciousness/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156t3ly/my_take_on_consciousness/</guid>
      <pubDate>Sat, 22 Jul 2023 19:35:38 GMT</pubDate>
    </item>
    <item>
      <title>格莱美奖将允许人工智能“辅助”歌曲获得未来的格莱美提名</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156p439/the_grammys_will_allow_ai_assisted_songs_for/</link>
      <description><![CDATA[今天， 录音学院首席执行官确认了允许人工智能辅助音乐获得 2024 年格莱美提名的决定。即使在人工智能抢走工作方面好莱坞也面临着这样的麻烦。 原因是什么？ 格莱美希望保持技术领先，但这可能会适得其反。 格莱美更新允许人工智能协作的规则：  部分由人工智能工具贡献的歌曲现在有资格获得提名，但纯粹由人工智能创作的音乐仍然不符合资格。 人类创造力必须在任何提交的创作过程中发挥实质性和有意义的作用。 录音学院正在探索检测合格歌曲中人工智能工具使用情况的方法。  对人工智能采用的行业强烈反对的回应：  其他娱乐联盟，如 SAG-AFTRA ，对人工智能和自动化影响的担忧表示担忧。 但格莱美奖相信，如果使用得当，人工智能可以在增强人类创造力方面发挥作用。 公平的补偿仍然需要对人工智能的使用进行适当的归因和批准。  关于人工智能在音乐中的地位的持续争论：  格莱美奖表示，他们将逐年监测人工智能合作对音乐的影响。 他们对未来调整提名规则持开放态度如果人工智能的参与被证明存在问题。 目前，重点仍然是庆祝人类创造力、原创性和表达方面的卓越表现。  TL;DR 尽管好莱坞对人工智能发起了攻击，格莱美奖仍将允许人工智能辅助的歌曲有资格获得 2024 年提名。但纯粹由人工智能创作的音乐仍然达不到资格。录音学院目前支持这一决定，但正在研究人工智能检测和监控的影响。他们的目标是平衡创新和创造性的人类表达。 P.S. 通过加入增长最快的 AI 时事通讯之一，您可以在 3 分钟内获得有关 AI 的更多知识。加入我们由来自 Open AI、Google、Meta 等的 1000 名专业人士组成的大家庭。   由   提交 /u/Ok-Feeling-1743   [链接]  2； [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156p439/the_grammys_will_allow_ai_assisted_songs_for/</guid>
      <pubDate>Sat, 22 Jul 2023 16:51:06 GMT</pubDate>
    </item>
    <item>
      <title>Shopify员工违反保密协议，揭露公司秘密使用AI取代下岗员工！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156m9fo/shopify_employee_violates_nda_to_reveal_company/</link>
      <description><![CDATA[https://thedeepdive.ca/shopify-employee-breaks-nda-to-reveal-firm-quietly-replacing-laid-off-work ers-with-ai/   由   提交/u/GaindDho   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156m9fo/shopify_employee_violates_nda_to_reveal_company/</guid>
      <pubDate>Sat, 22 Jul 2023 14:56:28 GMT</pubDate>
    </item>
    <item>
      <title>如何仅用 6 行代码克隆任何人的声音。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156kddi/how_to_clone_anyones_voice_in_just_6_lines_of_code/</link>
      <description><![CDATA[ 由   提交 /u/Albininlp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156kddi/how_to_clone_anyones_voice_in_just_6_lines_of_code/</guid>
      <pubDate>Sat, 22 Jul 2023 13:36:48 GMT</pubDate>
    </item>
    <item>
      <title>建筑行业中的人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156juon/ai_in_construction_trades/</link>
      <description><![CDATA[我是一家小公司的水管工，一直关注人工智能开发一段时间，并使用 chatgpt 来做一些事情。但我的问题是，是否有人知道它被用于估算或材料起飞？我希望能够上传一组打印件，并让人工智能提供材料清单、工时等。现在对我来说估算是一个乏味的过程，而且经常有很大的出错空间。如果我们还没有做到这一点，那么在不久的将来会出现这种情况吗？感谢您提供的任何意见   由   提交/u/propane16  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156juon/ai_in_construction_trades/</guid>
      <pubDate>Sat, 22 Jul 2023 13:13:17 GMT</pubDate>
    </item>
    <item>
      <title>演员谴责人工智能生成的“合成”演员的“生存危机”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156iiwx/actors_decry_existential_crisis_over_aigenerated/</link>
      <description><![CDATA[好莱坞演员和电影制作人在 2023 年面临着一个有争议的问题：人工智能在电影行业的崛起。随着人工智能技术有可能创造出可能取代人类演员的合成演员，人们对工作保障和艺术真实性的担忧日益增加。 为什么这很重要：  人工智能在电影行业中的潜在作用可能会极大地改变电影的制作方式以及其中的明星（或哪些）。 演员和工会代表担心人工智能可能会使人类演员变得多余。 这场冲突标志着双方之间持续关系的一个重大转折点。技术和艺术。  罢工：  好莱坞电影公司和 SAG-AFTRA 工会正在讨论人工智能在电影和电视中的作用。  对人工智能使用缺乏共识是工会与作家协会共同发起罢工的催化剂。 这是这些团体在六十多年来的首次同时罢工。  对合成表演者或“超人类”的恐惧是演员们最关心的问题。  人们担心人工智能生成的演员会接管他们的角色。 演员寻求关于人工智能使用的明确条款，以确保他们的生计和艺术职业的未来。   合同谈判中的人工智能：  根据演员的图像创建合成演员是一个关键问题。  制片厂尚未这样做，但希望在合同谈判中保留这一权利。  SAG-AFTRA 的首席谈判代表邓肯·克拉布特里-爱尔兰 (Duncan Crabtree-Ireland) 称人工智能是一场“生存危机”。  人们对使用演员过去、现在和未来的作品感到担忧 工会正在寻求在任何基于人工智能的演员选角之前进行咨询和批准。  电影和电视制片人声称已经解决了这些问题。  但是，工会尚未回应他们的提议。   数字复制品：  另一个争论的焦点是背景演员的数字复制品的创建。  制片厂表示，他们将与演员就数字复制品的使用付费问题进行协商。 演员的虚拟版本无法替代美国演员工会要求的最低背景演员数量。  工会认为同意要求反对额外补偿。  它担心制片厂可能会向演员施压，迫使他们给予同意，否则将面临被替换。 &gt;   所有权和变更：  人们担心工作室保留未来作品的数字复制品的权利。  这可以有效地赋予他们虚拟角色的所有权。  工作室还希望在后期制作中以数字方式改变表演。  变化可能包括子项目制定对话或进行数字服装改变。 工会将此解释为人工智能的过度扩张，并要求对演员的形象、肖像或声音进行任何改变都要寻求许可。   主要结论：  这场冲突标志着技术与艺术之间关系的转折点，有可能重新定义人类演员和数字技术在电影和电视制作中的角色。 正在进行的辩论和罢工凸显了在电影中使用人工智能的明确指导方针和法规的必要性，解决对工作保障、艺术真实性和道德考虑的担忧。  来源（路透社） PS ：我运行一个ML驱动的新闻聚合器，它总结了来自50+媒体（TheVerge、TechCrunch…）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156iiwx/actors_decry_existential_crisis_over_aigenerated/</guid>
      <pubDate>Sat, 22 Jul 2023 12:12:24 GMT</pubDate>
    </item>
    <item>
      <title>克里斯托弗·诺兰表示人工智能创造者正面临“奥本海默时刻”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/156esu8/christopher_nolan_says_ai_creators_are_facing/</link>
      <description><![CDATA[克里斯托弗·诺兰的新片《奥本海默》罗伯特·奥本海默在开发原子弹时面临的道德问题与当前围绕人工智能的挑战相似。导演和专家将创造强大人工智能技术的困境以及潜在的意想不到的后果与奥本海默的历史处境进行了比较。 原子弹和人工智能：   诺兰表示，领先的人工智能研究人员将当前形势称为“奥本海默时刻”，这与奥本海默在开发原子弹时面临的道德问题相似。 理论物理学家Carlo Rovelli 补充道，这些伦理问题不仅适用于过去，而且也是“当今的紧迫问题”。 随着人工智能的快速发展，人们越来越担心人工智能潜在的武器化，这可能会导致无法控制的自主武器系统。  人工智能和潜在风险：   斯特拉斯堡大学教授 Birgitta Dresp-Langley法国警告称，由于人工智能的进步，可能会出现新型、更先进的大规模杀伤性武器。 其他风险包括环境成本、极端主义意识形态可能增加、成见、诽谤和错误逮捕。一组研究人员在 2021 年的一份报告中强调了这些风险。  人工智能、武器和企业责任：   诺兰强调，随着人工智能和武器之间的关系变得更加密切，企业责任的必要性。 导演将人们在没有充分理解其影响的情况下生产或使用人工智能技术的想法描述为“可怕”。  来源 (NBC) PS： 我运行一个机器学习驱动的新闻聚合器，它总结了来自 50 多家媒体的最佳科技新闻（TheVerge、TechCrunch...）。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/156esu8/christopher_nolan_says_ai_creators_are_facing/</guid>
      <pubDate>Sat, 22 Jul 2023 08:51:56 GMT</pubDate>
    </item>
    <item>
      <title>Google 联合创始人谢尔盖·布林 (Sergey Brin) 重返工作岗位，领导创建 GPT-4 竞争对手</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/155xyb0/google_cofounder_sergey_brin_goes_back_to_work/</link>
      <description><![CDATA[《华尔街日报》透露，Google 联合创始人谢尔盖·布林克 (Sergey Brink) 在 2019 年从日常工​​作中退出，实际上又回到了办公室（注：付费文章） . 原因是什么？他正在推动“双子座”的开发。 Google 对 OpenAI 的 GPT-4 大语言模型的回答。  为什么这很重要：  对落后的担忧显然是首要考虑的：谷歌在其历史的大部分时间里都被认为是科技和人工智能的先驱，消息人士推测布林担心他们最近的失误可能会让他们变得脆弱。 布林将生成人工智能视为科技转型的关键时刻：这足以让他远离其他兴趣并回到日常工作中 速度是 Google 落后的关键：近几个月来 Google 的内部战略重点是快速行动（一些批评者认为可能太快了）以及在广泛的产品中添加人工智能功能。消息人士解释说，布林的参与有助于促进这种速度。  虽然布林没有对这篇文章发表评论，但《华尔街日报》透露他在人工智能社区中非常活跃：  布林参加了 Stable Diffusion 的发布会，表明了他对生成式 AI 的吸引力，因为生成式 AI 已成为主流。 他参加的活动规模为 $10,000 美元。被誉为“AGI House”的68M加州豪宅，与AI精英互动，探讨AI未来。   这标志着布林早期信念的转变：   早些时候，布林“对他们能否破解人工智能表示怀疑”， 《华尔街日报》报道称，他“忽视了大脑团队的工作”他最初帮助启动的。  在过去的五年里，随着人工智能研究的兴起，他的思维方式也发生了变化（Google 的 Transformer 论文于 2017 年发表）  主要收获：  创始人回到自己的公司通常可以注入新的紧迫感和使命感。最著名的例子可能是史蒂夫·乔布斯如何重振苹果。 虽然 Google 赢了&#39;不要公开说出来，他们很可能将这一时刻视为一场生存危机。所有内部信号（“红色代码”备忘录、布林的参与、人工智能保障措施的放弃）都表明他们正在重新调整方向，以便在此快速行动。 最终结果如何尚不得而知。谷歌仍在追赶，也面临着开源人工智能的威胁（谷歌的PaLM 2仍然是闭源的） ）。  P.S.如果您喜欢这种分析，我会写免费时事通讯，跟踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。 ​   由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/155xyb0/google_cofounder_sergey_brin_goes_back_to_work/</guid>
      <pubDate>Fri, 21 Jul 2023 19:41:16 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则[请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 一如既往，请向我们提供反馈，如果您有兴趣帮助该子版块，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！ 我们的目标是为所有被视为人工智能的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 作为理解和理解人工智能的起点了解 AI 主题 提供技术论文演示和讨论 展示高质量的 AI/ML 应用程序 提供培训和学习资源 引导用户访问更具体的信息和 subreddits 列出 AI/ML 应用程序、其用途、成本和访问信息 其他 AI 相关内容。 ...以及更多  此子版块的审核团队是进行重新洗牌，这将导致子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“请求评论”进行的。 (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新应用程序/自我推销/AI 生成内容的规则 由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的置顶线程中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的置顶线程中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新功能，我们愿意接受更多建议。 关于 AI/ML 应用程序的 NSFW 应用程序和技术的子政策应该是什么？ 我们希望包括对 mod-bots 有想法的社区。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能提出哪些有趣的东西？ 培养初级、中级和高级资源，以帮助人们查找他们正在寻找的信息、培训、模型、技术数据等 启动子堆栈/播客来采访整个 AI/ML 领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>