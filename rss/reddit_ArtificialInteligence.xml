<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能会怎样，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 04 Jul 2023 03:29:43 GMT</lastBuildDate>
    <item>
      <title>科技公司挑战欧盟法案，声称该法案可能会阻碍创新</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14q3k6i/tech_companies_challenge_eu_act_claiming_it_could/</link>
      <description><![CDATA[这里有一些您可能会感兴趣的事情 - 来自雷诺、喜力、空客和西门子等一些重量级欧洲公司的 150 多名高管正在表明立场反对欧盟最近批准的人工智能法案。  他们都签署了一封致欧洲议会、委员会和成员国的公开信，认为该法案可能对“欧洲的竞争力和技术主权”构成严重威胁。  经过两年的制定，《人工智能法案》草案于6月14日获得批准。它的范围相当广泛，甚至包括针对大型语言模型 (LLM) 和基础模型等较新人工智能技术的法规 - 想想 OpenAI 的 GPT-4。 这些公司担心该法案目前的形式可能会扼杀创新并破坏欧洲的科技雄心。 他们认为这些规则过于严格，将使欧洲公司很难在人工智能技术领域处于领先地位。 主要的担忧之一是生成式人工智能系统的规则，该系统是一种属于“基础模型”的人工智能类型。类别。根据该法案，这些人工智能提供商必须在欧盟注册其产品，接受风险评估，并满足透明度要求，例如公开披露用于训练其模型的受版权保护的数据。  高管们认为，这些要求可能会给公司带来巨大的合规成本和责任风险，并有可能将他们吓出欧洲市场。 他们呼吁欧盟放宽这些规则，更多地关注基于风险的方法。 Jeannette zu Fürstenberg，La Famiglia VC 的创始合伙人、签署人之一对此非常直言不讳，称该法案可能“对欧洲竞争力产生灾难性影响”。有人担心该法案可能会阻碍欧洲当前科技人才的繁荣。  当然，也有阻力。 Dragoş Tudorache 在《人工智能法案》的制定中发挥了重要作用，他坚称该法案旨在促进透明度和标准，同时为行业提供一席之地。他对高管们的立场也不太印象深刻。 这是一个棘手的情况。  来源。  如果您喜欢研究此类内容，我有一个免费时事通讯，我可以在其中发送此类更新以及更多内容。如果您有兴趣，请在这里订阅。非常感谢！   由   提交 /u/spotlightai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14q3k6i/tech_companies_challenge_eu_act_claiming_it_could/</guid>
      <pubDate>Tue, 04 Jul 2023 03:28:53 GMT</pubDate>
    </item>
    <item>
      <title>我们可以使用可以读取图像的法学硕士来编写 Rongorongo 吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14q3ja9/can_we_codify_rongorongo_using_an_llm_that_can/</link>
      <description><![CDATA[为了翻译 Rongorongo，第一步是将其编码：为字形分配代码。 我们正在努力由各方来做到这一点 - C.E.I.P.P.以及我之前在 r/Rongorongo 上提到过的其他人，但那是以前的事了。现在，A.I.可以阅读图片和文字，而且这些大型语言模型似乎是为这项任务量身定做的。 那么怎么样？我们能否按顺序提供 15,000 个字形图像，按平板电脑和侧面分开，并找到比 Barthel 和 Fischer 之前的原始尝试更好的字形代码索引？ ​   由   提交/u/arthurjeremypearson   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14q3ja9/can_we_codify_rongorongo_using_an_llm_that_can/</guid>
      <pubDate>Tue, 04 Jul 2023 03:27:36 GMT</pubDate>
    </item>
    <item>
      <title>开源 OpenAI 兼容替代方案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14q2bif/open_source_openai_compatible_alternative/</link>
      <description><![CDATA[我是开源的Text-Generator.io&lt; br /&gt; github.com/TextGeneratorio/text-generator.io 它的API 与 OpenAI 兼容，因此可以作为替代品（简单的一个）行更改） 文本生成器自动提取并理解链接、图像（OCR/字幕）还可以通过耳语将语音转换为文本，并生成任何语言的高质量文本、语音和代码。&lt; br /&gt; 文本生成器还具有批量文本生成 UI。 嵌入 API 支持在同一向量空间中嵌入图像链接文本和代码，这有助于创建 AI 搜索应用程序。  文本生成器包含未经过滤的 AI 聊天模型 text-generator.io/blog/ new-unfiltered-chat-gpt-model 为 netwrck.com  One 等网站提供支持它的独特之处在于，它会根据跨模型输入的复杂性进行基准测试，自动选择最佳模型，加载最佳的 7B 参数模型，使其能够在消费级 24GB VRAM GPU 上运行，达到不同寻常的质量。它还支持人工智能自动完成/代码自动完成，没有子标记化问题（为此使用 min_probability 设置）。  热衷于帮助每个人在此基础上继续发展。让我知道您的想法！    由   提交 /u/leepenkman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14q2bif/open_source_openai_compatible_alternative/</guid>
      <pubDate>Tue, 04 Jul 2023 02:28:39 GMT</pubDate>
    </item>
    <item>
      <title>越南采取积极主动的方式监管社交媒体内容，以遏制虚假信息的传播。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14q18s4/vietnam_taking_a_proactive_approach_in_regulating/</link>
      <description><![CDATA[来源 越南首次向国际社交媒体平台发出公开诉求，包括Facebook、YouTube 和 TikTok，实施人工智能算法来自动识别和消除“有毒”内容，例如攻击性材料、虚假信息和反对国家的内容。 合规的时间表和流程尚未明确。这与东南亚国家建立人工智能治理和道德准则的努力以及越南自己打击虚假信息的措施不谋而合，其中包括迫使外国科技公司在当地设立办事处并在当地存储数据。 &lt; strong&gt;据报道，Netflix 已采取措施设立当地办事处，对 TikTok 在越南业务的初步检查发现了几起违规行为。 我的想法是 鉴于动机，越南似乎正在采取积极主动的方式监管社交媒体内容，以遏制虚假信息的传播。 对人工智能系统的需求不仅是展示了对技术在管理在线平台中的作用的认识，同时也对主要科技公司遵守国家法规提出了期望。 打击虚假信息的斗争很重要，但必须与保护信息相平衡言论自由。这是一个复杂的问题，因为定义什么构成“虚假信息”或“有毒”内容可能是主观的并且取决于上下文。  虽然人工智能有潜力成为内容审核的强大工具，因为它能够快速处理大量数据。 考虑透明度也很重要和上诉程序。如果人工智能正在对哪些内容“有毒”做出决定，用户应该清楚地了解这些决定，并在他们认为这些决定不正确时提出质疑。 这在我的时事通讯上进行了深入介绍 查看最新的人工智能职位、免费的人工智能工具、跳过等待名单、免费优惠券等等。   由   提交 /u/KSSolomon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14q18s4/vietnam_taking_a_proactive_approach_in_regulating/</guid>
      <pubDate>Tue, 04 Jul 2023 01:37:20 GMT</pubDate>
    </item>
    <item>
      <title>有人注意到 gpt-4 被削弱了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14q039s/anyone_notice_gpt4_has_been_nerfed/</link>
      <description><![CDATA[我最近尝试使用几周前使用的相同短语生成 dnd 会话，但 Bing 似乎只在互联网上搜索，即使设置为有创造力的。在详细介绍船舶构成、具有个性的军官名单、我属于哪个派系以及有关环境的详细信息之前。现在如果你还能让它做到这一点那就太糟糕了。给出了什么？   由   提交/u/camtimono  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14q039s/anyone_notice_gpt4_has_been_nerfed/</guid>
      <pubDate>Tue, 04 Jul 2023 00:41:53 GMT</pubDate>
    </item>
    <item>
      <title>疯狂使用无限数据库。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14py8kb/wild_use_of_infinite_databases/</link>
      <description><![CDATA[我使用模糊逻辑、反向传播和具有梯度下降函数的神经网络构建了一个人工智能。这是在法学硕士之前的日子（1990 年代末）。这一切都是高度数学化的，综合数据集和规则库是一体的。我们使用合成数据和经验数据来训练模型，并遵循严格的程序，以使表面尽可能光滑和同心。当系统“处于野外”状态后，在一段时间内，我们回收了所有过滤后的经验数据，惩罚或奖励值在零到一之间。当时，这是一个简单的专家系统，使用数据范围（通过 C++ 转换为语言输出）。换句话说，语言对系统没有任何意义，也没有连接到任何重要的数据库。因此，它有点愚蠢，但效果很好。  今天的模型有很大不同。法学硕士能够理解语言并根据需要分配算法值。但是 ChatGPT 无法访问网络上漫游的庞大数据库。或者至少他们公开宣称。可能有一些模型可以，但我对这些实体一无所知。  谁能讨论一下，如果人工智能能够完全访问它能理解的绝大多数数据库，我们会期望什么样的范式？当我们这样做时，给它完整的 Imdb、YouTube、Facebook 和其他库。人工智能创造者害怕这种做法吗？如果是这样，为什么？   由   提交/u/1Simplemind   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14py8kb/wild_use_of_infinite_databases/</guid>
      <pubDate>Mon, 03 Jul 2023 23:18:30 GMT</pubDate>
    </item>
    <item>
      <title>“谷歌表示，它将抓取你在网上发布的所有内容以供人工智能使用”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14pvxyj/google_says_itll_scrape_everything_you_post/</link>
      <description><![CDATA[Google 的政策更新明确允许他们抓取几乎所有在线发布的数据，以开发和改进他们的 AI 工具。他们更新了该政策引用了使用公共信息来训练人工智能模型并开发谷歌翻译和云人工智能功能等产品。  语言更改指定了“人工智能模型”而不是之前在旧政策中使用的“语言模型”。 新政策不仅包括 Google 翻译，还提到了 Bard 和 Cloud AI。 这是一个不常见的做法隐私政策条款，通常描述公司自有服务上发布的信息的使用。  对隐私和数据使用的影响：这一变化引发了新的隐私问题，需要改变我们对在线活动的看法。不再仅仅关乎谁可以看到信息，还关乎如何使用信息。这引发了有关 Bard 和 ChatGPT 等聊天机器人如何使用公开信息、可能复制或转换旧博客文章或评论中的文字的问题。 潜在的法律问题和影响：人工智能系统使用公开信息的法律不确定性。谷歌和 OpenAI 等公司已经抓取了互联网的大部分内容来训练他们的人工智能模型，这引发了有关知识产权的问题。在接下来的几年里，法院可能不得不解决这些以前未探讨过的版权问题。 对用户体验和服务提供商的影响：埃隆·马斯克将几起 Twitter 事故归咎于必要性为了防止数据被抓取，大多数 IT 专家声称这更多地与技术或管理故障有关。在 Reddit 上，API 的变化引起了网站志愿者版主的强烈反对。这引发了一场大规模抗议，导致 Reddit 的大部分内容被关闭，如果心怀不满的版主决定下台，可能会导致持久的变化。  来源 (Gizmodo)&lt; /p&gt; PS： 我运行一个 ML 驱动的新闻聚合器，它用  进行总结AI 来自 50 多家媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Super-Waltz-5676   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14pvxyj/google_says_itll_scrape_everything_you_post/</guid>
      <pubDate>Mon, 03 Jul 2023 21:46:56 GMT</pubDate>
    </item>
    <item>
      <title>“人工智能模型只花了五个小时就设计出了一台功能计算机”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14puyyb/it_only_took_five_hours_for_an_ai_model_to_design/</link>
      <description><![CDATA[研究人员开发了一种人工智能模型，能够在不到五个小时内创建一个功能性 CPU，有望通过加快设计过程并提高设计效率来彻底改变半导体行业。效率更高。 CPU 设计创新：已经开发出一种人工智能模型，可以在大约五个小时内设计出一个正常运行的 CPU。这一成就与通常需要数年时间的手动过程形成鲜明对比。  由 19 名中国计算机处理器研究人员组成的小组在一篇研究论文中介绍了这项创新。 他们提出，他们的方法可能会导致自我进化机器的开发以及传统 CPU 设计流程的重大转变。  RISC-V 32IA 和 Linux 兼容性：AI设计的CPU采用RISC-V 32IA人工智能指令集，可成功运行Linux操作系统（内核5.15）。  研究人员报告称，该CPU的性能为与 1991 年人类设计的 Intel 80486SX CPU 相媲美。 研究人员的目标不仅仅是超越最新人类设计的 CPU 的性能，还要塑造计算的未来。&lt; /li&gt;  人工智能设计流程的效率和准确性：人工智能驱动的设计流程被发现比传统的人工设计流程更加高效和准确。   人工智能设计方法将设计周期缩短约1000倍，消除了通常消耗60-80%设计时间和资源的手动编程和验证的需要。 AI 设计的 CPU 在验证测试中显示出 99.99% 的准确率，令人印象深刻。 芯片的物理设计采用 65 纳米技术的脚本，能够创建用于制造的布局。  li&gt;  ​ 来源（Quartz） PS：我运行一个ML驱动的新闻聚合器，使用AI总结来自50+媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Super-Waltz-5676   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14puyyb/it_only_took_five_hours_for_an_ai_model_to_design/</guid>
      <pubDate>Mon, 03 Jul 2023 21:10:30 GMT</pubDate>
    </item>
    <item>
      <title>我认为生成式人工智能就像人类发现了火，但不知道他们可以用它制造蒸汽机。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14ppzgs/i_think_generative_ai_is_like_man_discovering/</link>
      <description><![CDATA[我认为 bard 和 chatGPT 的结果没有区别。这就像火柴与打火机。我认为中间传播和稳定扩散之间没有区别。 我这么说主要是因为它们在输入输出级别上是相同的。我有兴趣看到法学硕士或图像生成软件的实际应用的发展，这些应用不在“内容生成”的镜头下，我认为我们可以使用这些生成模型对社会进行真正的结构性改进。我们目前没有前进，因为我们目前对我们已经制造了“火”的事实感到敬畏。最终，我们有责任摆脱这种反动立场，并利用这些生成模型做实际的事情。我这样说是为了反对目前使用这些模型。即注意力捕获。   由   提交 /u/SikinAyylmao   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14ppzgs/i_think_generative_ai_is_like_man_discovering/</guid>
      <pubDate>Mon, 03 Jul 2023 17:55:15 GMT</pubDate>
    </item>
    <item>
      <title>“演员如何因人工智能而失去声音”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14pnhjd/how_actors_are_losing_their_voices_to_ai/</link>
      <description><![CDATA[英国配音演员 Greg Marston 于 2005 年在不知情的情况下放弃了自己的配音权。这份合同现在允许 IBM 将其配音出售给有能力的第三方使用人工智能克隆它。马斯顿的情况很独特，因为他在同一市场上与人工智能生成的语音克隆竞争。 生成式人工智能的商业化及其影响：生成式人工智能的快速商业化，可以再现类似人类的声音，威胁到依赖其声音的艺术家的职业生涯。这主要是由于潜在的剥削性合同和数据抓取方法造成的。英国表演艺术家工会 Equity 确认已收到多起与人工智能利用和诈骗相关的投诉。 普遍的剥削做法：艺术家经常成为旨在收集信息的欺骗性做法的牺牲品人工智能的语音数据，例如虚假的选角电话。语音工作合同有时包含艺术家可能无法完全理解的隐藏人工智能语音合成条款。 报酬和人工智能权利争论：批评者认为人工智能技术的发展正在引发大量财富从创意行业转移到科技行业。作为回应，Equity 呼吁签订期限有限的合同，并明确要求人工智能克隆获得同意。目前，艺术家可获得的法律追索权有限，只有数据隐私法提供了一些规定。 对在职艺术家的影响：行业的变化使艺术家越来越难以维持他们的事业。为了支持艺术家，Equity 正在推动新的权利并提供资源，帮助他们驾驭不断发展的人工智能领域。  来源 (FT)  PS：我运行一个ML驱动的新闻聚合器，它用AI总结了来自 50 多家媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Super-Waltz-5676   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14pnhjd/how_actors_are_losing_their_voices_to_ai/</guid>
      <pubDate>Mon, 03 Jul 2023 16:18:27 GMT</pubDate>
    </item>
    <item>
      <title>每日两分钟 AI 更新（日期：2023 年 7 月 3 日）：来自 Microsoft、Humane、Nvidia 和 Moonlander 的新闻</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14pkz88/twominutes_daily_ai_update_date_7032023_news_from/</link>
      <description><![CDATA[继续分享人工智能领域当天主要更新的易于理解且较小的版本。   微软使用 ChatGPT 来指导机器人并与机器人交互 - 微软研究院提出了一项使用 OpenAI 的 ChatGPT 进行机器人应用的实验研究。它概述了一种策略，该策略结合了快速工程的设计原则和高级功能库的创建，使 ChatGPT 能够适应不同的机器人任务、模拟器和外形因素。 -该研究涵盖了以下范围内的一系列任务-它还发布了 PromptCraft，一个开源平台，任何人都可以在其中分享机器人应用的良好提示方案的示例。 &lt; li&gt;Magic123 从未摆出的图像创建 HQ 3D 网格 - Snap Inc.（和其他公司）的新研究提出了 Magic123，这是一种新颖的图像到 3D 管道，使用两级粗略- 精细优化流程，可生成高质量高分辨率 3D 几何图形和纹理。它从单个未摆出的图像生成逼真的 3D 对象。 Microsoft CoDi 通过可组合扩散实现任意生成 - Microsoft 推出了 CoDi，一种新颖的能够跨多种模式处理并同时生成内容的生成模型。它可以处理多对多生成策略，同时生成输出模态和单对单模态生成的任意混合。 Humane 公布了其第一款设备的名称：Humane Ai Pin  - 它是一款带有软件平台的独立设备，可利用人工智能的力量来实现创新的个人计算体验。 微软通过 Bing 推出 Windows Copilot 预览版聊天 - 微软正在让早期用户抢先体验 Windows 11 的 AI 助手。该程序作为 Windows Insider 开发频道更新的一部分提供。 &lt; Nvidia 收购了一家缩小 ML 模型的 AI 初创公司 - Nvidia 在 2 月份悄悄收购了已有两年历史的 OmniML，后者的软件帮助缩小了机器学习模型，以便它们可以在设备上运行，而不是在计算机上运行。  Moonlander 推出基于人工智能的沉浸式 3D 游戏开发平台 - 该平台利用更新的法学硕士、机器学习算法和生成扩散模型来简化游戏开发管道。目标是让开发人员能够轻松设计和生成高质量的沉浸式体验、3D 环境、机制和动画。它包括“text-2-game”功能。  这些新闻和创新的更详细分类请参见 每日新闻通讯。    由   提交 /u/RohitAkki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14pkz88/twominutes_daily_ai_update_date_7032023_news_from/</guid>
      <pubDate>Mon, 03 Jul 2023 14:42:37 GMT</pubDate>
    </item>
    <item>
      <title>“对人工智能风险过度炒作的恐慌可能会导致错误的监管”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14pkcyf/panic_about_overhyped_ai_risk_could_lead_to_the/</link>
      <description><![CDATA[人工智能叙事的传播通常受到兴趣、无知和机会主义的推动，可能会造成错误信息的风暴。这可能涉及：  夸大其词，分散了解决人工智能风险的政策制定的注意力。 将人工智能与核武器等高破坏性技术进行不准确的比较。 &lt; li&gt;忽视了对彻底禁令进行仔细监管的重要性。  人工智能与核武器：人工智能和核武器虽然都是重要的，但本质上是不同的：  核武器是一种特定的破坏性技术，而人工智能的应用范围广泛。 核武器完全由民族国家控制，而人工智能可以由私人公民使用. 因此，这两种技术的监管方法存在显着差异。 将人工智能比作核武器可能会导致不准确的监管建议。   灭绝级风险问题：将人工智能强调为灭绝级威胁可能会破坏有关人工智能治理的富有成效的对话：  讨论应集中在网络攻击等更可能的风险上、虚假信息活动或恶意行为者的滥用。 将人工智能标记为“灭绝级别”。威胁助长了危言耸听，而不是解决这些挑战。  对人工智能安全“曼哈顿项目”的误导性呼吁：呼吁开展大型政府项目来解决这些问题人工智能安全误解了这个问题：  人工智能安全涵盖了广泛的概念，需要细致入微的方法而不是单一目标。 研究人员对人工智能安全定义存在不同意见各种方法都需要认真讨论和探索。 政府支持的大型项目无法提供所需的探索自由。  来源（Vox） PS： 我运行一个 ML 驱动的新闻聚合器，它用 &lt; strong&gt;AI 来自 50 多家媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Super-Waltz-5676   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14pkcyf/panic_about_overhyped_ai_risk_could_lead_to_the/</guid>
      <pubDate>Mon, 03 Jul 2023 14:19:21 GMT</pubDate>
    </item>
    <item>
      <title>“Will.i.am 称赞人工智能技术是音乐领域的‘新文艺复兴’”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14peze0/william_hails_ai_technology_as_new_renaissance_in/</link>
      <description><![CDATA[在最近的一次采访中， Will.i.am 将 AI 视为一种音乐行业的革命性工具。他相信人工智能可以创作出独特且令人印象深刻的歌曲，同时也对人工智能模仿人类创造力相关的版权问题表示担忧。 Will.i.am 的对音乐中人工智能的乐观态度：Will.i.am 将人工智能视为音乐领域的新曙光，能够生成模仿他风格的独特作品。他相信这项技术将能够创造出吸引人的音乐，同时反映社会评论，他认为这是歌曲中理想的属性。  他谈到了他使用人工智能创作新歌曲的个人经验。&lt; /li&gt; 他提到人工智能有能力创造自己版本的流行歌曲，例如“Boom Boom Pow”。  对人工智能模仿和版权的担忧 ：尽管 Will.i.am 很兴奋，但他还是对人工智能模仿人类创造力的法律影响表示担忧。他强调人工智能需要制定法规和指导方针，特别是在拥有自己的肖像方面。  他指出，虽然人工智能可以模仿，但对于谁拥有最终的作品并没有明确的规则。  建立这些规则和边界的责任在于人类，而不是人工智能。  ​ 来源（标准晚报） PS：我运行一个ML驱动的新闻聚合器，它总结了AI 来自 50 多家媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Super-Waltz-5676   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14peze0/william_hails_ai_technology_as_new_renaissance_in/</guid>
      <pubDate>Mon, 03 Jul 2023 10:14:07 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则[请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行一项民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 作为请始终向我们提供反馈，如果您有兴趣帮助该子项目，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！&lt; /p&gt; 我们的目标是为所有与人工智能有关的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 服务作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用 提供培训和学习资源&lt; /li&gt; 引导用户访问更具体的信息和子版块 列出 AI/ML 应用程序、其用途、成本和访问信息 其他与 AI 相关的内容。  li&gt; ...以及更多  该子项目的审核团队正在进行重组，这将导致该子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“Request-For-”评论” (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新申请/自我推销/AI 生成的规则content  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的粘帖中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的粘帖中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新的功能，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们会喜欢将社区纳入模组机器人的想法中。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能想出哪些有趣的东西？ 培养初级、中级和高级资源来帮助人们查找信息，他们正在寻找的培训、模型、技术数据等 启动子堆栈/播客来采访整个人工智能/机器学习领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>