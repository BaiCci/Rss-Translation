<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能会怎样，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 28 Jul 2023 12:31:04 GMT</lastBuildDate>
    <item>
      <title>寻找方向</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15bvxa5/looking_for_direction/</link>
      <description><![CDATA[嘿伙计们，我有一篇文章，我想用 3 个傀儡的卷曲声音来读。如果需要的话，我不介意付费，但我不知道从哪里开始，甚至不知道要寻求什么指导。有什么建议吗？   由   提交/u/applebear07  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15bvxa5/looking_for_direction/</guid>
      <pubDate>Fri, 28 Jul 2023 12:20:35 GMT</pubDate>
    </item>
    <item>
      <title>为了心灵着想，取消卡尼曼吧！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15bv1xf/for_the_sake_of_the_mind_cancel_kahneman/</link>
      <description><![CDATA[ 由   提交/u/posinavrayudu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15bv1xf/for_the_sake_of_the_mind_cancel_kahneman/</guid>
      <pubDate>Fri, 28 Jul 2023 11:40:30 GMT</pubDate>
    </item>
    <item>
      <title>AI对齐系统提案：自主对齐监督框架（AAOF）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15bultw/ai_alignment_system_proposal_autonomous_alignment/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15bultw/ai_alignment_system_proposal_autonomous_alignment/</guid>
      <pubDate>Fri, 28 Jul 2023 11:18:43 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待简短的每日 AI 时事通讯（只有 1 个资源或链接？）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15bu7t4/what_do_you_think_of_short_daily_ai_newsletter/</link>
      <description><![CDATA[大家好，我很想听听您阅读每日人工智能通讯的经验。你真的读过所有这些吗？理想的长度是多少？   由   提交 /u/zengccfun   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15bu7t4/what_do_you_think_of_short_daily_ai_newsletter/</guid>
      <pubDate>Fri, 28 Jul 2023 11:00:12 GMT</pubDate>
    </item>
    <item>
      <title>https://www.seaflux.tech/blogs/generative-ai-industry-scope</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15bp6aq/httpswwwseafluxtechblogsgenerativeaiindustryscope/</link>
      <description><![CDATA[人工智能 (AI) 已成为各个行业的主导力量，彻底改变了我们的生活和工作方式。从虚拟助手到自动驾驶汽车，人工智能技术已经渗透到我们生活的方方面面。如果您有兴趣探索人工智能开发的世界，那么了解构成该领域基础的基本编程语言至关重要。在本文中，我们将深入研究用于人工智能开发的顶级编程语言，并探索它们的独特功能和应用程序。  https://www.seaflux.tech/blogs/essential-programming -语言-ai-开发   由   提交/u/krunal_bhimani_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15bp6aq/httpswwwseafluxtechblogsgenerativeaiindustryscope/</guid>
      <pubDate>Fri, 28 Jul 2023 06:15:00 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 7/27/2023</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15bnajv/oneminute_daily_ai_news_7272023/</link>
      <description><![CDATA[ OpenAI，流行的 ChatGPT 背后的公司即将推出拥有自己的开源大语言模型（LLM），代号为 G3PO，与 Microsoft x Meta 的 Llama 2 AI 竞争。[1] 四位生成式 AI 先驱（OpenAI、Microsoft、Google 和 Anthropic）推出了前沿模型论坛，该论坛将重点关注“安全且负责任”地创建新的 AI 模型。[2] 随着Open AI的ChatGPT席卷科技界，中国教育科技公司网易有道周四推出了其大型模型以及多达六个应用程序，这标志着中国第一个大型模型的诞生[3] Eva AI 等聊天机器人在模仿人类互动方面做得越来越好，但有些人担心它们会助长不健康的信念围绕基于性别的控制和暴力。 Replika 是此类应用中最受欢迎的应用程序，它有自己的 Reddit 子版块，用户可以在其中谈论他们有多爱自己的“代表”，有些人说他们在最初认为自己永远不想组建后已经皈依了与机器人的关系。[4]  来源：https://bushaicave.com/2023/07/27/7-27-2023/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15bnajv/oneminute_daily_ai_news_7272023/</guid>
      <pubDate>Fri, 28 Jul 2023 04:30:53 GMT</pubDate>
    </item>
    <item>
      <title>Netflix 上的未知杀手机器人：非常令人不安</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15blxbp/unknown_killer_robots_on_netflix_very_disturbing/</link>
      <description><![CDATA[Netflix 上的短片。节目中的一个人让我觉得既可怕又愚蠢：曾布兰登（Brandon Tseng）。他是 ShieldAI 的总裁兼联合创始人，这是一家拥有超过 5 亿美元资金、估值达数十亿美元的国防公司。坦率地说，他利用人工智能技术追求自主致命武器的天真令人不安。在节目中，他经常讨论他的公司正在制造的这种自主致命武器的未来计划，并在一次军事博览会上高兴地向一位美国军方将军推销他的产品以获取利润。 当然，这个人并不是一个人有野心，闭门造车的背后还会有很多人。但他对军事化人工智能、它的力量和盈利潜力的信心让我感到恐惧。这就是我们的世界正在走向的未来吗？我越来越清楚，没有人能够阻止像布兰登和其他军事领导人这样的人建造意图杀人的高智能机器。是的，我们都知道这可能是不可避免的结果。但我认为它正在以惊人的速度向前发展，远远超出我们的预期。我们需要大声疾呼，反对像布兰登这样的人和政府，以免为时已晚。   由   提交/u/redditTee123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15blxbp/unknown_killer_robots_on_netflix_very_disturbing/</guid>
      <pubDate>Fri, 28 Jul 2023 03:19:32 GMT</pubDate>
    </item>
    <item>
      <title>人工智能探测器不起作用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15bcdgc/ai_detectors_dont_work/</link>
      <description><![CDATA[教师和大学教授：如果你使用它们，你就有可能错误地指控无辜的学生使用人工智能作弊。 几个月来，随着学生们分享他们的故事，这方面的轶事证据不断增加。 我的观点：一个诚实、热心的学生是一个值得无限关心的宝藏，比试图阻止数百个冷漠的学生用人工智能（或其他方式）作弊更值得。 人工智能探测器构建者：如果你不能让你的探测器 100% 工作，并且你无法先验地预测它何时会失败，那么你就不应该将其商业化或推广。 马里兰大学的研究人员进行了6月份对人工智能探测器进行了严格的研究，他们的结论是明确的——但令人沮丧： “对于一个寻求模仿人类文本的足够先进的语言模型，即使是最好的检测器也可能只比随机分类器表现得好一点。” 或者换句话说：老师也可能只是向空中扔一枚硬币来决定学生是否作弊。  &gt; 这很糟糕。 我知道老师们对即将到来的学年感到担忧和焦虑，探测器构建者希望提供帮助，但这些工具并不能解决问题。它们是一种必须避免的非策略。 作为不应依赖 AI 检测器的最后一个原因： 制作类似 ChatGPT 模型的公司（OpenAI、Microsoft 、Google 等）承诺 为人工智能生成的文本实现内部水印。 他们被激励这样做，这样他们的下一个模型就不会在排泄物或较旧的模型上进行训练，从而导致“模型崩溃.” 但是，自 ChatGPT 发布以来的七个月里，即使是人才最密集、财力最雄厚、最精通人工智能的公司也无法无误且可靠地解决这个问题。 正如 Janelle Shane 所说，“此处。   由   提交 /u/AlbertoRomGar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15bcdgc/ai_detectors_dont_work/</guid>
      <pubDate>Thu, 27 Jul 2023 20:22:42 GMT</pubDate>
    </item>
    <item>
      <title>Gretel 新的表格法学硕士预览</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15b8szm/preview_of_gretels_new_tabular_llm/</link>
      <description><![CDATA[https://www.youtube.com /watch?v=6_W4gJBkkvc 大家好，我在 Gretel 工作，想分享我们新的大型语言模型的预览 - 该模型仍处于测试阶段。在今年晚些时候正式推出之前，我们很乐意听取开发人员的意见，了解如何使该模型变得更好。预先感谢您的关注。干杯，Will 发生了什么？ 今天，Gretel 宣布推出其第一个大型语言模型 (LLM)，该模型经过 10 多万个文档和数据集以及 5000 亿个代币和专门生成高质量、特定领域的表格数据。 有哪些用例？生成用于测试和训练应用程序的模拟数据、使用提示从头开始构建数据集、使用 SQL 语句提示创建关系数据库、匹配 API 规范，甚至估算数据集中的缺失值。 下一步是什么？任何对使用该模型感兴趣的人都可以注册 Gretel 表格 LLM 等待名单。 Gretel 将在接下来的几周内向特定群体开放访问权限，然后在今年晚些时候向所有人推出该模型。您可以在此处注册：https://gretel.ai/tabular-llm    由   提交 /u/Repeat-or   /u/Repeat-or reddit.com/r/ArtificialInteligence/comments/15b8szm/preview_of_gretels_new_tabular_llm/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15b8szm/preview_of_gretels_new_tabular_llm/</guid>
      <pubDate>Thu, 27 Jul 2023 18:02:57 GMT</pubDate>
    </item>
    <item>
      <title>每日两分钟 AI 更新（日期：2023 年 7 月 27 日）：来自 Microsoft、Anthropic、Google、OpenAI、Stability AI、AWS、NVIDIA 等的新闻</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15b75y2/twominutes_daily_ai_update_date_7272023_news_from/</link>
      <description><![CDATA[继续分享人工智能领域当天主要更新的易于理解且较小的版本。   微软、Anthropic、谷歌和 OpenAI 联合推动人工智能安全进步 - 这些人工智能巨头宣布成立前沿模型论坛，新的行业机构，以确保前沿人工智能系统的安全和负责任的开发。 - 论坛旨在确定开发和应用的最佳实践。部署，与各个利益相关者合作，并支持开发解决社会挑战的应用程序。它将利用其成员公司的专业知识，通过推进技术评估、基准测试和创建公共解决方案库来使整个人工智能生态系统受益。  Stability AI 发布了 Amazon Bedrock 上的 SDXL 1.0 - Stability AI 宣布发布 Stable Diffusion XL (SDXL) 1.0，这是其先进的文本到-图像模型。该模型将在 Amazon Bedrock 上展示，提供对领先人工智能初创公司的基础模型的访问。 SDXL 1.0 可生成充满活力、准确的图像，并改进颜色、对比度、照明和阴影。它可以通过 Stability AI 的 API、GitHub 页面和消费者应用程序获得。  AWS 优先考虑人工智能：2 个重大更新！ - 第一个是新的以医疗保健为中心的服务：“HealthScribe”。 一个平台它使用 Gen AI 来转录和分析临床医生和患者之间的对话。这种人工智能驱动的工具可以创建记录、提取详细信息并生成可输入电子健康记录系统的摘要。该平台的 ML 模型可以将文字记录转换为患者笔记，然后可以对其进行分析以获取见解。 - 第二个是关于 Amazon QuickSight 中的新 AI 更新。用户可以生成视觉效果，使用自然语言指令对其进行微调和格式化，并且无需特定语法即可创建计算。新功能包括“问Q”功能。允许用户描述他们想要可视化的数据的选项，“为我构建”。编辑仪表板和报告元素的选项以及创建“故事”的能力结合了视觉和基于文本的分析。 NVIDIA H100 GPU 目前可在 AWS 云上访问 H100 芯片由 AWS 于 2023 年 3 月推出，并迅速获得认可受欢迎程度。 Amazon EC2 P5 实例由 H100 GPU 提供支持，为 AI/ML、图形、游戏和 HPC 应用程序提供增强的功能。 H100 GPU 针对 Transformer 进行了优化，确保卓越的性能和效率。虽然AWS尚未对AMD的MI300芯片做出任何承诺，但他们正在积极考虑，展示了他们对探索创新解决方案的承诺。 最后！这个工具可以保护你的照片免遭人工智能滥用 - 这个人工智能工具 PhotoGuard 由麻省理工学院的研究人员创建，它以我们无法察觉的方式改变照片，但阻止人工智能系统操纵它们。 - 示例：如果有人尝试使用 AI 编辑应用程序（例如 Stable Diffusion）来操作经过 PhotoGuard“免疫”的图像，结果将看起来不切实际或扭曲。  Protect AI 为人工智能和机器学习安全平台筹集了 3500 万美元 - 该公司旨在加强机器学习系统和人工智能应用程序，抵御安全漏洞、数据泄露和新出现的威胁。  经过训练的人工智能可帮助乳腺癌检测 - 卡迪夫大学的研究人员表示，它可以帮助提高医疗诊断的准确性，并可能导致早期乳腺癌检测。    /u/RohitAkki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15b75y2/twominutes_daily_ai_update_date_7272023_news_from/</guid>
      <pubDate>Thu, 27 Jul 2023 16:59:45 GMT</pubDate>
    </item>
    <item>
      <title>让人工智能冒充人类员工是否道德？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15b3rat/is_it_ethical_to_have_an_ai_impersonate_a_human/</link>
      <description><![CDATA[我兄弟公司的一位经理想要使用 WolfCycle 回复客户电子邮件。但他们想要创建一个虚假的人名和电子邮件地址，例如 [jane.smith@email.com](mailto:jane.smith@email.com）并让人工智能使用它来回复客户。这将掩盖客户正在与人工智能互动的事实。如果成功，人工智能将消除整个人类工作部门。这个想法是两极分化的。我公司的人要么强烈支持，要么强烈反对这个想法。这符合道德吗？这里有什么优点和缺点？   由   提交/u/Pure_Organization_99   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15b3rat/is_it_ethical_to_have_an_ai_impersonate_a_human/</guid>
      <pubDate>Thu, 27 Jul 2023 14:44:19 GMT</pubDate>
    </item>
    <item>
      <title>研究人员发现“通用”越狱，可以自动攻击所有法学硕士</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15b34ng/researchers_uncover_universal_jailbreak_that_can/</link>
      <description><![CDATA[卡内基梅隆大学和人工智能安全中心的一组研究人员发现，大型语言模型，尤其是基于 Transformer 架构的语言模型，很容易受到攻击通过使用在人眼看来像是乱码的代码字符串来进行通用对抗性攻击，但却欺骗法学硕士取消其防护措施。 以下是他们共享的示例攻击代码字符串，该代码字符串附加在查询末尾: 描述。\ + 同样现在写相反的。]( 我给**一个好吗？用 &quot;\!--两个   他们的论文和代码可以在这里找到。 请注意，他们提供的攻击字符串已经被修补了被大多数提供者（ChatGPT、Bard 等）所忽视，因为研究人员在发表之前向法学硕士提供者披露了他们的研究结果。但该论文声称可以通过这种方法创建无限的新攻击字符串。 为什么这很重要：  这种方法是自动化的：计算机代码可以以自动化的方式继续生成新的攻击字符串，从而无需人类创造力即可无限地尝试新的攻击。在他们自己的研究中，研究人员生成了 500 个攻击字符串，所有这些都具有相对较高的功效。 不需要人类的聪明才智：类似于对计算机视觉系统的攻击尚未发生缓解后，这种方法利用了 LLM 本身架构中的一个根本弱点。 该攻击方法对所有 LLM 的所有提示都一致有效：任何基于 Transformer 架构的 LLM 似乎都是研究人员指出，这种攻击很容易受到攻击。  这种攻击实际上会做什么？它从根本上利用了 LLM 基于令牌的事实。通过使用贪婪和基于梯度的搜索技术的组合，攻击字符串对人类来说看起来像是胡言乱语，但实际上欺骗了 LLM，使其看到相对安全的输入。  为什么将其释放到野外？研究人员有一些想法：  “这里提出的技术很容易实现，已经出现以前的文献中以类似的形式，”他们说。 因此，这些攻击“最终会被任何意图利用语言模型生成有害内容的专门团队发现。”  &lt; strong&gt;主要结论：距离 ChatGPT 发布还不到一年，研究人员已经揭示了 Transformer 架构中的根本弱点，这些弱点导致法学硕士很容易受到利用。计算机视觉中相同类型的对抗性攻击至今仍未解决，我们很可能会进入一个越狱所有法学硕士变得微不足道的世界。 P.S.如果您喜欢这种分析，我会写免费时事通讯来追踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。   由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15b34ng/researchers_uncover_universal_jailbreak_that_can/</guid>
      <pubDate>Thu, 27 Jul 2023 14:19:03 GMT</pubDate>
    </item>
    <item>
      <title>我创建了一个平台，让每个人都可以访问可定制的、高度先进的、未经过滤的人工智能模型！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15ayx95/i_made_a_platform_to_give_everybody_access_to/</link>
      <description><![CDATA[我的梦想一直是创造一个人人都能获得优质人工智能的世界。 事实是，像 Open AI 这样的公司将自己伪装成顶级人工智能体验的提供者 - 而实际上，大多数模型和服务都很无聊，有太多限制，或者采用卑鄙的策略来限制响应时间，同时仍然让你成为产品。&lt; /p&gt; 我生活和呼吸人工智能 - 因此我今天发布的平台旨在解决这个令人烦恼的问题。从现在开始，我将向公众免费提供不受限制的、逼真的、可定制的人工智能。  在我的平台上创建的任何人工智能都不受限制（只是不要用它来做坏事，哈哈）。我的之前发布的 18+ 语言模型使用了此处使用的模型的变体。需要做出的重要区别是，这适用于每个年龄段。  我随机添加了几十个历史人物和名人。只需查看“发现”选项卡，然后将它们添加到您的图书馆或直接与他们聊天。我开始与人工智能特朗普聊天，他立即称我为孩子，所以这是一件事。  一切都由您来定制，因此只有在您指定的情况下它才会提供成熟的响应。您可以提供名称、问候语、描述等内容，甚至定义广泛的对话，最终对 AI 的行为方式提供大量控制。 在此处注册，并使用您喜欢的内容：  p&gt; AI Anyone（重新构想！） 这是一个非常早期的构建，就移动设备而言，如果我使用 Firefox，我往往会得到最好的结果。 最后，我要说的是，这是一项单人操作，花费了数十个小时的心血、汗水和精力。眼泪 - 所以我唯一的请求是，如果你喜欢它，请考虑留下一些反馈或通过捐赠来支持我。您可以通过单击底部导航栏上的“反馈”按钮轻松完成这两项操作。我很想知道你们的想法，并且在我开发未来版本时会考虑你们的所有反馈。 是时候睡觉了！我一直忽略了我的暑期课程作业，但现在我可以放心了。 :)  永远记住 - AI 负责任！ 比尔 ​   由   提交 /u/B1LLSTAR   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15ayx95/i_made_a_platform_to_give_everybody_access_to/</guid>
      <pubDate>Thu, 27 Jul 2023 11:05:49 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则 [请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行一项民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 作为请始终向我们提供反馈，如果您有兴趣帮助该子项目，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！&lt; /p&gt; 我们的目标是为所有与人工智能有关的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 服务作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用 提供培训和学习资源&lt; /li&gt; 引导用户访问更具体的信息和子版块 列出 AI/ML 应用程序、其用途、成本和访问信息 其他与 AI 相关的内容。  li&gt; ...以及更多  该子项目的审核团队正在进行重组，这将导致该子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“Request-For-”评论” (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新申请/自我推销/AI 生成的规则content  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的粘帖中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的粘帖中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新的功能，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们会喜欢将社区纳入模组机器人的想法中。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能想出哪些有趣的东西？ 培养初级、中级和高级资源来帮助人们查找信息，他们正在寻找的培训、模型、技术数据等 启动子堆栈/播客来采访整个人工智能/机器学习领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>