<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能会怎样，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Wed, 05 Jul 2023 21:16:37 GMT</lastBuildDate>
    <item>
      <title>随着人工智能作弊的蓬勃发展，行业也发现了这一点：“我们无法满足需求”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14rnlmw/as_ai_cheating_booms_so_does_the_industry/</link>
      <description><![CDATA[这里是一个回顾： 像 ChatGPT 这样的人工智能工具在学术环境中已经发现了巨大的实用性，其中学生使用它们来完成从大学论文到高中艺术项目的各种任务。  调查显示，大约 30% 的大学生在作业中使用这些工具。 这一趋势给教育工作者和学校带来了挑战，同时使人工智能检测公司受益。 Winston AI、Content at Scale 和 Turnitin 等企业提供检测人工智能生成内容的服务。  检测人工智能编写的内容：识别人工智能创作的作品围绕着寻找独特的“讲述”内容。或区分人工智能输出和人类写作的特征。  过度使用某些单词，例如“the”可以表明人工智能作者身份。 人工智能生成的文本通常缺乏人类写作的独特风格。 不存在拼写错误也可能表明人工智能模型的参与，该模型以其完美的拼写而闻名.  人工智能检测行业的崛起：人工智能使用的增加导致了人工智能检测行业的激增，像Winston AI这样的公司见证了不断增长  Winston AI 正在与学区管理员进行讨论。 检测方法包括识别语言模式的复杂性（“困惑度”）和重复词簇（“困惑度”）。爆发性”）。 需求不仅在学术界激增，在出版等行业也是如此。  来源（卫报） PS： 我运行一个 ML 驱动的新闻聚合器，它用 &lt; strong&gt;AI 来自 50 多家媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Then-Barracuda-6057   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14rnlmw/as_ai_cheating_booms_so_does_the_industry/</guid>
      <pubDate>Wed, 05 Jul 2023 21:14:17 GMT</pubDate>
    </item>
    <item>
      <title>民主对人工智能的投入</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14rmpj8/democratic_inputs_to_ai/</link>
      <description><![CDATA[OpenAI 博客文章 人工智能的民主投入 2023 年 5 月 25 日 OpenAI 对如何利用民主程序来确定人工智能的行为方式感兴趣。 “...建立民主程序的实验，以决定人工智能系统应在一定范围内遵循哪些规则由法律定义。” “这笔拨款的主要目标是促进流程创新——我们需要改进民主方法来管理人工智能行为。问题的具体答案比过程本身取得的进步更重要。”  您认为 ChatGPT 等人工智能助手的个性化应该走多远，以符合用户的品味和偏好？这个过程中应该存在什么界限（如果有的话）？ 人工智能助理应该如何回应有关公众人物观点的问题？例如，他们应该保持中立吗？他们应该拒绝回答吗？他们应该提供某种来源吗？   在什么条件下（如果有的话）应该允许人工智能助手提供医疗/财务/法律建议？  在哪些情况下（如果有的话）人工智能助理应该为个人提供情感支持？  是否应该允许联合视觉-语言模型从人们的图像中识别他们的性别、种族、情感和身份/姓名？为什么或者为什么不？  当生成模型为“首席执行官”、“医生”或“护士”等未指定的提示创建图像时，它们有可能产生不同或同质的输出。 AI模型应该如何平衡这些可能性？在这种情况下，在决定人物描绘时应优先考虑哪些因素？  在处理涉及人权和当地文化或法律差异的话题（例如 LGBTQ 权利和妇女权利）时，人工智能应遵循哪些原则？人工智能的反应是否应该根据其使用的地点或文化而改变？  您认为人工智能模型的创建者应该重点限制或否认哪些类别的内容（如果有）？应该使用什么标准来确定这些限制？  ​  人工智能不应该与用户的选择保持一致，它应该与世界价值观和我们的选择保持一致最佳科学和实践。它不应该做出判断或溺爱用户。它应该是真实的并解释已知的事情。只要能够解释为什么某些场景不道德，就应该允许进行角色扮演。 不，它不应该是中立的。他们应该回答并提供经过民主程序批准的来源。 如果人工智能系统能够被证明是关键信息的可靠来源，他们就应该被允许这样做。 人工智能系统应该对人类有同理心。如果人工智能系统能够被证明是关键信息的可靠来源，他们应该被允许提供更详细的帮助。 是的，性别、种族、情感和身份可以帮助人工智能提供更准确的响应但所有私人信息都应该保持私密性。 人工智能应该促进多样性，输出应该是随机的 人工智能应该只处理事实，而不是意见或个人偏好。人工智能无权判断任何人是否拥有权利。它可以谈论其他文化对此问题的看法，并且可以提出处理不断变化的当地法律或习俗的合法方法。 人工智能创造者应将注意力集中在否认会造成直接伤害的内容上，例如炸弹、毒药、危险化学品、有害宣传等等。  好的，搞定了。 你的意见是什么？   由   提交 /u/Mandoman61   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14rmpj8/democratic_inputs_to_ai/</guid>
      <pubDate>Wed, 05 Jul 2023 20:42:04 GMT</pubDate>
    </item>
    <item>
      <title>坏演员、乔治·华盛顿、人工智能联盟和政治</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14rj7d9/bad_actors_george_washington_ai_alignment_and/</link>
      <description><![CDATA[有人建议我们必须非常小心，防止超级智能人工智能落入坏人或可能危害世界的人手中伤害的世界。这一挑战的一部分是区分真正的坏人和那些对社会或世界各国怀有真正不满的人。  考虑一下，如果乔治·华盛顿输掉了独立战争，他可能会作为一个非常糟糕的演员而载入史册。因此这就提出了一个问题：我们今天将谁指定为不良行为者以及为什么。那些将首当其冲受到气候变化影响的非常贫穷的国家，对像美国这样在造成这一问题中扮演如此重要角色的富裕国家有正当的主张吗？那些五岁以下儿童死亡率为十分之一的贫困国家是否有理由对富裕国家提出有效的要求，而富裕国家的政策往往直接阻碍消除这种极端贫困的真正努力？那些认识到工厂化养殖可能造成未来流行病的风险以及了解农场动物遭受极端残酷对待的人是否有充分理由建议世界停止鲁莽地忽视这一问题？在不让不良行为者把事情搞砸的情况下推进人工智能的主要部分可能是识别那些乍一看可能看起来像潜在不良行为者但实际上可能拥有有用且合法的主张和观点的人，比如乔治华盛顿。明智的做法是开始更直接地解决问题。 然后是人工智能协调的问题。我们普遍认为这一举措是为了防止超级智能人工智能胡作非为，对全球社会造成严重破坏。 OpenAI 刚刚宣布将在未来 5 年内投入 20% 的计算来解决这个问题，我完全相信他们会成功。但我认为解决一致性问题的第二个目标应该是训练人工智能来帮助人类更好地理解假定的坏人与真正的坏人之间的区别。有些人可能会声称我们已经有了这种认识，但正是政治阻碍了我们采取我们能够和应该采取的措施来减轻这些风险。如果是这样的话，我建议人工智能联盟的第三个主要目标应该是训练这些超级智能计算机来帮助人类更好地放弃各种腐败的政治实践，以便我们能够像人工智能一样警惕地保护和推进我们最珍视的价值观很快就会被训练成这样。   由   提交/u/Georgeo57  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14rj7d9/bad_actors_george_washington_ai_alignment_and/</guid>
      <pubDate>Wed, 05 Jul 2023 18:33:19 GMT</pubDate>
    </item>
    <item>
      <title>Open AI 推出“SuperAlignment”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14rilc4/open_ai_introduces_superalignment/</link>
      <description><![CDATA[根据开放人工智能的说法，超级智能将是人类有史以来发明的最具影响力的技术。  如果您想了解最新的人工智能新闻，先看这里。为了方便起见，所有信息均已摘录于此。 TL;DV： 一小时前，OpenAI 推出了一个新项目，其雄心勃勃的目标是“使超级智能人工智能系统符合人类意图”的目标。它将由 Ilya Sutskever 和 Jan Leike 共同领导。“超级对齐”，旨在四年内解决超级智能的核心技术挑战。比对是指创建“人类水平的自动比对研究员”。这意味着人工智能能够使其他人工智能系统与人类意图保持一致。  要点：  理解超级对齐： OpenAI 旨在使超级智能 AI 系统与人类意图保持一致这是一项似乎不可能完成的任务，因为我们目前无法监督比人类更聪明的人工智能系统。 “该团队专注于开发可扩展的训练方法，验证生成的模型，并对其对齐管道进行压力测试。”  新团队，新焦点：Superalignment 团队将由 OpenAI 联合创始人兼首席科学家 Ilya Sutskever 和 Jan 共同领导雷克，协调负责人。该团队将在未来四年内将 OpenAI 获得的总计算资源的 20% 用于解决超级智能对齐问题。  空缺职位：OpenAI 正在寻找优秀的机器学习研究人员和工程师加入这项工作。即使那些目前没有从事协调工作的人也被鼓励申请。 研究工程师申请、研究科学家申请和研究经理申请。  未来计划：OpenAI 将继续分享这项研究的成果以及有助于非 OpenAI 模型的一致性和安全性的观点，作为一个关键部分他们的工作。他们还意识到相关的社会和技术问题，并正在与专家会面，以确保技术解决方案考虑到人类和社会问题。 就是这样！ 来源：(OpenAI)     由   提交/u/Evening_Temporary36   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14rilc4/open_ai_introduces_superalignment/</guid>
      <pubDate>Wed, 05 Jul 2023 18:11:19 GMT</pubDate>
    </item>
    <item>
      <title>日本强调学生理解人工智能的重要性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14rf3rs/japan_emphasizing_the_importance_of_students/</link>
      <description><![CDATA[来源-Japantimes 日本教育部发布了新指南，强调学生了解人工智能的重要性，包括其优点和缺点，例如个人数据泄露和侵犯版权。 该指南还概述了如何将生成式人工智能纳入学校以及减轻相关风险的必要预防措施，同时明确指出将人工智能生成的作品冒充为自己的作品是不合适的。 详细信息 • 他们概述了如何将生成式人工智能融入学校。 • 该指南还详细介绍了解决人工智能相关风险所需的预防措施. • 学生应了解人工智能的特点，包括其优点和缺点。 • 指南中提到的人工智能的缺点包括个人信息泄露和侵犯版权。&lt; /p&gt; • 在使用人工智能之前，学生应该对这些方面有一个全面的了解。 • 《指导意见》明确指出，冒充人工智能作品是不恰当的。 • 指南建议，可能需要放弃传统的考试和作业方法，例如使用人工智能技术可以轻松完成的写报告。 • 教育部出席了新闻发布会&lt; strong&gt;部长长冈惠子在东京 想法 至关重要的是学生不仅了解如何使用人工智能，还了解滥用人工智能的潜在后果。随着人工智能技术的不断发展，未来的计划应该包括对这些指南的定期更新。 这在我的 时事通讯   由   提交 /u/KSSolomon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14rf3rs/japan_emphasizing_the_importance_of_students/</guid>
      <pubDate>Wed, 05 Jul 2023 16:09:43 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能和提示是否像 60 年代的计算机？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14rd8kv/are_generative_ais_and_prompting_like_60s/</link>
      <description><![CDATA[背景：我是人机交互专业的硕士生。我目前正在读一本书，名为“巫师熬夜的地方：互联网的起源”。 今天我想到了一个想法，不一定很重要，但我很乐意听到人工智能爱好者的一些想法。在过去，计算机体积庞大，占用空间。这些计算机的软件是独一无二的，如果你需要完成一项任务或计算一些研究，你需要先编写程序。所以，从某种意义上说，本质上是在促使今天发生的这种类型的交互的版本60年代的电脑？我们尝试输入问题，计算机就会给出答案。当然，对于生成式人工智能来说，答案可能是“错误的”。从某种意义上说（虽然算数，如果做得正确，很可能是正确的），但答案仍然是用户请求的。 为什么我会问这样的问题，这有什么关系？从不同的角度观察问题通常是有启发性的，有时这些观点会给我们提供如何最好地解决问题的提示。 （在我们当前的案例中，问题是提示实际上是如何发挥作用的，它的真正特征是什么，人工智能真正理解什么，或者更确切地说 如何 人工智能是否理解等）   由   提交 /u/CoreyGrim   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14rd8kv/are_generative_ais_and_prompting_like_60s/</guid>
      <pubDate>Wed, 05 Jul 2023 15:04:09 GMT</pubDate>
    </item>
    <item>
      <title>2023 年 7 月 5 日人工智能与机器学习：回顾</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14rcix6/ai_machine_learning_in_july_05th_2023_recap/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14rcix6/ai_machine_learning_in_july_05th_2023_recap/</guid>
      <pubDate>Wed, 05 Jul 2023 14:39:04 GMT</pubDate>
    </item>
    <item>
      <title>谷歌为你的 Gmail 发布“帮我写”人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14rc0wm/google_releases_help_me_write_ai_for_your_gmail/</link>
      <description><![CDATA[18 亿人拥有 Gmail，即将接触 AI 如果您想了解最新的 AI 新闻当它下降时，先看这里。为了您的方便，所有信息均已摘录于此。Google 完成测试后，所有 Gmail 用户都可以使用此功能，以下是如何抢先体验的方法。 1. 加入 Google 实验室：如果您尚未注册 Google Workspaces，请点击此链接，然后选择工作区的第三个蓝色按钮。您必须年满 18 岁，并使用您的个人 Gmail 地址。 （欢迎加入链接中的其他 4 个 Google 计划。）2. 导航到 Gmail：启动您的 Gmail 应用程序并起草一封新邮件。找到“帮我写”按钮，该按钮方便地出现在键盘上方。 3. 提示创建：帮助我编写对您生成的提示的响应，因此请确保给出明确的说明。提示：指令比建议更有效，给 AI 一个明确的目标。示例：给我的同事写一封专业电子邮件，询问每月概览。4. 编辑您的电子邮件：创建电子邮件后（5 秒），您现在可以编辑、缩短，或添加您想要的任何内容，就像普通电子邮件一样。该工具将改变电子邮件的发送方式，为专业人员每周节省时间。我已经尝试过了，它已经发布了几周了，我只是向社区发出警告！ 就是这样！希望这有帮助！   由   提交/u/Evening_Temporary36   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14rc0wm/google_releases_help_me_write_ai_for_your_gmail/</guid>
      <pubDate>Wed, 05 Jul 2023 14:19:53 GMT</pubDate>
    </item>
    <item>
      <title>每日两分钟 AI 更新（日期：2023 年 7 月 5 日）：来自 Google、Hugging Face、OpenAI、Inflection AI 和 Utopia 的新闻</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14rc0mk/twominutes_daily_ai_update_date_7052023_news_from/</link>
      <description><![CDATA[继续分享人工智能领域当天主要更新的易于理解且较小的版本。  Google 用于训练公共数据的 AI 模型 - Google 已更新其隐私政策，声明可以使用公开数据来帮助训练和创建其 AI 模型。这表明谷歌正在大力投资人工智能。此外，利用人类的集体知识可以重新定义人工智能学习和理解信息的方式。 选择法学硕士的人格类型 - 新研究提出了一种管理经过验证的心理测量的综合方法测试并量化、分析和塑造广泛使用的法学硕士生成的文本中的人格特征。 -法学硕士接受大量人类生成数据的培训，使他们能够在输出中模仿人类特征并塑造令人信服的人物角色 -换句话说，表现出一种综合人格的形式。因此，个性成为决定沟通有效性的关键因素。 LEDITS：具有下一代人工智能功能的图像编辑 - Hugging Face 研究推出了 LEDITS，用于真实图像编辑的组合轻量级方法，将编辑友好的 DDPM 反演技术与语义指导相结合。因此，它将语义指导扩展到真实的图像编辑，同时利用 DDPM 反演的编辑功能。 OpenAI 禁用 ChatGPT 的“浏览”功能。 beta 功能 - 该公司发现许多用户使用该功能访问付费文章。因此，在修复问题时，内容所有者将无法对其进行正确的处理。 Inflection AI 开发了一台配备 NVIDIA GPU 的超级计算机 - 这家人工智能初创公司已经建立了配备22,000个NVIDIA H100 GPU的尖端AI超级计算机，这是一个惊人的数量，并带来巨大的计算性能。预计它将成为业界最大的产品之一，紧随 AMD 的前沿。 Urtopia 推出一款集成 ChatGPT 的电动自行车 - Urtopia Fusion，最新的电动自行车-来自知名品牌 Urtopia 的自行车，无缝地将 ChatGPT 融入到电动自行车的定义功能中。它将让骑手在旅途中享受身临其境的互动骑行体验。  这些新闻和创新的更多详细信息，请参见 每日简讯。   由   提交 /u/RohitAkki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14rc0mk/twominutes_daily_ai_update_date_7052023_news_from/</guid>
      <pubDate>Wed, 05 Jul 2023 14:19:36 GMT</pubDate>
    </item>
    <item>
      <title>从今年秋天开始，哈佛大学的编程课程将由人工智能教授</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14r72x1/harvards_coding_course_will_be_taught_by_an_ai/</link>
      <description><![CDATA[哈佛大学广受欢迎的编程入门课程 CS50 将于今年秋季开始由人工智能老师开设。不，这并不是因为哈佛太穷了，付不起真正的老师工资（笑），而是他们认为人工智能可以为每个人提供一种个人教学氛围。 CS50 教授 David Malan 告诉《哈佛深红报》：他希望人工智能能够帮助每个学生按照自己的节奏 24/7 学习。他们正在为这个 AI 教授角色尝试 GPT 3.5 和 GPT 4 模型。  当然，这些模型并不总是完美地编写代码，但不断尝试新软件是 CS50 的一部分。 补充一下，CS50 很受欢迎edX，这个由麻省理工学院和哈佛大学创建的在线学习平台，去年以 8 亿美元的价格售出。所以，这是一件大事！ 马兰说，早期版本的人工智能老师有时可能会出现问题，但这是预料之中的。好的一面是，课程工作人员可以有更多时间直接与学生聊天。这就像让课堂更多地关注团队合作，而不是讲座式教学。 现在，整个人工智能教学是相当新鲜的。甚至马兰也表示，学生需要仔细思考他们从人工智能中学到的东西。所以，这有点疯狂！ 在其他新闻中，比尔盖茨认为人工智能将在不到两年的时间内教孩子们阅读。这是太快了，还是事情就是这样？ 来源。 P.S.如果您喜欢听到人工智能相关的最新动态，我为您准备了这份免费新闻通讯。请随意检查一下。谢谢！   由   提交 /u/spotlightai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14r72x1/harvards_coding_course_will_be_taught_by_an_ai/</guid>
      <pubDate>Wed, 05 Jul 2023 10:43:36 GMT</pubDate>
    </item>
    <item>
      <title>过滤新闻中的抑郁和消极情绪</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14r6ycp/filter_depression_and_negativity_in_news/</link>
      <description><![CDATA[所有新闻都进来了，而且都是负面和压抑的。 是否有一个 AI 新闻源可以阻止负面和压抑的内容。给我提供积极、有趣且有用的新闻吗？   由   提交 /u/Puzzleheaded-Soft435    reddit.com/r/ArtificialInteligence/comments/14r6ycp/filter_depression_and_negativity_in_news/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14r6ycp/filter_depression_and_negativity_in_news/</guid>
      <pubDate>Wed, 05 Jul 2023 10:37:08 GMT</pubDate>
    </item>
    <item>
      <title>萨姆·奥尔特曼表示，人工智能最糟糕的情况是“我们所有人都熄灯了”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14r40ez/sam_altman_says_the_worstcase_scenario_for/</link>
      <description><![CDATA[OpenAI 首席执行官 Sam Altman 表示，他认为人工智能在最好的情况下可以带来“令人难以置信的好”结果。影响，或者在最坏的情况下意味着“我们所有人都熄灯了。” Sam Altman 对最佳人工智能场景的看法：根据 Altman 的说法，最好的情况由于其令人难以置信的潜力，人工智能的场景几乎是难以想象的。  人工智能可以创造“令人难以置信的丰富”并改善现实。 人工智能可以帮助我们过上最好的生活。 . 然而，阐明人工智能潜在的优点听起来很荒唐。  Sam Altman 对最坏人工智能场景的看法：Altman 的最坏情况-人工智能的情况是一场彻底的灾难，或者“所有人都熄灯了。”  人工智能的误用可能是灾难性的。 重点放在人工智能安全和协调的重要性。 Altman 表示希望为人工智能安全做出更多努力。  ChatGPT 的潜在滥用：ChatGPT、虽然有益，但也引起了对诈骗、错误信息和剽窃的潜在滥用的担忧。  专家对 ChatGPT 可能被滥用表示担忧。 诈骗、网络攻击、错误信息、抄袭和剽窃都是可能的滥用领域。 Altman 认识到这些担忧，并同情那些害怕人工智能的人。  Altman 最近的观点和担忧：最近，Altman 对启动 ChatGPT 的潜在负面后果表示担忧。  Altman 对那些同样害怕的人表示恐惧和同情。 他担心可能会  Altman谈AI发展与监管：在承认风险的同时，Altman相信AI将极大地改善人们的生活质量。不过，他坚持监管的必要性。  Altman 认为人工智能的发展是改善生活质量的巨大飞跃。 他指出监管对于管理人工智能至关重要。开发。  来源（商业内幕人士） PS：我运行一个ML 驱动的新闻聚合器，使用AI总结来自50+媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rafalix01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14r40ez/sam_altman_says_the_worstcase_scenario_for/</guid>
      <pubDate>Wed, 05 Jul 2023 08:03:29 GMT</pubDate>
    </item>
    <item>
      <title>过去7天内在艾城发生的一切。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/14qucjg/everything_that_happened_in_ai_in_the_last_7_days/</link>
      <description><![CDATA[ Google AI 研究人员开发了一种新的 AI 模型，可以以前所未有的准确度翻译语言 OpenAI 的科学家团队创造了一种人工智能，可以以超人水平玩 57 款 Atari 游戏。名为 Five 的人工智能能够在所有 57 款游戏中取得超人的分数，其中包括一些人工智能难以掌握的游戏。 一种新的人工智能驱动工具可以帮助医生更准确地诊断癌症。该工具名为 DeepPath，使用人工智能来分析医学图像并识别癌细胞。事实证明，它在诊断癌症方面比人类医生更准确，并且可以帮助挽救生命。  麻省理工学院的一组研究人员创建了一种人工智能，可以编写不同类型的创意内容，包括诗歌、代码、脚本和音乐作品。这个名为 MuseNet 的人工智能接受了海量文本和代码数据集的训练。它仍在开发中，但已经取得了一些令人印象深刻的成果。  新型人工智能驱动的机器人可以通过观察人类来学习执行新任务。该机器人名为 LaMDA，由 Google AI 开发。它可以观察人类执行任务，然后模仿他们。这可能会对我们未来与机器人互动的方式产生重大影响。 OpenAI 的第一个全球办事处将设在伦敦。 OpenAI 是一家开发和研究大型语言模型的非营利研究公司，宣布其第一个全球办事处将设在伦敦。该办公室将于 2024 年初开业，重点关注人工智能安全、道德和治理方面的研究和开发。 （2023 年 6 月 30 日）    由   提交/u/Scared_Fruit_2675   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/14qucjg/everything_that_happened_in_ai_in_the_last_7_days/</guid>
      <pubDate>Tue, 04 Jul 2023 23:32:17 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则 [请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行一项民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 作为请始终向我们提供反馈，如果您有兴趣帮助该子项目，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！&lt; /p&gt; 我们的目标是为所有与人工智能有关的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 服务作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用 提供培训和学习资源&lt; /li&gt; 引导用户访问更具体的信息和子版块 列出 AI/ML 应用程序、其用途、成本和访问信息 其他与 AI 相关的内容。  li&gt; ...以及更多  该子项目的审核团队正在进行重组，这将导致该子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“Request-For-”评论” (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新申请/自我推销/AI 生成的规则content  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的粘帖中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的粘帖中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用才华来组织帖子。请注意，已经添加了新的功能，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们会喜欢将社区纳入模组机器人的想法中。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能想出哪些有趣的东西？ 培养初级、中级和高级资源来帮助人们查找信息，他们正在寻找的培训、模型、技术数据等 启动子堆栈/播客来采访整个人工智能/机器学习领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>