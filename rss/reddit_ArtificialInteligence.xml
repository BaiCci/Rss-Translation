<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能会怎样，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 08 Aug 2023 21:13:48 GMT</lastBuildDate>
    <item>
      <title>关于AI对齐的问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15ltwk4/question_regarding_ai_alignment/</link>
      <description><![CDATA[每当我尝试搜索有关该问题的任何内容时，我总是能找到一些内容来详细解释问题是什么，或者它如何影响我们，但我从来没有找到任何可以显示该问题复杂性的东西，我想这是最好的地方。 因此，据我所知，这个问题来自这样一个事实：人工智能方法实现其目标可能会不符合我们的意愿，但是，人工智能可以有多个不同优先级的目标，对吗？因为如果可以的话，那么一个系统的首要目标是不做[X]件事（比如做出最终会在可预见的未来对生命造成伤害的行为） ，次要目标是真正确保给定任务的执行是该问题的良好临时解决方案？我的意思是，当然，人工智能仍然可能因为其次要任务而做坏事，但这样的系统不会消除最坏的情况吗？显然不可能那么简单，但似乎没有人谈论为什么该解决方案不起作用，而我只是想了解为什么它不起作用。 我知道这会对性能产生负面影响人工智能，但即使有这些额外的任务，它必须优化，它仍然比任何人类工人快得多，而没有这些规定的人工智能理论上会存在危险，因此可以通过法律强制执行，每个人工智能都必须拥有这些任务设置为主要任务。 再一次，我知道事情不可能那么简单，但我想知道为什么事情不可能那么简单。 请注意，我没有向聊天机器人询问这件事，正如您所期望的那样，我不想从它那里得到答案。聊天机器人在特定主题上经常出现错误，因此，如果我要从我不能完全信任的来源获得响应，我宁愿获得多个响应，而不仅仅是一个。   由   提交 /u/sdrawkcabsihtetorwI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15ltwk4/question_regarding_ai_alignment/</guid>
      <pubDate>Tue, 08 Aug 2023 20:47:21 GMT</pubDate>
    </item>
    <item>
      <title>通过 GPT 逐步进行软件设计和代码生成</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15ltdth/step_by_step_software_design_and_code_generation/</link>
      <description><![CDATA[ 由   提交 /u/RoboCoachTech   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15ltdth/step_by_step_software_design_and_code_generation/</guid>
      <pubDate>Tue, 08 Aug 2023 20:28:23 GMT</pubDate>
    </item>
    <item>
      <title>用于校对/编辑机密文档的最佳人工智能工具</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15lsqia/best_ai_tools_for_proof_readingediting_of/</link>
      <description><![CDATA[我是一名独立顾问，我的工作很大一部分（最耗时的方面）是对冗长的技术报告进行校对和语法更正（通常涉及很多首字母缩略词和不寻常的措辞 - Word 的“编辑器”经常将这些标记为语法错误，而实际上并非如此）。我很想以某种方式实施人工智能来帮助我更快地做到这一点，但人工智能工具似乎有很多可供调查的选项。 我的另一个考虑因素是这些报告是保密的（不是机密，我想说的是，只有中等程度的机密），而且我敏锐地意识到，让人工智能访问它们可能会将其内容暴露给拥有人工智能的任何公司。从个人角度来看，我从事的其他工作更加保密，我不想让任何人后门访问我的数据。 Grammerly 是最好使用的工具吗？或者您会推荐其他工具吗？另外，当使用诸如 Grammerly 之类的东西时，您可以控制它可以访问哪些文档吗？ 感谢您的帮助！ 编辑：除了一般校对（拼写）之外，我还应该添加这一点/语法），我想使用人工智能来帮助澄清措辞不当/不清楚的想法，并识别不一致等（如果有）。报告通常会缺少需要其他人跟进的信息 - 我需要能够在这种情况下分辨出来。我喜欢 ChatGPT 的一件事是它在校对时似乎能理解写作背后的含义。我最终使用这样一个工具的目标是，我只需要浏览文档，而不需要担心人工智能工具会改变报告中的实质性内容，从而改变其含义。此外，如果可能的话，我需要确保输出保持最终产品的奇怪格式。   由   提交/u/FairRecommendation4  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15lsqia/best_ai_tools_for_proof_readingediting_of/</guid>
      <pubDate>Tue, 08 Aug 2023 20:03:55 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的职业和未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15lsg3l/careers_and_the_future_of_ai/</link>
      <description><![CDATA[大家好， 我担任软件开发人员已有 15 年，但此后将我的职业生涯提升到解决方案架构和其他技术领域技能。我拥有计算机科学学位，多年前就写过一篇人工智能论文。 不管怎样，我很难弄清楚如何在人工智能的未来发展中最好地定位自己非常快。我的主要关注领域是了解企业如何利用人工智能和/或它将如何彻底改变许多行业。 我想在这股浪潮爆发之前开始准备游泳，但老实说我不知道从哪里开始我的技能和兴趣适合的地方。是否有任何人可以推荐的重点领域、课程、研究、研讨会等？我想开始生活和呼吸人工智能，但一个起点会很好。 任何有关产品或技术的帮助或见解都会非常有帮助。除了对爱好艺术和动画的稳定扩散有一些相当深入的经验之外，我几乎一无所知。 谢谢！  &amp;# 32；由   提交 /u/helpMeOut9999   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15lsg3l/careers_and_the_future_of_ai/</guid>
      <pubDate>Tue, 08 Aug 2023 19:53:11 GMT</pubDate>
    </item>
    <item>
      <title>人工智能甚至让教皇感到紧张</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15lq4m7/ai_is_even_making_the_pope_nervous/</link>
      <description><![CDATA[就连教皇方济各也对人工智能日益增长的影响力和潜在陷阱表示不安，特别是在深度造假和错误信息领域，并呼吁采取负责任的态度发展人工智能以保护人类尊严与和平。 这是 来源，我将其总结为几个要点： 教皇方济各的担忧人工智能  作为天主教会的精神领袖，方济各教皇并没有孤立于技术趋势之外。他看到人工智能如何深入融入我们的生活，并建议谨慎行事。 虽然人工智能提供了效率和创新等显着优势，但教皇强调了它破坏和改变社会规范、挑战价值观和传统的潜力。   人工智能的双刃剑  深度伪造，例如伪造的弗朗西斯教皇穿着高档服装的照片，突显了其中的风险人工智能：创造误导性和不真实的内容。 虽然人工智能有望彻底改变政治、经济和个人经历等领域，但缺乏适当的指导方针和控制可能会导致其走上可能造成混乱和潜在危害的道路。   迫切需要道德监督  教皇方济各强调需要在全球范围内讨论人工智能的道德挑战，查看这些演讲对于引导受人工智能影响的未来走向正确的方向至关重要。 对他来说，这不仅是控制人工智能的危险，也是以造福所有人、确保和平和尊重每个人的价值的方式使用人工智能.  PS：加入这个发展最快的技术/，更加了解人工智能和技术AI 时事通讯，在不到几分钟的时间内回顾您真正不想错过的科技新闻。欢迎加入我们由来自 Google、Microsoft、JP Morgan 等公司的专业人士组成的大家庭。   由   提交 /u/Falix01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15lq4m7/ai_is_even_making_the_pope_nervous/</guid>
      <pubDate>Tue, 08 Aug 2023 18:26:15 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何*好的*图像生成 AI API？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15lpmk6/are_there_are_any_good_image_gen_ai_apis/</link>
      <description><![CDATA[ 由   提交/u/thedarklord176   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15lpmk6/are_there_are_any_good_image_gen_ai_apis/</guid>
      <pubDate>Tue, 08 Aug 2023 18:07:40 GMT</pubDate>
    </item>
    <item>
      <title>您对转向以数据为中心的人工智能方法有何看法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15lmyx1/what_are_your_thoughts_on_the_shift_toward_a/</link>
      <description><![CDATA[大家好！ 我最近偶然发现 ScienceDirect 上的一篇文章，探讨了以数据为中心的人工智能、数据质量的重要性，以及您可能听说过的 Python 工具：ydata-profiling。 我想与大家分享要点并了解您对此的想法：这是这篇文章！ 对于那些不知道的人来说，ydata-profiling 是一个 Python 工具，可以生成有关以下内容的详细报告：您的数据集，包括缺失值、数据分布、相关性等等。 本文讨论了 ydata-profiling 如何成为初始数据分析的宝贵工具，提供富有洞察力的数据快照并提供帮助及早发现潜在的数据质量问题。 提问：我很想听听您对人工智能向以数据为中心的方法转变的经验和想法。这里有人在他们的项目中广泛使用过 ydata-profiling 吗？它在识别数据质量问题方面的效果如何？我们将非常感谢您提供反馈和见解！   由   提交 /u/SeaEngineering9034   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15lmyx1/what_are_your_thoughts_on_the_shift_toward_a/</guid>
      <pubDate>Tue, 08 Aug 2023 16:27:22 GMT</pubDate>
    </item>
    <item>
      <title>因病失声，我需要人工智能的帮助！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15lmmo5/losing_my_voice_to_a_disease_i_need_ai_to_help/</link>
      <description><![CDATA[大家好，就像标题所说，我因为疾病（帕金森病）而失去了声音，我想创建一个 AI声音使用10年前的录音。我曾经是一位多产的播客，我有大约 50 集播客可以用作输入。这可能吗？我可以使用什么服务或软件？由于帕金森病是一种进行性疾病，我的声音无法修复。人工智能声音可以让我工作，并为我打开新的大门。谢谢！   由   提交/u/NWMoney101  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15lmmo5/losing_my_voice_to_a_disease_i_need_ai_to_help/</guid>
      <pubDate>Tue, 08 Aug 2023 16:14:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 Langchain、PineconeDB 和 Airbyte 与您的数据聊天</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15lkx5v/chat_with_your_data_using_langchain_pineconedb/</link>
      <description><![CDATA[Airbyte 的一些团队成员（以及杀死它的 Joe！）最近使用 Airbyte 构建了我们自己的内部支持 AI 聊天机器人、Langchain、Pinecone 和 OpenAI，这将回答我们在 Airbyte 上开发新连接器时提出的任何问题。  当我们对其进行原型设计时，我们意识到它可以应用于许多其他用例和数据源，因此......我们创建了 其他社区成员可以利用的教程以及Github repo 来运行它。 教程显示：  如何使用 Airbyte 从各种来源提取非结构化数据开源 如何将数据加载到矢量数据库（此处为 Pinecone），为 LLM 使用准备数据 如何将矢量数据库集成到 ChatGPT 中以提出以下问题您的专有数据  我希望其中一些有用，并且希望得到您的反馈！    由   提交 /u/jeanlaf   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15lkx5v/chat_with_your_data_using_langchain_pineconedb/</guid>
      <pubDate>Tue, 08 Aug 2023 15:11:11 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 为即将到来的 GPT-5 数据训练发布网络爬虫机器人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15lks9h/openai_releases_web_crawling_bot_for_upcoming/</link>
      <description><![CDATA[OpenAI 推出了名为 GPTBot 的网络爬虫收集更多数据来训练下一代人工智能系统（GPT-5）。这扩大了数据收集工作，但引发了同意问题。 如果您想要轻松进行人工智能开发先看这里&lt; /p&gt; 网络爬虫：  OpenAI 发布 GPTBot 来爬取公共网络数据。 它避免了禁止的、敏感的和付费内容。 网站必须选择退出，以免其收集数据。  推动未来人工智能 ：  数据收集旨在改进 GPT-5 等下一代系统。 ChatGPT 取得巨大成功后，人们寻求更多数据。 OpenAI 落后于竞争对手，需要更多数据优越的训练数据。  道德考虑：  数千人认为默认选择退出方法会忽略同意。 &lt; li&gt;数据收集仍然是人工智能面临的主要道德挑战。 平衡能力和透明度是复杂的。  TL;DR：OpenAI 发布了名为 GPTBot 的网络爬虫旨在扩展未来人工智能系统的训练数据，但默认数据收集会引发同意问题。在推动功能改进的同时，此举凸显了在推进强大的人工智能过程中围绕透明度的道德紧张关系。 来源：(链接) PS：加入其中一个 增长最快的 AI 时事通讯。加入我们的大家庭，该大家庭由来自 Open AI、Google、Meta 等的 1000 名专业人士组成。&lt; /p&gt;   由   提交 /u/saffronfan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15lks9h/openai_releases_web_crawling_bot_for_upcoming/</guid>
      <pubDate>Tue, 08 Aug 2023 15:06:12 GMT</pubDate>
    </item>
    <item>
      <title>创造一个有感知能力的劳拉·克劳馥来玩《古墓丽影》</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15ljcnu/creating_a_sentient_lara_croft_to_play_tomb_raider/</link>
      <description><![CDATA[Sentient Lara Croft 玩古墓丽影： 这是一部充满灵感的作品使用人工智能和视频游戏的方式。绝对值得关注这个 YouTuber。劳拉原来的声音的使用方式是最奇怪的。我没有创建视频。我认为这家伙需要更多的观点。   由   提交/u/ZoNeS_v2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15ljcnu/creating_a_sentient_lara_croft_to_play_tomb_raider/</guid>
      <pubDate>Tue, 08 Aug 2023 14:11:36 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们可能很快就会选举人工智能来管理我们的政府</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15lh9mg/why_we_may_soon_be_electing_ais_to_run_our/</link>
      <description><![CDATA[想象一下，三年后，有人开发出了一种人工智能，它的智能程度是最聪明的人的三倍，知识也比最聪明的人高出许多倍。现在想象一下，人们开始尝试让这些人工智能来经营他们的业务，并发现他们可以在人工智能的掌舵下赚更多的钱。  事实上，想象一下，这些人工智能变得如此擅长经营企业，以至于它们犯错误的可能性就像袖珍计算器犯计算错误一样。 几年后，人们可能会发现几乎没有人类首席执行官和首席技术官担任企业负责人。在最初的几年里，人类当然会反复检查这些人工智能的工作。几年后，这种检查可能会被证明是不必要的，而且效率低下，就像检查袖珍计算器是否犯错误一样。 一旦我们达到了这一点，就不需要推理上的重大飞跃。认识到，如果首席执行官人工智能可以为企业带来更多的钱，那么类似的人工智能在管理政府方面也将同样有效。这些由人工智能管理的新政府将以比今天人类选举产生的官员更低的成本为选民做更多的好事。  选民还希望人工智能当选官员能够接受培训，使其不腐败，例如，做符合其竞选捐助者最大利益的事情，而不是做符合人民最大利益的事情。政治丑闻将减少到几乎闻所未闻的程度。 今天，我们正在训练人工智能比医学博士同行更有效地行医，而且成本要低得多。我们还训练人工智能比人类律师更有效、更便宜地执业。我们已经在让人工智能执行非常高级别的决策方面取得了惊人的进展。 最初，某个地方的地方政府将尝试使用人工智能作为市长并选举出共同委员会。当地居民很快就会了解到人工智能可以如何更加智能和有效地管理当地政府。然后，这些当地居民会开始吹嘘他们惊人的实验，附近的地方政府很快就会效仿他们的做法。 不久之后，县和州政府将进行这项实验，并对他们的人工智能运行得多么出色感到惊讶那些地方政府。不久之后，我们的政党意识到人工智能可以在联邦层面做同样的事情，并开始修改法律，允许人工智能当选国会议员，甚至总统。 现在对许多人来说这似乎非常牵强，但一旦公司董事会意识到人工智能首席执行官可以为这些公司赚更多的钱，让人工智能管理我们的政府的想法就会突然变得不再那么牵强。    由   提交/u/Georgeo57  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15lh9mg/why_we_may_soon_be_electing_ais_to_run_our/</guid>
      <pubDate>Tue, 08 Aug 2023 12:47:32 GMT</pubDate>
    </item>
    <item>
      <title>分析显示，52% 的 ChatGPT 答案不正确，77% 的答案过于冗长</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/15l8ax4/analysis_shows_that_52_percent_of_chatgpt_answers/</link>
      <description><![CDATA[普渡大学团队研究了 ChatGPT 对 517 个 Stack Overflow 问题的回答，评估其质量和准确性。他们还分析了所使用的语言，并收集了 12 名志愿者对模型答案的反馈。该机器人的说服力足以欺骗三分之一的参与者。 ​ 这项研究中有哪些值得注意的点？ - 52% 的 ChatGPT 答案不正确。 - 77% 的 ChatGPT 答案过于冗长。 - ChatGPT 答案由于其全面性和准确性，在 39.34% 的情况下受到首选。语言风格。 - 在首选的 ChatGPT 答案中，77% 是错误的。 - OpenAI 承认 ChatGPT 的输出可能存在不准确之处。 - 普渡大学的研究发现用户可以识别 ChatGPT 答案中的明显错误。 - 不易验证的错误会导致用户无法识别或低估错误。 - 12 名参与者中的 2 名仍然更喜欢ChatGPT 的响应存在明显错误。 - ChatGPT 的首选地位通常源于其礼貌、权威的风格。 - 礼貌的语言、教科书式的答案、全面性和从属关系可能会导致错误答案看起来是正确的。 ​ 出于各种原因，参与者更喜欢不正确且冗长的 ChatGPT 答案，而不是 Stack Overflow 的答案 -在许多情况下，如果参与者能从冗长而详细的答案中获得有用的信息，他们并不介意长度。 - 当人们认为 ChatGPT 的答案有帮助时，他们就忽略了错误。由于 ChatGPT 充满信心地分享信息，即使是错误的，用户也会更加信任它并经常选择错误的答案。 - ChatGPT 使用“驱动器属性”来存储信息。用语言表示成就或成果，但不像 Stack Overflow 那样频繁提及风险。 - 对 ChatGPT 信息传达的信心会赢得用户信任，即使答案不正确也会导致偏好。 - 对 ChatGPT 信息传达的信心会赢得用户的信任。 p&gt; - 由于理解上下文的问题，ChatGPT 更有可能犯概念错误而不是事实错误。 ​ 这些错误是 ChatGPT 用户的原因吗？ 5月和6月有大幅下降吗？尽管 ChatGPT 经常把编码问题弄错，但它的建议却非常可信。您的体验如何？ ChatGPT 以友好的语气成功地建立了对未来的信任，但未来如果答案继续错误，这会阻碍用户吗？ ​ P.S.如果您觉得这有帮助，请加入我们的免费 AI 时事通讯，该通讯已覆盖 28,000 多名企业家和企业家。专业人士每天都会更新人工智能的重要进展。   由   提交 /u/clonefitreal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/15l8ax4/analysis_shows_that_52_percent_of_chatgpt_answers/</guid>
      <pubDate>Tue, 08 Aug 2023 05:10:34 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则 [请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行一项民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 作为请始终向我们提供反馈，如果您有兴趣帮助该子项目，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！&lt; /p&gt; 我们的目标是为所有与人工智能有关的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 服务作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用 提供培训和学习资源&lt; /li&gt; 引导用户访问更具体的信息和子版块 列出 AI/ML 应用程序、其用途、成本和访问信息 其他与 AI 相关的内容。  li&gt; ...以及更多  该子项目的审核团队正在进行重组，这将导致该子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“Request-For-”评论” (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新申请/自我推销/AI 生成的规则content  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的粘帖中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的粘帖中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新的功能，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们会喜欢将社区纳入模组机器人的想法中。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能想出哪些有趣的东西？ 培养初级、中级和高级资源来帮助人们查找信息，他们正在寻找的培训、模型、技术数据等 启动子堆栈/播客来采访整个人工智能/机器学习领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>