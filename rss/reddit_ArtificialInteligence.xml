<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能会怎样，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 18 Jul 2023 18:21:50 GMT</lastBuildDate>
    <item>
      <title>一个可以实时记录通话时间的工具</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1535h31/a_tool_that_can_take_live_minutes_on_the_call/</link>
      <description><![CDATA[是否有工具可以帮助捕获我的通话并将其放入会议记录中？  它甚至可以只是一个转录，我可以让聊天 gpt 来做笔记。   由   提交/u/BWayne04  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1535h31/a_tool_that_can_take_live_minutes_on_the_call/</guid>
      <pubDate>Tue, 18 Jul 2023 17:58:49 GMT</pubDate>
    </item>
    <item>
      <title>后真相心态、特朗普和人工智能对社会现实感知的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1534vsm/the_impact_of_posttruth_mentality_trump_and_ai_on/</link>
      <description><![CDATA[对我们当前状态、我们如何走到这一步以及我们需要注意的风险进行研究的哲学观点。 https://optimistic-xxplore4life.wordpress.com/2023/07/18/the-impact-of-post-truth-mentality-trump-and-ai-on-societys-perception-of-reality/    由   提交 /u/Unlikely_Scapegoat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1534vsm/the_impact_of_posttruth_mentality_trump_and_ai_on/</guid>
      <pubDate>Tue, 18 Jul 2023 17:35:29 GMT</pubDate>
    </item>
    <item>
      <title>如何使用我喜欢的不同乐器和我喜欢的歌曲的人声创作一首新歌曲？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1534ufp/how_can_i_create_a_new_song_with_a_different/</link>
      <description><![CDATA[我喜欢这首歌曲，但想更改乐器歌曲同时保留人声！是否可以使用人工智能工具来创建匹配的乐器并将歌曲与乐器相匹配？   由   提交/u/t_4_ll_4_t   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1534ufp/how_can_i_create_a_new_song_with_a_different/</guid>
      <pubDate>Tue, 18 Jul 2023 17:34:05 GMT</pubDate>
    </item>
    <item>
      <title>精确的音频转录</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1534qb4/precise_audio_transcript/</link>
      <description><![CDATA[嗨 我正在使用 OpenAI 的 Whisper API 将音频转录为文本。 使用 . vtt 或 .srt 格式，它输出对应于单词组的时间。  例如： 00:01.000 --&gt; 00:04.000 - 人们相信热力学是关于功和热的。 00:05.000 --&gt; 00:09.000 - 它实际上是关于什么的？ - 能量和熵。  但是如果我想知道更精确的时间怎么办？ 例如，“熵”出现时的时间？发音如何？ 有办法实现这一点吗？ （用耳语或其他方式） 谢谢 ​ ​   由   提交/u/nit_electron_girl  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1534qb4/precise_audio_transcript/</guid>
      <pubDate>Tue, 18 Jul 2023 17:29:41 GMT</pubDate>
    </item>
    <item>
      <title>Meta 推出 LLaMA 2 LLM：免费、开源，现已可用于商业用途</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1534a6g/meta_launches_llama_2_llm_free_opensource_and_now/</link>
      <description><![CDATA[繁荣——就在这里！我们之前听说 Meta 即将发布免费用于商业用途的 LLM，现在我们终于有了更多详细信息。 LLaMA 2 现在可以在此处下载。 以下是需要了解的重要信息：  模型已经过训练比 LLaMA 1 多 40% 的数据，上下文长度加倍：这应该为希望对其进行微调的人们提供更强大的起始基础。 它有 3 种版本模型大小： 7B、13B 和 70B 参数。 LLaMA 2 在各种基准测试中均优于其他开源模型： MMLU、TriviaQA、HumanEval 等是一些常用的基准。竞争模型包括 LLaMA 1、Falcon 和 MosaicML 的 MPT 模型。 还包含 76 页的技术规范文档：可以快速通读，它采用 Meta 的风格对于模型的训练和微调方式非常开放，而 OpenAI 在 GPT-4 上的细节相对稀疏。  还有什么有趣的地方：他们与 Microsoft 关系融洽：  微软是 Llama 2 的首选合作伙伴，Meta 在其新闻稿中宣布，“从今天开始，Llama 2 将在Azure AI 模型目录，使开发人员能够使用 Microsoft Azure。” 我的结论：MSFT 知道开源将会发展壮大。他们不愿意投入所有尽管对 OpenAI 进行了 100 亿美元的巨额投资，但他们还是把鸡蛋放在一个篮子里。  Meta 与 Microsoft 的合作伙伴关系对 OpenAI 来说是一剂强心针。请注意媒体中的语言发布：  “现在，通过扩大合作伙伴关系，微软和 Meta 支持一种开放的方法，以增加对基础人工智能技术的访问，从而使全球企业受益。相信当今人工智能模型的访问民主化的不仅仅是 Meta 和微软。我们在世界各地拥有广泛的多元化支持者，他们也相信这种方法” 所有这些都依赖于开源的优势：“增加访问”， “民主化访问”、“世界各地的支持者”  要点：开源与闭源之战变得非常有趣。 Meta 不仅使 LLaMA 1 可供商业使用，他们还发布了更好的模型，并同时宣布与 Microsoft 进行强有力的合作。有传言称 OpenAI 未来将发布开源模型 - 现在球已经到了他们的球场上。 P.S.如果您喜欢这种分析，我会写免费时事通讯来跟踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。   由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1534a6g/meta_launches_llama_2_llm_free_opensource_and_now/</guid>
      <pubDate>Tue, 18 Jul 2023 17:12:11 GMT</pubDate>
    </item>
    <item>
      <title>美国演员工会和作家协会在哲学上有立足之地吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1533xm2/do_sag_and_the_writers_guild_have_a_leg_to_stand/</link>
      <description><![CDATA[罢工的很大一部分似乎集中在对“肖像权”的补偿上。从那以后我一直在思考这个问题&gt;！琼太糟糕了！&lt;出来后我不得不说，我认为演员和编剧最终都会失败，因为向人们收取对你的记忆的费用根本没有意义，而所有录音的核心都是保存的音频视频记忆 - 一种帮助人们提高记忆准确性的控制论工具。 虚构但并不遥远的工具，用于&gt;！ Joan is Awful!&lt; 基本上是一台根据佩戴者大脑活动创建个性化内容的机器。这并不是说迪士尼正在拍摄塞尔玛·海耶克的图像，然后使用该图像来创建一个非常高端的深假“虚拟塞尔玛·海耶克”。相反，最终的结果是，作为用户，你将能够戴上一个设备来监控你的大脑活动。您打开该设备并“训练它”通过狂看一些节目。你真正喜欢看的东西会对你的大脑活动产生一种影响，你不喜欢看的东西会对你的大脑活动产生另一种影响。经过充分的训练后，该设备基本上看起来像 VR 耳机，将根据您喜欢的内容专门为您生成内容。不会有“表演”分享给所有人。相反，它将是你自己的想象力，受到过去观看行为的启发，为你展示，并根据你自己的大脑实时调整，以最大限度地提高你的享受。您对塞尔玛·海耶克伟大的记忆可能会激发您的想象力，将塞尔玛·海耶克纳入其定制内容中，但环球影业或迪士尼对此无能为力。他们无法控制你喜欢什么，以及你喜欢的东西与现实生活中的人的相似程度或听起来有多少。   由   提交 /u/Ok-Cheetah-3497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1533xm2/do_sag_and_the_writers_guild_have_a_leg_to_stand/</guid>
      <pubDate>Tue, 18 Jul 2023 16:59:25 GMT</pubDate>
    </item>
    <item>
      <title>G/O Media CEO（Onion、AV Club等）：如果不生产更多AI编写的内容就是“不负责任”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1533h1r/go_medias_ceo_onion_av_club_etc_it_would_be/</link>
      <description><![CDATA[尽管 G/O Media 的员工和更广泛的媒体界对推动制作更多人工智能编写内容的计划提出了强烈批评，但 G/O Media O Media 的首席执行官 Jim Spanfeller 并没有退缩。 事实上，他认为，“我认为不进行测试是不负责任的”。他告诉 Vox​​ 在最近的一次采访中。 背景信息：G/O Media 拥有 AV Club、Jezebel、the Onion、Gizmodo、Deadspin 等网站. 推动新闻报道：  作家普遍担心人工智能会抢走他们的工作：特别担心 G/O Media 的这些最初的人工智能测试是在没有任何警告的情况下进行的。 G/O Media 最近的人工智能文章出现了令人尴尬的错误：例如，如何按时间顺序观看所有星球大战电影就存在多个错误。但谷歌仍然将其列为搜索词“星球大战电影”的热门文章，显示出不正当的激励措施。 数字媒体业务面临压力：曾经的宠儿Buzzfeed、Vox 等公司尚未被证明可行，而且近年来广告预算的缩减也影响了他们的收入。人工智能似乎是一种自然的成本削减解决方案。  G/O 媒体高管怎么说？  “它是G/O 的编辑总监 Merrill Brown 说道。 “我认为不对其进行测试是不负责任的行为，”首席执行官 Jim Spanfeller 说道。 “我认为不对其进行测试是不负责任的。” &gt; 我们的目标是雇用更多记者，”Spanfeller 解释道（尽管今年因作家裁员而陷入困境）  毫不奇怪，G/O 媒体员工正在抵制——匿名：  “这是一次毫不掩饰的尝试，用机器生成的内容取代真正的新闻报道，”一位 G/O 记者告诉 Vox​​。 “G/O 的目标是让员工做得越来越多，发表越来越多的文章。从来没有停止过这样的情况。这是一家重视数量而非质量的公司。” 另一位 G/O 记者表示，“这对员工士气来说是一场灾难。”  并非所有公司都如此。然而，媒体高管同意人工智能是未来。“我们肯定会关注人工智能的各个方面，以增强我们的工作，但目前看不到完全由人工智能生成的内容有任何好处，”Axios 主编吉姆范德黑告诉 Vox​​。 “看起来一切都是危险，在了解更多信息之前没有任何好处。” 主要结论：人工智能生成的内容充斥互联网只是何时&lt;的问题/em&gt;，而不是if。随着人工智能工程师越来越多地接管，未来十年人工撰写的新闻可能会成为稀缺商品。这将如何影响作家的工作还有待观察——尽管没有理由乐观。 P.S.如果您喜欢这种分析，我会写免费时事通讯来跟踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。 ​ &lt;!-- SC_ON - -&gt;  由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1533h1r/go_medias_ceo_onion_av_club_etc_it_would_be/</guid>
      <pubDate>Tue, 18 Jul 2023 16:41:31 GMT</pubDate>
    </item>
    <item>
      <title>不，尽管我以写作为生，但我并不害怕人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1531qp2/no_im_not_scared_of_ai_even_though_i_write_for_a/</link>
      <description><![CDATA[每个人都问我是否害怕人工智能抢走我的工作。 我一点也不担心。  p&gt; 我为初创公司、为技术早期采用者编写内容。我工作的每个人都尝试过 ChatGPT，但他们仍然雇用我。 如果我出于 SEO 原因写博客，我会因恐惧而颤抖。但我写的内容是供人们阅读的，而不是由 Google 的算法阅读和排序的。 如果您是一名作家并且害怕人工智能，则有以下 3 个原因之一：&lt; /p&gt;  你不是一个优秀的作家，认为 ChatGPT 可以打败你。唯一的解决办法就是多写。 您还没有充分使用 ChatGPT，没有意识到它有多么糟糕。ChatGPT 的书写很容易被发现。它很无聊，太礼貌，重复，而且充满了废话。正如编剧乔恩·洛佩兹所说，“人工智能可能会杀死我们所有人，但它永远写不出一部好电影。” 你担心人工智能未来会变得有多好。 你担心人工智能未来会变得有多好。好吧，我明白这一点，这就是好莱坞编剧的罢工的意义所在。 “我们现在必须坚守阵地，这样他们就无法在十年内打败我们。”但我就是不买账，我同意洛佩兹的观点。人工智能无法写出一部好电影、一本好书等等。当然，它可以写一部电影或一本书，但它们不会有任何好处。  我个人不担心人工智能有几个原因：  我很有趣。 ChatGPT 则不然。ChatGPT 没有普通受过公立学校教育、纯属传教士风格的会计师那么有趣，后者为父亲工作，正在和一个名叫艾莉森的女孩约会。幽默是不合逻辑的，软件和会计师是有逻辑的。 我分享个人故事。ChatGPT 无法分享有意义的童年故事，当你骑自行车擦伤膝盖时，没有手，没有令人尴尬的初吻故事，没有关于死亡和悲伤的故事。 ChatGPT 无法传达人类体验，因为它不是人类。 我已经建立了个人品牌。我与来自世界各地的数千名读者建立了真正的关系和友谊。遍布全球，在 Twitter 上拥有 18,000 名关注者。人们想阅读我的作品，而不是 ChatGPT 的作品。  作为一名专业作家，您的个人品牌就是一切。 当您考虑这一点时，个人品牌就是一切。品牌只是个性的在线描述，因此展示您的个性，这才是您人性化的原因。 如果您想作为一名作家脱颖而出，请尽可能人性化。因此，不要像机器人一样。 愿意在工作中承担风险。犯蠢。讲述你童年的故事。向读者展示你自己。添加您生活中的图片。 让别人发笑。让某人哭泣。让某人开始与朋友交谈，甚至坠入爱河。 无论你做什么，只是不要像 ChatGPT 或名叫 Kevin 的会计师那样无聊。 --  如果您喜欢优秀的人类写作，请查看我的免费时事通讯 7k 书呆子。   由   提交 /u/iamjasonlevin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1531qp2/no_im_not_scared_of_ai_even_though_i_write_for_a/</guid>
      <pubDate>Tue, 18 Jul 2023 15:35:38 GMT</pubDate>
    </item>
    <item>
      <title>研究人员警告说，法学硕士对人类数据创建构成“威胁”。 StackOverflow 的帖子今年已经下降了 16%。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/152zvul/llms_are_a_threat_to_human_data_creation/</link>
      <description><![CDATA[LLM 依靠广泛的人类知识作为训练数据来产生输出。 Reddit、StackOverflow、Twitter 等都是广泛用于训练基础模型的已知来源。 一组研究人员正在记录一个有趣的趋势：随着像 ChatGPT 这样的 LLM 越来越受欢迎，它们导致了 LLM 的大幅下降。 StackOverflow 等网站上的内容。  这是 arXiv 上的论文，供有兴趣深入阅读的人使用。 我已经取笑过下面列出了 Reddit 讨论的要点。 为什么这很重要：  研究人员认为，高质量内容正在遭受流失发现。ChatGPT 不仅仅在 StackOverflow 上显示低质量的答案。 结果是“开放数据”有限，这可能会影响如何处理问题。 AI 模型和人类都可以学习。 “ChatGPT 的广泛采用可能会使其变得困难”。训练未来的迭代，尤其是因为 LLM 生成的数据通常无法有效地训练新的 LLM。   这是“模糊 JPEG”图像。研究人员指出，ChatGPT 无法取代其最重要的输入（来自人类活动的数据）的问题，但由于法学硕士，数字商品可能只会减少。 主要要点：   我们正处于在线内容高度颠覆的时期，因为 Reddit、Twitter 和 StackOverflow 等网站也意识到他们的人工生成内容有多么有价值，并且越来越想把它锁起来。  随着网络上的内容越来越多地由人工智能生成，“模糊的 JPEG”变得越来越重要。问题只会变得更加明显，特别是因为人工智能模型无法可靠地区分人类创建的内容和人工智能生成的作品。  P.S.如果您喜欢这种分析，我会写免费时事通讯来跟踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。 ​ ​ &gt;   由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/152zvul/llms_are_a_threat_to_human_data_creation/</guid>
      <pubDate>Tue, 18 Jul 2023 14:23:22 GMT</pubDate>
    </item>
    <item>
      <title>克劳德2创意写作被点燃</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/152xbfn/claude_2_creative_writing_is_lit/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/152xbfn/claude_2_creative_writing_is_lit/</guid>
      <pubDate>Tue, 18 Jul 2023 12:36:33 GMT</pubDate>
    </item>
    <item>
      <title>Stability AI 老板预测，由于人工智能，印度大多数外包程序员将在两年内消失</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/152x90b/most_outsourced_coders_in_india_will_be_gone_in_2/</link>
      <description><![CDATA[Stability AI 首席执行官 Emad Mostaque 预计，由于人工智能的兴起，未来两年印度外包编码员的数量将大幅下降. 印度外包编码员面临的威胁：Emad Mostaque 预测，由于人工智能技术的进步，印度外包编码员将出现大量失业。他认为，现在可以用更少的人来开发软件，这对这些工作构成了重大威胁。  人工智能对基于计算机的工作的影响尤其严重，因为这些工作是看不见的。 值得注意的是，印度的外包程序员被认为面临的风险最大。  劳动法对全球产生不同的影响：虽然预计会出现失业，但影响由于不同的劳动法，世界各地的情况都会有所不同。法国等拥有严格劳动法的国家可能会受到较少的干扰。  劳动法将决定失业的程度。 预计印度的失业人数会更高  印度的高风险情景：拥有超过 500 万软件程序员的印度预计将受到最严重的打击。鉴于其在外包方面的重要地位，该国特别容易受到人工智能导致的失业的影响。  印度软件程序员受到的威胁最大。 印度的重大劳动力市场加剧了这一风险。全球外包角色。  来源 (CNBC) PS: 我运行一个 人工智能驱动的新闻聚合器，总结了来自50+媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/152x90b/most_outsourced_coders_in_india_will_be_gone_in_2/</guid>
      <pubDate>Tue, 18 Jul 2023 12:33:34 GMT</pubDate>
    </item>
    <item>
      <title>专家得出结论，人工智能书写检测器不可信。 GPTZero 的创始人现在也承认了这一点。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/152h8qh/ai_writing_detectors_cant_be_trusted_experts/</link>
      <description><![CDATA[这个 Reddit 子版块中最引人注目的一件事是，教授们使用人工智能检测工具来“抓住”大量被指控的学生。使用生成式人工智能写作辅助。 在对人工智能写作检测背后的技术和理论的全面审视中，专家们提出了一个强有力的案例为什么大多数检测方法都是废话。 最值得注意的是- 就连广受欢迎的人工智能书写检测工具 GPTZero 的创始人 Edward Tian 也承认，他的产品的下一版本正在远离人工智能检测（更多内容见下文）。 为什么这很重要：   虽然一些教授鼓励使用人工智能工具，但这仍然是例外。许多学校继续尝试并抓住人工智能写作工具的使用，因此，人们采用了 Turn-It-In、GPTZero 和其他工具。 被指控作弊会在现实生活中产生后果：课程不及格、被停学，甚至被开除都是可能的结果，具体取决于学校的荣誉准则。 这些检测工具被视为说真话的人：但它们实际上非常不可靠且基于未经证实的科学。  专家的看法如何？  马里兰大学研究人员的综合报告表示不存在误报率很高，各种简单的提示方式都可以骗过AI探测器。研究人员认为，随着法学硕士的进步，真正的检测只会变得更加困难。 斯坦福大学的一项研究表明，7 种流行的检测器都对非英语使用者存在偏见。为什么这很重要？它展示了如何限制语言表达来标记 AI 检测，并且添加困惑的简单提示可以击败 GPT 检测器。  简而言之：现有的 GPT 内容检测机制并不有效。   这是因为他们依赖两个有缺陷的属性来做出决定：“困惑”和“困惑”。和“突发性”。但人类可以通过以某些风格写作或使用更简单的语言来轻松标记这些简单的人工智能启发式算法。  在 Ars Technica 的压力下，GPTZero 的创建者 Edward Tian 承认他正在将 GPTZero 从普通的 AI 中解放出来。检测：  他说的：“与 Turn-it-in 等其他检测器相比，我们正在从构建检测器转向相反，GPTZero 的下一版本不会检测人工智能，而是突出最人性化的部分，并帮助教师和学生共同了解人工智能参与教育的程度。”   最后的想法：预计这场战斗将持续数年——特别是因为人工智能检测/反作弊软件领域有大量资金。人类对人工智能的无知将继续推动人工智能“作弊”案件。 P.S.如果您喜欢这种分析，我会写免费时事通讯来跟踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。   由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/152h8qh/ai_writing_detectors_cant_be_trusted_experts/</guid>
      <pubDate>Mon, 17 Jul 2023 23:12:20 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 的竞争对手在暗网上出售“无道德界限”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/152e8i5/chatgpt_rival_with_no_ethical_boundaries_sold_on/</link>
      <description><![CDATA[黑客现在可以使用一种新的人工智能工具 WormGPT，它没有道德界限。该工具在暗黑市场上销售网络网络犯罪论坛可以生成类似人类的文本来协助黑客活动。使用这种人工智能工具会引发网络安全问题，因为它会导致更真实且难以检测的大规模攻击。 如果您想掌握最新的技术/人工智能发展，先看这里。 WormGPT 简介：WormGPT 是网络安全公司 SlashNext 观察到的一种 AI 模型在暗网上。  它被誉为 GPT 模型的替代品，但专为恶意活动而设计。 据称它接受了各种数据的训练，特别是与恶意软件相关的数据. 其主要应用是在黑客活动中，生成类似人类的文本来帮助攻击。  WormGPT 的功能：测试借助 WormGPT 的功能，SlashNext 指示其生成电子邮件。  目的是欺骗客户经理支付欺诈性发票。 生成的电子邮件具有说服力且狡猾。 ，展示了复杂网络钓鱼攻击的潜力。 因此，该工具可以促进大规模、复杂的网络攻击。  与其他人工智能工具的比较  强&gt;：ChatGPT 和 Google 的 Bard 等其他人工智能工具具有内置的防止滥用保护功能。  但是，WormGPT 是为犯罪活动而设计的。 其创建者将其视为ChatGPT 的敌人，使用户能够进行非法活动。 因此，它代表了网络犯罪世界中的新型人工智能工具。  潜力威胁：执法机构欧洲刑警组织警告 ChatGPT 等大型语言模型 (LLM) 带来的风险。  它们可能被用于欺诈、冒充或社会工程攻击. 起草真实文本的能力使法学硕士成为网络钓鱼的有力工具。 因此，网络攻击可以更快、更真实地进行，并且规模显着增加。&lt; /li&gt;  来源（独立报）&lt; /a&gt; PS：我运行一个人工智能驱动的新闻聚合器，它总结了来自 50 多家媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/152e8i5/chatgpt_rival_with_no_ethical_boundaries_sold_on/</guid>
      <pubDate>Mon, 17 Jul 2023 21:13:48 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则[请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行一项民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 作为请始终向我们提供反馈，如果您有兴趣帮助该子项目，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！&lt; /p&gt; 我们的目标是为所有与人工智能有关的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 服务作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用 提供培训和学习资源&lt; /li&gt; 引导用户访问更具体的信息和子版块 列出 AI/ML 应用程序、其用途、成本和访问信息 其他与 AI 相关的内容。  li&gt; ...以及更多  该子项目的审核团队正在进行重组，这将导致该子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“Request-For-”评论” (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新申请/自我推销/AI 生成的规则content  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的粘帖中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的粘帖中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用才华来组织帖子。请注意，已经添加了新的功能，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们会喜欢将社区纳入模组机器人的想法中。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能想出哪些有趣的东西？ 培养初级、中级和高级资源来帮助人们查找信息，他们正在寻找的培训、模型、技术数据等 启动子堆栈/播客来采访整个人工智能/机器学习领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>