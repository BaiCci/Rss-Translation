<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、人工智能在商业中的应用、人工智能如何影响我们的生活、未来可能会发生什么，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Wed, 19 Jul 2023 02:46:59 GMT</lastBuildDate>
    <item>
      <title>如何构建人工智能程序来为现有有声读物自主创建视觉注释视频系列？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/153i3nc/how_would_one_build_an_ai_program_to_autonomously/</link>
      <description><![CDATA[我想为 JM Roberts 的 50 小时有声读物《世界历史》创建一个视觉伴侣。这个想法是，现有图像会自动从互联网获取，并以一定的时间间隔（可能每 10-20 秒）伴随音频。例如，美索不达米亚的历史地图将与那个时代的艺术和雕塑图像一起出现在本书的该章中。  人工智能是否已经达到可以大规模完成 50 小时内容的程度？谢谢！   由   提交 /u/RevolutionaryTone276   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/153i3nc/how_would_one_build_an_ai_program_to_autonomously/</guid>
      <pubDate>Wed, 19 Jul 2023 02:28:17 GMT</pubDate>
    </item>
    <item>
      <title>从制造商项目表中获取可用信息</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/153dfo5/getting_usable_information_from_manufacturer_item/</link>
      <description><![CDATA[我们有大约 20 张高尔夫球杆 UPC、SKU、条形码、定价和描述的 Excel 表，数十万行数据。我们希望尽可能地将产品分组在一起，但这些工作表的设置都不同，但具有相似的信息。它们都与列或标题不一致 例如，对于挖起杆来说，它们可能都是一种型号，但具有不同的倾角、弹跳和研磨。一般来说，倾角和弹跳在产品说明中都有。对于推杆来说也是如此，它们通常在描述中都有长度。  有什么办法可以运行这些文件，以便更好地猜测俱乐部变体并将它们分组，而无需手动执行吗？ 提前谢谢您！   由   提交/u/corbrat89  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/153dfo5/getting_usable_information_from_manufacturer_item/</guid>
      <pubDate>Tue, 18 Jul 2023 23:03:02 GMT</pubDate>
    </item>
    <item>
      <title>黑客创建了 ChatGPT 的邪恶版本，他们称之为“WormGPT”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/153cpjb/hackers_create_an_evil_version_of_chatgpt_they/</link>
      <description><![CDATA[黑帽黑客发布了 WormGPT，一个“邪恶”的病毒。 ChatGPT 版本，目前用于窃取加密货币和 NFT 的电子邮件网络钓鱼诈骗。 如果您想掌握最新的技术/AI 发展，首先查看此处。 恶意 AI 开发：WormGPT 是基于 GPT-J 模型的 ChatGPT 克隆，专门用于非法黑客攻击。 &lt; ul&gt; WormGPT 接受了与恶意软件、网络钓鱼和网络攻击相关的数据集的训练。 它没有像 ChatGPT 那样的安全限制或内容过滤。 WormGPT 可以根据需要生成有说服力的网络钓鱼电子邮件、恶意软件代码等。 目前，WormGPT 的访问权限正在黑客论坛上以低廉的价格出售。  网络钓鱼攻击部署 WormGPT强&gt;：WormGPT 现在被用来实施商业电子邮件泄露诈骗。  它会自动生成令人信服地冒充高管的电子邮件。 这些网络钓鱼电子邮件已帮助窃取了数百万美元的加密货币和 NFT。 生成式 AI 极大地提高了网络钓鱼的规模和效率。  人工智能网络犯罪问题：专家认为恶意使用人工智能，例如WormGPT 将导致复杂的网络犯罪增加。  WormGPT 展示了滥用人工智能的技术障碍的迅速侵蚀。 它甚至可以使不熟练的黑客通过人工智能发起强有力的攻击。&lt;​​/li&gt; 防御新一波人工智能驱动的威胁提出了艰巨的挑战。  TL;DR: 黑客发布了 WormGPT，一种恶意 ChatG用于黑客目的的 PT 克隆。它被用来生成有效的网络钓鱼电子邮件，窃取加密货币资金。专家警告说，WormGPT 预示着人工智能驱动的网络犯罪浪潮即将到来，这种犯罪可能难以防御。 来源：（链接） 还有一件事：通过加入增长最快的组织之一，您可以在 3 分钟内对人工智能更加了解。 AI 时事通讯。 加入我们的大家庭，该大家庭由来自 Open AI、Google、Meta 等的 1000 名专业人士组成。   由   提交/u/saffronfan  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/153cpjb/hackers_create_an_evil_version_of_chatgpt_they/</guid>
      <pubDate>Tue, 18 Jul 2023 22:35:07 GMT</pubDate>
    </item>
    <item>
      <title>最佳人工智能文本生成器</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/153cosg/best_ai_text_generator/</link>
      <description><![CDATA[您知道吗，一般人在一分钟内可以输入大约 40 个单词？这相当令人印象深刻，对吧？ 但是想象一下：有一种称为人工智能写作软件的特殊计算机程序，它不仅可以在相同的时间内生成数百个单词，而且可能生成数千个单词！这就像在您的指尖拥有一个超快的作家一样。 现在，您可能想知道为什么这如此重要。好吧，想想你每次都必须为学校写论文或文章。提出好的想法并将其付诸实践可能需要花费大量的时间和精力。但有了人工智能文本生成器，写作变得更快更容易。 在这篇文章中，我将向您介绍一些最好的人工智能文本生成器工具。这些程序旨在帮助您快速撰写高质量的文章。它们可以生成各种主题的文本，您甚至可以自定义样式和语气来满足您的需求。 想象一下，在人工智能写作软件的帮助下，您可以节省多少时间和精力。您不必费力寻找合适的词语，而是可以专注于组织您的想法并使您的文章变得更好。无论您是在作业上寻求额外帮助的学生，还是喜欢写作的人，这些人工智能文本生成器都可以成为真正的游戏规则改变者。 因此，如果您有兴趣增强您的写作技巧并快速轻松地撰写高质量的文章，请继续阅读。您即将发现最好的人工智能文本生成器工具的奇妙世界！ https://www.successtechservices.com/best-ai-text-generator/   由   提交/u/Chisom1998_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/153cosg/best_ai_text_generator/</guid>
      <pubDate>Tue, 18 Jul 2023 22:34:17 GMT</pubDate>
    </item>
    <item>
      <title>Meta 推出了人工智能研究社区，但投入的资源很少</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/153a3wb/meta_launches_an_ai_research_community_but/</link>
      <description><![CDATA[Meta 正在发起一个新的人工智能研究小组，即开放创新人工智能研究社区，几乎不需要投入任何资源。 社区运营和目标：开放创新人工智能研究社区将是一个成员主导的组织，Meta AI 仅充当促进者的角色。  目标是创建一个支持大型开源基础模型的实践社区。 He re，成员可以协作，分享见解，并提出有关构建负责任和安全的人工智能模型的问题。 它还旨在加快下一代人工智能研究人员的培训过程。  Meta 的有限支持：Meta 计划赞助一系列围绕关键开放研究问题和负责任的开源模型开发的研讨会，但尚未投入任何大量资源。  尽管人工智能研究的潜在成本很高，但 Meta 尚未表明任何财务费用支持社区，可能是为了避免受到不当影响的感觉。  Meta 的人工智能争议：Meta 的举措是在其处理人工智能道德的争议和批评背景下提出的。  Meta 被指控发布包含种族主义内容和不准确的科学数据的人工智能演示。 批评者声称 Meta 的人工智能道德团队缺乏实力，其反人工智能偏见工具也不足. 有人指控该公司通过其广告算法加剧社会经济不平等，并在自动审核系统中对黑人用户表现出偏见。  研究社区的影响和潜力：开放创新人工智能研究社区的潜在影响仍有待观察，特别是考虑到 Meta 缺乏资源承诺。  邀请具有相关人工智能经验的教授参与，但选择这个社区而不是其他社区的原因仍不清楚。 由于承诺的资源有限，人们对 Meta 对这一计划的诚意和奉献精神一直存有疑问。  来源 (TechCrunch)  PS：我运行一个人工智能驱动的新闻聚合器，它总结了来自50+媒体（TheVerge、TechCrunch…）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/153a3wb/meta_launches_an_ai_research_community_but/</guid>
      <pubDate>Tue, 18 Jul 2023 20:55:02 GMT</pubDate>
    </item>
    <item>
      <title>关于ai语音的愚蠢问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1534aks/stupid_question_about_ai_voice/</link>
      <description><![CDATA[抱歉，但我对大量猫发出类似于单词的声音的视频感到非常好奇。能不能把它们变成艾语音。   由   提交/u/buttwholebanger  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1534aks/stupid_question_about_ai_voice/</guid>
      <pubDate>Tue, 18 Jul 2023 17:12:37 GMT</pubDate>
    </item>
    <item>
      <title>Meta 推出 LLaMA 2 LLM：免费、开源，现已可用于商业用途</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1534a6g/meta_launches_llama_2_llm_free_opensource_and_now/</link>
      <description><![CDATA[繁荣——就在这里！我们之前听说 Meta 即将发布免费用于商业用途的 LLM，现在我们终于有了更多详细信息。 LLaMA 2 现在可以在此处下载。 以下是需要了解的重要信息：  模型已经过训练比 LLaMA 1 多 40% 的数据，上下文长度加倍：这应该为希望对其进行微调的人们提供更强大的起始基础。 它有 3 种版本模型大小： 7B、13B 和 70B 参数。 LLaMA 2 在各种基准测试中均优于其他开源模型： MMLU、TriviaQA、HumanEval 等是一些常用的基准。竞争模型包括 LLaMA 1、Falcon 和 MosaicML 的 MPT 模型。 还包含 76 页的技术规范文档：可以快速通读，它采用 Meta 的风格对于模型的训练和微调方式非常开放，而 OpenAI 在 GPT-4 上的细节相对稀疏。  还有什么有趣的地方：他们与 Microsoft 关系融洽：  微软是 Llama 2 的首选合作伙伴，Meta 在其新闻稿中宣布，“从今天开始，Llama 2 将在Azure AI 模型目录，使开发人员能够使用 Microsoft Azure。” 我的结论：MSFT 知道开源将会发展壮大。他们不愿意投入所有尽管对 OpenAI 进行了 100 亿美元的巨额投资，但他们还是把鸡蛋放在一个篮子里。  Meta 与 Microsoft 的合作伙伴关系对 OpenAI 来说是一剂强心针。请注意媒体中的语言发布：  “现在，通过扩大合作伙伴关系，微软和 Meta 支持一种开放的方法，以增加对基础人工智能技术的访问，从而使全球企业受益。相信当今人工智能模型的访问民主化的不仅仅是 Meta 和微软。我们在世界各地拥有广泛的多元化支持者，他们也相信这种方法” 所有这些都依赖于开源的优势：“增加访问”， “民主化访问”、“世界各地的支持者”  要点：开源与闭源之战变得非常有趣。 Meta 不仅使 LLaMA 1 可供商业使用，他们还发布了更好的模型，并同时宣布与 Microsoft 进行强有力的合作。有传言称 OpenAI 未来将发布开源模型 - 现在球已经到了他们的球场上。 P.S.如果您喜欢这种分析，我会写免费时事通讯来跟踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。   由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1534a6g/meta_launches_llama_2_llm_free_opensource_and_now/</guid>
      <pubDate>Tue, 18 Jul 2023 17:12:11 GMT</pubDate>
    </item>
    <item>
      <title>G/O Media CEO（Onion、AV Club等）：如果不生产更多AI编写的内容就是“不负责任”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1533h1r/go_medias_ceo_onion_av_club_etc_it_would_be/</link>
      <description><![CDATA[尽管 G/O Media 的员工和更广泛的媒体界对推动制作更多人工智能编写内容的计划提出了强烈批评，但 G/O Media O Media 的首席执行官 Jim Spanfeller 并没有退缩。 事实上，他认为，“我认为不进行测试是不负责任的”。他告诉 Vox​​ 在最近的一次采访中。 背景信息：G/O Media 拥有 AV Club、Jezebel、the Onion、Gizmodo、Deadspin 等网站. 推动新闻报道：  作家普遍担心人工智能会抢走他们的工作：特别担心 G/O Media 的这些最初的人工智能测试是在没有任何警告的情况下进行的。 G/O Media 最近的人工智能文章出现了令人尴尬的错误：例如，如何按时间顺序观看所有星球大战电影就存在多个错误。但谷歌仍然将其列为搜索词“星球大战电影”的热门文章，显示出不正当的激励措施。 数字媒体业务面临压力：曾经的宠儿Buzzfeed、Vox 等公司尚未被证明可行，而且近年来广告预算的缩减也影响了他们的收入。人工智能似乎是一种自然的成本削减解决方案。  G/O 媒体高管怎么说？  “它是G/O 的编辑总监 Merrill Brown 说道。 “我认为不对其进行测试是不负责任的行为，”首席执行官 Jim Spanfeller 说道。 “我认为不对其进行测试是不负责任的。” &gt; 我们的目标是雇用更多记者，”Spanfeller 解释道（尽管今年因作家裁员而陷入困境）  毫不奇怪，G/O 媒体员工正在抵制——匿名：  “这是一次毫不掩饰的尝试，用机器生成的内容取代真正的新闻报道，”一位 G/O 记者告诉 Vox​​。 “G/O 的目标是让员工做得越来越多，发表越来越多的文章。从来没有停止过这样的情况。这是一家重视数量而非质量的公司。” 另一位 G/O 记者表示，“这对员工士气来说是一场灾难。”  并非所有公司都如此。然而，媒体高管同意人工智能是未来。“我们肯定会关注人工智能的各个方面，以增强我们的工作，但目前看不到完全由人工智能生成的内容有任何好处，”Axios 主编吉姆范德黑告诉 Vox​​。 “看起来一切都是危险，在了解更多信息之前没有任何好处。” 主要结论：人工智能生成的内容充斥互联网只是何时&lt;的问题/em&gt;，而不是if。随着人工智能工程师越来越多地接管，未来十年人工撰写的新闻可能会成为稀缺商品。这将如何影响作家的工作还有待观察——尽管没有理由乐观。 P.S.如果您喜欢这种分析，我会写免费时事通讯来跟踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。 ​ &lt;!-- SC_ON - -&gt;  由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1533h1r/go_medias_ceo_onion_av_club_etc_it_would_be/</guid>
      <pubDate>Tue, 18 Jul 2023 16:41:31 GMT</pubDate>
    </item>
    <item>
      <title>不，尽管我以写作为生，但我并不害怕人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1531qp2/no_im_not_scared_of_ai_even_though_i_write_for_a/</link>
      <description><![CDATA[每个人都问我是否害怕人工智能抢走我的工作。 我一点也不担心。  p&gt; 我为初创公司、为技术早期采用者编写内容。我工作的每个人都尝试过 ChatGPT，但他们仍然雇用我。 如果我出于 SEO 原因写博客，我会因恐惧而颤抖。但我写的内容是供人们阅读的，而不是由 Google 的算法阅读和排序的。 如果您是一名作家并且害怕人工智能，则有以下 3 个原因之一：&lt; /p&gt;  你不是一个优秀的作家，认为 ChatGPT 可以打败你。唯一的解决办法就是多写。 您还没有充分使用 ChatGPT，没有意识到它有多么糟糕。ChatGPT 的书写很容易被发现。它很无聊，太礼貌，重复，而且充满了废话。正如编剧乔恩·洛佩兹所说，“人工智能可能会杀死我们所有人，但它永远写不出一部好电影。” 你担心人工智能未来会变得有多好。 你担心人工智能未来会变得有多好。好吧，我明白这一点，这就是好莱坞编剧的罢工的意义所在。 “我们现在必须坚守阵地，这样他们就无法在十年内打败我们。”但我就是不买账，我同意洛佩兹的观点。人工智能无法写出一部好电影、一本好书等等。当然，它可以写一部电影或一本书，但它们不会有任何好处。  我个人不担心人工智能有几个原因：  我很有趣。 ChatGPT 则不然。ChatGPT 没有普通受过公立学校教育、纯属传教士风格的会计师那么有趣，后者为父亲工作，正在和一个名叫艾莉森的女孩约会。幽默是不合逻辑的，软件和会计师是有逻辑的。 我分享个人故事。ChatGPT 无法分享有意义的童年故事，当你骑自行车擦伤膝盖时，没有手，没有令人尴尬的初吻故事，没有关于死亡和悲伤的故事。 ChatGPT 无法传达人类体验，因为它不是人类。 我已经建立了个人品牌。我与来自世界各地的数千名读者建立了真正的关系和友谊。遍布全球，在 Twitter 上拥有 18,000 名关注者。人们想阅读我的作品，而不是 ChatGPT 的作品。  作为一名专业作家，您的个人品牌就是一切。 当您考虑这一点时，个人品牌就是一切。品牌只是个性的在线描述，因此展示您的个性，这才是您人性化的原因。 如果您想作为一名作家脱颖而出，请尽可能人性化。因此，不要像机器人一样。 愿意在工作中承担风险。犯蠢。讲述你童年的故事。向读者展示你自己。添加您生活中的图片。 让别人发笑。让某人哭泣。让某人开始与朋友交谈，甚至坠入爱河。 无论你做什么，只是不要像 ChatGPT 或名叫 Kevin 的会计师那样无聊。 --  如果您喜欢优秀的人类写作，请查看我的免费时事通讯 7k 书呆子。   由   提交 /u/iamjasonlevin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1531qp2/no_im_not_scared_of_ai_even_though_i_write_for_a/</guid>
      <pubDate>Tue, 18 Jul 2023 15:35:38 GMT</pubDate>
    </item>
    <item>
      <title>研究人员警告说，法学硕士对人类数据创建构成“威胁”。 StackOverflow 的帖子今年已经下降了 16%。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/152zvul/llms_are_a_threat_to_human_data_creation/</link>
      <description><![CDATA[LLM 依靠广泛的人类知识作为训练数据来产生输出。 Reddit、StackOverflow、Twitter 等都是广泛用于训练基础模型的已知来源。 一组研究人员正在记录一个有趣的趋势：随着像 ChatGPT 这样的 LLM 越来越受欢迎，它们导致了 LLM 的大幅下降。 StackOverflow 等网站上的内容。  这是 arXiv 上的论文，供有兴趣深入阅读的人使用。 我已经取笑过下面列出了 Reddit 讨论的要点。 为什么这很重要：  研究人员认为，高质量内容正在遭受流失发现。ChatGPT 不仅仅在 StackOverflow 上显示低质量的答案。 结果是“开放数据”有限，这可能会影响如何处理问题。 AI 模型和人类都可以学习。 “ChatGPT 的广泛采用可能会使其变得困难”。训练未来的迭代，尤其是因为 LLM 生成的数据通常无法有效地训练新的 LLM。   这是“模糊 JPEG”图像。研究人员指出，ChatGPT 无法取代其最重要的输入（来自人类活动的数据）的问题，但由于法学硕士，数字商品可能只会减少。 主要要点：   我们正处于在线内容高度颠覆的时期，因为 Reddit、Twitter 和 StackOverflow 等网站也意识到他们的人工生成内容有多么有价值，并且越来越想把它锁起来。  随着网络上的内容越来越多地由人工智能生成，“模糊的 JPEG”变得越来越重要。问题只会变得更加明显，特别是因为人工智能模型无法可靠地区分人类创建的内容和人工智能生成的作品。  P.S.如果您喜欢这种分析，我会写免费时事通讯来跟踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。 ​ ​ &gt;   由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/152zvul/llms_are_a_threat_to_human_data_creation/</guid>
      <pubDate>Tue, 18 Jul 2023 14:23:22 GMT</pubDate>
    </item>
    <item>
      <title>克劳德2创意写作被点燃</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/152xbfn/claude_2_creative_writing_is_lit/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/152xbfn/claude_2_creative_writing_is_lit/</guid>
      <pubDate>Tue, 18 Jul 2023 12:36:33 GMT</pubDate>
    </item>
    <item>
      <title>Stability AI 老板预测，由于人工智能，印度大多数外包程序员将在两年内消失</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/152x90b/most_outsourced_coders_in_india_will_be_gone_in_2/</link>
      <description><![CDATA[Stability AI 首席执行官 Emad Mostaque 预计，由于人工智能的兴起，未来两年印度外包编码员的数量将大幅下降. 印度外包编码员面临的威胁：Emad Mostaque 预测，由于人工智能技术的进步，印度外包编码员将出现大量失业。他认为，现在可以用更少的人来开发软件，这对这些工作构成了重大威胁。  人工智能对基于计算机的工作的影响尤其严重，因为这些工作是看不见的。 值得注意的是，印度的外包程序员被认为面临的风险最大。  劳动法对全球产生不同的影响：虽然预计会出现失业，但影响由于不同的劳动法，世界各地的情况都会有所不同。法国等拥有严格劳动法的国家可能会受到较少的干扰。  劳动法将决定失业的程度。 预计印度的失业人数会更高  印度的高风险情景：拥有超过 500 万软件程序员的印度预计将受到最严重的打击。鉴于其在外包方面的重要地位，该国特别容易受到人工智能导致的失业的影响。  印度软件程序员受到的威胁最大。 印度的重大劳动力市场加剧了这一风险。全球外包角色。  来源 (CNBC) PS: 我运行一个 人工智能驱动的新闻聚合器，总结了来自50+媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/152x90b/most_outsourced_coders_in_india_will_be_gone_in_2/</guid>
      <pubDate>Tue, 18 Jul 2023 12:33:34 GMT</pubDate>
    </item>
    <item>
      <title>专家得出结论，人工智能书写检测器不可信。 GPTZero 的创始人现在也承认了这一点。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/152h8qh/ai_writing_detectors_cant_be_trusted_experts/</link>
      <description><![CDATA[这个 Reddit 子版块中最引人注目的一件事是，教授们使用人工智能检测工具来“抓住”大量被指控的学生。使用生成式人工智能写作辅助。 在对人工智能写作检测背后的技术和理论的全面审视中，专家们提出了一个强有力的案例为什么大多数检测方法都是废话。 最值得注意的是- 就连广受欢迎的人工智能书写检测工具 GPTZero 的创始人 Edward Tian 也承认，他的产品的下一版本正在远离人工智能检测（更多内容见下文）。 为什么这很重要：   虽然一些教授鼓励使用人工智能工具，但这仍然是例外。许多学校继续尝试并抓住人工智能写作工具的使用，因此，人们采用了 Turn-It-In、GPTZero 和其他工具。 被指控作弊会在现实生活中产生后果：课程不及格、被停学，甚至被开除都是可能的结果，具体取决于学校的荣誉准则。 这些检测工具被视为说真话的人：但它们实际上非常不可靠且基于未经证实的科学。  专家的看法如何？  马里兰大学研究人员的综合报告表示不存在误报率很高，各种简单的提示方式都可以骗过AI探测器。研究人员认为，随着法学硕士的进步，真正的检测只会变得更加困难。 斯坦福大学的一项研究表明，7 种流行的检测器都对非英语使用者存在偏见。为什么这很重要？它展示了如何限制语言表达来标记 AI 检测，并且添加困惑的简单提示可以击败 GPT 检测器。  简而言之：现有的 GPT 内容检测机制并不有效。   这是因为他们依赖两个有缺陷的属性来做出决定：“困惑”和“困惑”。和“突发性”。但人类可以通过以某些风格写作或使用更简单的语言来轻松标记这些简单的人工智能启发式算法。  在 Ars Technica 的压力下，GPTZero 的创建者 Edward Tian 承认他正在将 GPTZero 从普通的 AI 中解放出来。检测：  他说的：“与 Turn-it-in 等其他检测器相比，我们正在从构建检测器转向相反，GPTZero 的下一版本不会检测人工智能，而是突出最人性化的部分，并帮助教师和学生共同了解人工智能参与教育的程度。”   最后的想法：预计这场战斗将持续数年——特别是因为人工智能检测/反作弊软件领域有大量资金。人类对人工智能的无知将继续推动人工智能“作弊”案件。 P.S.如果您喜欢这种分析，我会写免费时事通讯来跟踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。   由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/152h8qh/ai_writing_detectors_cant_be_trusted_experts/</guid>
      <pubDate>Mon, 17 Jul 2023 23:12:20 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则[请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 一如既往，请向我们提供反馈，如果您有兴趣帮助该子版块，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！ 我们的目标是为所有被视为人工智能的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 作为理解和理解人工智能的起点了解 AI 主题 提供技术论文演示和讨论 展示高质量的 AI/ML 应用程序 提供培训和学习资源 引导用户访问更具体的信息和 subreddits 列出 AI/ML 应用程序、其用途、成本和访问信息 其他 AI 相关内容。 ...以及更多  此子版块的审核团队是进行重新洗牌，这将导致子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“请求评论”进行的。 (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新应用程序/自我推销/AI 生成内容的规则 由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的置顶线程中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的置顶线程中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新功能，我们愿意接受更多建议。 关于 AI/ML 应用程序的 NSFW 应用程序和技术的子政策应该是什么？ 我们希望包括对 mod-bots 有想法的社区。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能提出哪些有趣的东西？ 培养初级、中级和高级资源，以帮助人们查找他们正在寻找的信息、培训、模型、技术数据等 启动子堆栈/播客来采访整个 AI/ML 领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>