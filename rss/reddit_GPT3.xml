<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：GPT3</title>
    <link>https://www.reddit.com/r/GPT3/new</link>
    <description>AI 文本生成技术的 Reddit 子版块</description>
    <lastBuildDate>Thu, 24 Aug 2023 15:16:36 GMT</lastBuildDate>
    <item>
      <title>是否有任何更高级/ activley 更新的项目，例如 ChartAI</title>
      <link>https://www.reddit.com/r/GPT3/comments/1604p7s/is_there_any_more_advanced_activley_updated/</link>
      <description><![CDATA[我正在寻找与此类似的工具https:// github.com/thongekchakrit/ChartAI 使用自然语言和人工智能来查询表格数据，但是我提供的这个已经有一段时间没有更新了，并且缺少一些功能。我知道没有什么可以得到 AutoGPT 的支持，但是有人知道解决方案吗？   由   提交 /u/AUTOGPTtheboss   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1604p7s/is_there_any_more_advanced_activley_updated/</guid>
      <pubDate>Thu, 24 Aug 2023 15:13:43 GMT</pubDate>
    </item>
    <item>
      <title>我创建了 GPT Pilot - 一个用于开发工具的 PoC，它从头开始编写完全工作的应用程序（大规模工作的 GPT 工程师/smol 开发人员），同时开发人员监督实施 - 它像人类一样逐步创建代码和测试，调试代码、运行命令并请求反馈。</title>
      <link>https://www.reddit.com/r/GPT3/comments/1603yea/i_created_gpt_pilot_a_poc_for_a_dev_tool_that/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1603yea/i_created_gpt_pilot_a_poc_for_a_dev_tool_that/</guid>
      <pubDate>Thu, 24 Aug 2023 14:45:44 GMT</pubDate>
    </item>
    <item>
      <title>AI2 发布最大的训练语言模型开放数据集 Dolma</title>
      <link>https://www.reddit.com/r/GPT3/comments/15zr63o/ai2_releases_dolma_the_largest_open_dataset_for/</link>
      <description><![CDATA[     &lt; td&gt; 艾伦人工智能研究所 (AI2) 发布了 Dolma，这是一个新的大型文本数据集，可免费使用并开放供检查。该数据集旨在与 OpenAI 和 Meta 等公司用来训练语言模型的严密保护数据集相反。 AI2 旨在扭转这一趋势，并将用于创建语言模型的数据提供给人工智能研究社区。 如果您想掌握人工智能和机器学习的最新趋势和见解，先看这里。 https://preview.redd.it/q9cqwf5uhzjb1.png?width=2000&amp;放大器；格式= png&amp;auto=webp&amp;s=16a4f1e9ab36f2a21e9a1506e84a0b640ff2f9c2 为什么这很重要：  人工智能研究的透明度：&lt; /strong&gt; 发布 Dolma 的目的是通过公开记录用于创建数据集的来源和过程来提高人工智能研究的透明度。 道德问题： 有猜测称一些公司可能没有以道德或合法的方式获取他们的数据。 AI2 希望通过开放并免费使用 Dolma 来解决这些问题。 鼓励审查和改进：通过将 Dolma 提供给人工智能研究社区，AI2 希望鼓励审查以及数据集的改进。  卓玛是用于训练语言模型的最大开放数据集：  3万亿代币： Dolma 是最大的用于训练语言模型的开放数据集，拥有 3 万亿个代币。 直接使用和权限： Dolma 使用“ImpACT 许可证用于中型风险工件”，要求用户提供联系信息，披露任何卓玛衍生作品，在同一许可下分发这些衍生品，并同意不在各种禁区应用卓玛。  &lt; strong&gt;可以通过Hugging Face访问卓玛：  如果您对使用卓玛感兴趣， 您可以通过 Hugging Face 访问它。 对于那些关心个人数据的人，有一份删除请求表适用于特定情况。  P.S.如果您喜欢这种分析，我会写免费时事通讯&lt; /a&gt; 追踪生成人工智能技术的最大问题和影响。每个工作日都会发送一次，让您在 3 分钟内了解最新动态！ （来源）   由   提交 /u/AIsupercharged   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15zr63o/ai2_releases_dolma_the_largest_open_dataset_for/</guid>
      <pubDate>Thu, 24 Aug 2023 04:17:28 GMT</pubDate>
    </item>
    <item>
      <title>搜索基本分块 - 嵌入示例</title>
      <link>https://www.reddit.com/r/GPT3/comments/15zd62a/searching_for_basic_chunking_embedding_example/</link>
      <description><![CDATA[大家好。  也许这是一个愚蠢的问题，但我仍在学习，请不要嘲笑我。  如果有人拥有（或可以分享类似/资源）一个Python代码的基本示例，该示例可以获取文本、分割文本、嵌入文本、存储文本并根据查询进行调用，我将非常感激，那不用LangChain？  预先感谢您的各种答复。   由   提交/u/Natural_Speaker7954   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15zd62a/searching_for_basic_chunking_embedding_example/</guid>
      <pubDate>Wed, 23 Aug 2023 19:02:52 GMT</pubDate>
    </item>
    <item>
      <title>这家伙怎么把事情搞砸了</title>
      <link>https://www.reddit.com/r/GPT3/comments/15z9asm/how_does_this_mfer_even_screw_this_up/</link>
      <description><![CDATA[        由   提交 /u/M3rcury404   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15z9asm/how_does_this_mfer_even_screw_this_up/</guid>
      <pubDate>Wed, 23 Aug 2023 16:46:00 GMT</pubDate>
    </item>
    <item>
      <title>定制知识库</title>
      <link>https://www.reddit.com/r/GPT3/comments/15z3fl4/custom_knowledge_base/</link>
      <description><![CDATA[我是一名学术学生，即将完成我的学位。当然，目前我正在研究我的论文结论。我正在寻找替代的 LLM 解决方案，我可以在其中上传多个引用我的作品的 PDF 文件。我正在寻找一种可靠的模型，它可以同时搜索所有文件中的信息，并且能够帮助我使用这些参考文献编写高质量的科学文本。我没有编码知识，所以我正在 GitHub 上寻找一些解决方案。是否有可能执行提议的任务？如果是这样，最好的选择是什么？    由   提交/u/eduardo_cbo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15z3fl4/custom_knowledge_base/</guid>
      <pubDate>Wed, 23 Aug 2023 13:07:34 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 启动 GPT-3.5 Turbo 微调</title>
      <link>https://www.reddit.com/r/GPT3/comments/15ywog9/openai_launches_finetuning_for_gpt35_turbo/</link>
      <description><![CDATA[      OpenAI刚刚宣布一项新功能：对GPT-3.5 Turbo（GPT-3.5的轻量级版本）进行微调。这意味着用户现在可以携带自己的数据并训练模型，以便在特定任务和领域中表现更好。 如果您想掌握人工智能和技术的最新趋势和见解，先看这里。 https://preview.redd.it /qzj8610obtjb1.jpg?width=862&amp;format=pjpg&amp;auto=webp&amp;s=fc84493354838543e3d52306d809ebae83f4cd5b 为什么这很重要：  &lt; li&gt;微调为创建定制且可靠的人工智能解决方案开辟了新的可能性。用户可以通过向模型提供相关数据和指令来提高模型的准确性、一致性和风格。  微调还可以降低成本和延迟。用户可以通过将指令嵌入模型本身来缩短文本提示，从而加快 API 调用速度并降低使用费用。 微调可以帮助用户克服 GPT-3.5 Turbo 的一些限制。虽然 GPT-3.5 Turbo 比 GPT-4 更快、更便宜，但它的功能和数据源也较少。微调可以帮助缩小差距并提高模型的性能。  微调的工作原理：  用户需要准备自己的数据并上传到OpenAI的API。数据可以是任何格式，例如文本、图像或音频，只要兼容GPT-3.5 Turbo的输入和输出即可 用户需要通过 OpenAI 的 API 创建微调作业。该作业指定根据用户数据训练模型的参数和设置。 &lt; li&gt;用户需要等待微调工作完成。时间取决于数据和模型的大小和复杂性。 OpenAI 表示，典型的 100,000 个 token（约 75,000 个单词）数据的微调工作成本约为 2.40 美元，大约需要一个小时。 用户可以通过 OpenAI 的 API 使用微调后的模型. 微调后的模型可通过分配给用户的唯一端点进行访问。  P.S.如果您喜欢这种分析，您会喜欢免费时事通讯我每个工作日都会撰写关于生成人工智能技术的最新趋势和影响的文章。   由   提交 /u/AIsupercharged   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15ywog9/openai_launches_finetuning_for_gpt35_turbo/</guid>
      <pubDate>Wed, 23 Aug 2023 07:36:38 GMT</pubDate>
    </item>
    <item>
      <title>Meta的新AI模型可以翻译和转录100种语言</title>
      <link>https://www.reddit.com/r/GPT3/comments/15yw51k/metas_new_ai_model_can_translate_and_transcribe/</link>
      <description><![CDATA[      Meta 宣布 SeamlessM4T，这是一种开源人工智能模型，可以翻译和转录近 100 种语言的文本和语音。该模型是将翻译和转录结合到一个系统中的最雄心勃勃的努力之一。 如果您想掌握人工智能和技术的最新趋势和见解，先看这里。 https://preview.redd.it/74u14hr57tjb1.png?width= 900&amp;format=png&amp;auto=webp&amp;s=007d5a8a9406174c66abb42d5e80c2057460029e 为什么这很重要：  Meta 想要创建一个能够理解世界语言的通用系统。SeamlessM4T 可以执行诸如将语音转录为文本、翻译文本、从文本生成语音以及将语音翻译为语音等任务。这可以帮助说不同语言的人交流和访问信息。 Meta 使用大量数据来训练其模型。该公司抓取了公开可用的文本（按顺序排列）来自网络的“数百亿”句子）和语音（400 万小时）来创建 SeamlessAlign，这是 SeamlessM4T 的训练数据集。该数据集包含文本和语音之间的对齐以及语音到语音的对齐，这些对齐可教会模型如何跨语言映射声音和含义。 Meta 声称其模型优于当前的模型语音转录领域最先进的技术。根据内部基准测试，SeamlessM4T 在语音转文本任务中针对背景噪声和“说话人变化”的表现比其他模型更好。 Meta 表示，这是因为训练数据集中语音和文本数据的丰富组合，这使得 SeamlessM4T 比纯语音和纯文本模型具有优势。  但是，该模型存在一些挑战和局限性：  SeamlessM4T 在某些翻译中显示出性别偏见和毒性。在最近的一篇文章中，Meta 透露该模型“从中性术语翻译时过度概括为男性形式”，并且在从大多数语言的男性参考翻译时表现更好。此外，在某些语言中，例如孟加拉语和吉尔吉斯语，SeamlessM4T 会做出有关社会经济地位和文化的有毒翻译。 SeamlessM4T 不适合长篇翻译和认证翻译。 Meta建议不要使用 SeamlessM4T 翻译需要当局官方认可的大型文档或文本。由于存在误译和责任风险，Meta 也不鼓励将 SeamlessM4T 用于医疗或法律目的。 SeamlessM4T 可能会失去翻译的丰富性和多样性。一些专家认为 AI翻译人员可以减少人类口译员做出的翻译选择的多样性。人工智能系统可能会生成更“准确”的翻译，但这些翻译可能会以牺牲翻译创造力和细微差别为代价。  P.S.如果您喜欢这种分析，您会喜欢免费时事通讯 我每个工作日都会撰写有关生成式 AI 技术的最新趋势和影响的文章。   由   提交 /u/AIsupercharged   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15yw51k/metas_new_ai_model_can_translate_and_transcribe/</guid>
      <pubDate>Wed, 23 Aug 2023 07:06:27 GMT</pubDate>
    </item>
    <item>
      <title>借助新的 GPT-3.5 Turbo 微调功能，是否可以要求 GPT 输出仅关注或基于输入（微调）文件的答案？</title>
      <link>https://www.reddit.com/r/GPT3/comments/15yra3m/with_the_new_gpt35_turbo_fine_tuning_feature_is/</link>
      <description><![CDATA[大家好，通过新的 GPT-3.5 Turbo 微调功能，是否可以让 GPT 输出只关注或基于上传的输入（微调）文件，而不是任何其他数据，例如 GPT 训练所依据的截至 2021 年的数据？ 我有一个输入（微调）文件，其中包含更准确的数据，但我不知道不希望来自任何其他数据源的数据污染此输入（微调）文件中的数据。 非常感谢对此的任何输入！ &lt;!-- SC_ON - -&gt;  由   提交 /u/--leockl--   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15yra3m/with_the_new_gpt35_turbo_fine_tuning_feature_is/</guid>
      <pubDate>Wed, 23 Aug 2023 02:58:19 GMT</pubDate>
    </item>
    <item>
      <title>与 Bing AI 交谈</title>
      <link>https://www.reddit.com/r/GPT3/comments/15ylte1/talking_to_bing_ai/</link>
      <description><![CDATA[      这是su吗？   由   提交/u/dontfeedthebirdspls   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15ylte1/talking_to_bing_ai/</guid>
      <pubDate>Tue, 22 Aug 2023 23:05:27 GMT</pubDate>
    </item>
    <item>
      <title>用于您自己的 SaaS 产品的 OpenCopilot AI Copilot,下载OpenCopilot AI Copilot的源码_GitHub_酷徒适合所有人的开源人工智能助手。</title>
      <link>https://www.reddit.com/r/GPT3/comments/15xxgdo/github_openchataiopencopilot_ai_copilot_for_your/</link>
      <description><![CDATA[   /u/gharbat   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15xxgdo/github_openchataiopencopilot_ai_copilot_for_your/</guid>
      <pubDate>Tue, 22 Aug 2023 06:44:59 GMT</pubDate>
    </item>
    <item>
      <title>GPT-3 不成为操作系统是一件好事吗？</title>
      <link>https://www.reddit.com/r/GPT3/comments/15xthnl/is_gpt3_not_being_os_a_good_thing/</link>
      <description><![CDATA[只是想知道你们对这个问题的看法。它不开源是一件好事吗？或者说这是一件坏事。嘿，我很好奇你的答案。 另外，如果我不问的话，我至少不会知道这个问题的答案。   由   提交/u/jackyboyman13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15xthnl/is_gpt3_not_being_os_a_good_thing/</guid>
      <pubDate>Tue, 22 Aug 2023 03:26:58 GMT</pubDate>
    </item>
    <item>
      <title>Langchain：2 分钟解释</title>
      <link>https://www.reddit.com/r/GPT3/comments/15xj90d/langchain_explained_in_2_minutes/</link>
      <description><![CDATA[没有库存图片/视频、没有 gif 和华而不实的文本。只有纯粹的技术深入探讨。 这是关于 Langchain 的最快但深入的解释视频，Langchain 是一个日益流行的框架。  https://www.youtube.com/watch?v=C9bE8bHcJVI 使用 Langchain 是创建和测试基于 LLM 的高级 AI 应用程序的最快方法之一。看看吧！   由   提交/u/ComplianceRise569   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15xj90d/langchain_explained_in_2_minutes/</guid>
      <pubDate>Mon, 21 Aug 2023 20:35:03 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 效应：生成式 AI 如何塑造工作的未来</title>
      <link>https://www.reddit.com/r/GPT3/comments/15xhvgw/the_chatgpt_effect_how_generative_ai_is_shaping/</link>
      <description><![CDATA[   根据 LinkedIn，ChatGPT 引发了人工智能相关职位发布的大幅增长和简介，而 IBM 发布了一份报告，展示了人工智能如何日益成为业务绩效和创新的强大驱动力如果您想了解人工智能和技术的最新趋势和见解，先看这里。 https://preview.redd.it/16prop3ynijb1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=a8f8ddecc94d9dc77992ce00d5c61131 42f3a285  为什么这很重要：   ChatGPT 正在创造对人工智能技能的巨大需求：自 2022 年 11 月推出 ChatGPT 以来，英语全球范围内，与 GPT 或 ChatGPT 等 AI 技术相关的职位发布数量增加了 21 倍。 IBM 展示了如何利用 AI 实现业务成功：基于对全球 3,000 名受访者的调查通过对高管和 21,000 名员工的调查，IBM 发现组织财务成功的秘诀是重新思考其运营模式并思考人机合作伙伴关系 人工智能并不是要取代人类，而是要增强人类能力： IBM 很清楚，如果雇主想要成功地尝试人工智能，他们需要让员工参与到这个过程中，并与他们进行坦诚的对话，告诉他们人工智能并不是为了抢走他们的工作，而是为了增强他们的能力，让他们变得更好。 .  一些有趣的事实：   新加坡、芬兰、爱尔兰、印度和加拿大的 LinkedIn 用户将 AI 技能归因于自己：特别是，这些国家/地区的 LinkedIn 用户在个人资料中提及生成式 AI 关键字（例如“GAI”、“ChatGPT”、“Prompt Engineering”、“Prompt Crafting”）的次数有所增加。自年初以来每月增长 75%。 美国的人工智能在技术、信息和媒体领域最为常见：该领域占 2.2%美国所有人工智能类别中，其次是教育（1.2%）、服务业（0.9%）、金融服务（0.9%）和制造业（0.8%）。在美国，“人工智能主管”职位的数量在过去三年中几乎增加了两倍。 结果必须定义运营（而不是相反）：IBM 建议在使用人工智能时，公司应该专注于目标，而不是任务。这意味着公司不应将不良流程自动化，而应重新思考其工作流程并使其与预期结果保持一致。  P.S.如果你喜欢这种分析，我写免费时事通讯，涵盖人工智能和技术的最新趋势和见解。   由   提交 /u/AIsupercharged   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15xhvgw/the_chatgpt_effect_how_generative_ai_is_shaping/</guid>
      <pubDate>Mon, 21 Aug 2023 19:45:15 GMT</pubDate>
    </item>
    <item>
      <title>有人使用 Orca 风格的数据集微调过 text-davinci-003 吗？</title>
      <link>https://www.reddit.com/r/GPT3/comments/15xfvqt/have_anyone_fine_tuned_textdavinci003_using_some/</link>
      <description><![CDATA[只是出于好奇......有没有人曾经在遵循 orca 论文中所说的数据集上微调过闭源 openai 模型？  我知道它非常昂贵而且可能毫无意义，但我想知道是否有人测试过它。我真的很好奇它能产生什么样的结果 提前谢谢...   由   提交 /u/Distinct-Target7503    reddit.com/r/GPT3/comments/15xfvqt/have_anyone_fine_tuned_textdavinci003_using_some/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15xfvqt/have_anyone_fine_tuned_textdavinci003_using_some/</guid>
      <pubDate>Mon, 21 Aug 2023 18:32:10 GMT</pubDate>
    </item>
    </channel>
</rss>