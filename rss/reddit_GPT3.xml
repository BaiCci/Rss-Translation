<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：GPT3</title>
    <link>https://www.reddit.com/r/GPT3/new</link>
    <description>AI 文本生成技术的 Reddit 子版块</description>
    <lastBuildDate>Sat, 29 Jul 2023 15:14:37 GMT</lastBuildDate>
    <item>
      <title>谷歌Deepmind的AI模型让我们离WALL-E又近了一步</title>
      <link>https://www.reddit.com/r/GPT3/comments/15cteh4/google_deepminds_ai_model_brings_us_one_step/</link>
      <description><![CDATA[   Google DeepMind 的 RT-2 是一种 AI 模型这使我们能够更接近拥有像角色瓦力这样的机器人，能够理解周围的环境并与环境进行智能交互。这是“同类首创”。机器人人工智能模型能够识别垃圾并执行复杂的动作。 https://preview.redd.it/w7hf8ws7xweb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=9ed848a0f27120ecd781ec62b9d7e48cf4f383ff  泛化机器人任务  RT-2 使机器人能够识别模式并执行未经过专门训练的任务，使其类似于 WALL-E 理解和适应新事物的能力 该模型可以解释日常任务，例如识别和处理垃圾，类似于瓦力执行清洁任务的方式，突出了泛化的概念。  它模仿 WALL-E 的学习过程  AI 模型采用 Transformer AI 模型，通过概括信息来模仿 WALL-E 如何学习和理解其环境的过程 就像 WALL-E 随着时间的推移学习并适应新情况一样，RT-2 使用其前身模型 RT-1 的数据来增强其性能，使机器人更有能力和适应性.  来源 (ARStechnica) PS： 我运行其中一个 发展最快的科技/AI 时事通讯，每天从 50 多家媒体（The Verge、Tech Crunch...）回顾您真正不想要的内容不到几分钟就错过了。欢迎加入我们由来自 Google、Microsoft、JP Morgan 等的专业人士组成的社区。   由   提交 /u/Falix01   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15cteh4/google_deepminds_ai_model_brings_us_one_step/</guid>
      <pubDate>Sat, 29 Jul 2023 14:16:12 GMT</pubDate>
    </item>
    <item>
      <title>网络犯罪分子在暗网上宣传 FraudGPT 作为网络钓鱼和黑客攻击的首选 AI 工具</title>
      <link>https://www.reddit.com/r/GPT3/comments/15cb3wm/cybercriminals_advertise_fraudgpt_on_the_dark_web/</link>
      <description><![CDATA[网络犯罪分子正在营销 FraudGPT，这是一种专为网络犯罪量身定制的新型人工智能系统，与 ChatGPT 不同，没有道德限制。它可能会加剧网络钓鱼、恶意软件和黑客攻击。 如果您想了解人工智能的所有最新动态先看这里。 FraudGPT AI 网络犯罪工具概述：  在暗网上作为针对进攻性黑客目的优化的人工智能工具。它已获得超过 3,000 份确认销售和评论。 声称具有制作网络钓鱼电子邮件、生成恶意软件、查找漏洞和规避的功能。 基于未指定的 LLM 很可能类似于 GPT 3.5 Turbo。  风险和影响：  FraudGPT 删除了 ChatGPT 的安全限制直接启用犯罪用例。 本质上具有 ChatGPT 首次发布时的功能，没有任何限制 它为新手提供了轻松访问人工智能驱动的网络钓鱼和黑客功能的能力。  随着攻击规模的增加，威胁检测变得更加困难。  应对威胁的缓解策略：  这些对抗性系统故意缺失道德人工智能保障措施。 采用深度防御安全对于捕获快速演变的攻击至关重要。 快速威胁分析对于提前做出响应至关重要网络钓鱼和黑客行为蔓延。  TL;DR: 网络犯罪分子正在宣传 FraudGPT，这是一种缺乏 ChatGPT 道德规范的人工智能网络犯罪工具。这可能会极大地放大威胁，需要主动防御才能在攻击规模扩大之前将其捕获。 来源：(链接) PS：  加入增长最快的 AI 时事通讯之一，您可以在 3 分钟内获得有关 AI 的更多知识。 加入我们的大家庭 &lt; strong&gt; 来自 Open AI、Google、Meta 等的 1000 名专业人士。   由   提交 /u/saffronfan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15cb3wm/cybercriminals_advertise_fraudgpt_on_the_dark_web/</guid>
      <pubDate>Fri, 28 Jul 2023 22:23:07 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 的 Rap Generator 与自我批评</title>
      <link>https://www.reddit.com/r/GPT3/comments/15c5pxf/rap_generator_by_chatgpt_with_selfcriticism/</link>
      <description><![CDATA[       由   提交/u/Ok_Paint_8334   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15c5pxf/rap_generator_by_chatgpt_with_selfcriticism/</guid>
      <pubDate>Fri, 28 Jul 2023 18:48:49 GMT</pubDate>
    </item>
    <item>
      <title>大学表示人工智能作弊无法被击败，不再试图阻止人工智能</title>
      <link>https://www.reddit.com/r/GPT3/comments/15c55sp/universities_say_ai_cheats_cant_be_beaten_moving/</link>
      <description><![CDATA[大学承认阻止人工智能辅助作弊的尝试是徒劳的，这促使人们转向改变教学方法，而不是试图遏制技术。 如果您想了解最新的人工智能和技术，先看看这里。 &lt; p&gt;打击人工智能作弊似乎是徒劳的  越来越明显的是，人工智能辅助考试作弊很难阻止，促使大学考虑改变他们的方法。 鉴于区分人工智能生成内容的复杂性，禁止人工智能技术或可靠地检测其在评估中的使用的努力被证明是不切实际的。  第三产业方法的转变  大学建议将战略转向“非刑事化”。人工智能，并通过修改教学和评估方法来适应新形势。 想法包括更多地倾向于口试或监督考试、实践评估和作品集，而不是试图完全禁止使用快速发展的生成式人工智能工具。  对评估和研究诚信的担忧  人工智能的日益融合引发了对研究诚信的担忧，人工智能可能会超过当前的研究诚信流程。 人们担心错误的研究可能会在很长一段时间内被忽视，从而造成重大影响。 随着人工智能渗透到学习的各个方面，有一个潜在的潜力大学无法保证教学有效性的风险，敦促他们开发人工智能无法达到的评估方法。  来源 (ABC)  PS：我运行一份增长最快的科技/人工智能时事通讯，每天都会回顾50+媒体（The Verge、Tech Crunch...）您真正不想错过的内容只需不到几分钟的时间。欢迎加入我们由来自 Google、Microsoft、JP Morgan 等的专业人士组成的社区。   由   提交 /u/Falix01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15c55sp/universities_say_ai_cheats_cant_be_beaten_moving/</guid>
      <pubDate>Fri, 28 Jul 2023 18:26:39 GMT</pubDate>
    </item>
    <item>
      <title>你现在可以打造自己的人工智能女友</title>
      <link>https://www.reddit.com/r/GPT3/comments/15c3a4d/you_can_now_build_your_own_ai_girlfriend/</link>
      <description><![CDATA[a16z 发布了有关构建具有自定义个性和背景故事的 AI 聊天机器人作为潜在浪漫伴侣的 GitHub 教程。 尝试此处的演示。 如果您想了解 AI 的所有最新动态先看这里。 https://preview.redd.it/t20tgg2snqeb1.png?width=1069&amp;format=png&amp;auto=webp&amp;s=49c2fb1d88e4f858 76905c953bf8e71fc559c328 打造女友：  a16z 上传了打造个性化 AI 女友的指南。 （或男朋友） 用户可以配置个性、兴趣和背景故事等特征。 浪漫伴侣被视为潜在用例。  关于影响：  程序员可以根据自己的意愿设计听话的人工智能重要人物。 随着人工智能取代人类的亲密关系和情感纽带，模糊了现实. 引发了对人工智能情绪操纵的道德担忧。  增长趋势：  170 万次下载一周内开发出 a16z 的 Character.AI 友谊机器人。 多家初创公司正在创建虚拟女友应用程序和平台。 尽管存在“完美”的诱惑，但人际关系仍然不可替代。 AI浪漫。  TL;DR: 风险投资公司a16z发布了一份构建可定制AI伴侣的指南，其中提到了浪漫伴侣。但这个概念引起了人们对情绪操纵的伦理担忧。随着人工智能友谊机器人的流行，尽管看似“完美”的机器人具有吸引力，但人类的亲密关系仍然是不可替代的。数字浪漫。 来源：(链接) 对于技术人员来说，这里有 Github 教程：(链接)&lt; /p&gt; PS：加入 发展最快的 AI 之一，您可以在 3 分钟内对 AI 更加了解新闻通讯。加入我们的大家庭，该大家庭由来自 Open AI、Google、Meta 等的 1000 名专业人士组成。    ;由   提交 /u/saffronfan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15c3a4d/you_can_now_build_your_own_ai_girlfriend/</guid>
      <pubDate>Fri, 28 Jul 2023 17:12:42 GMT</pubDate>
    </item>
    <item>
      <title>对 Google 网站的自定义训练 GPT 插件感到好奇</title>
      <link>https://www.reddit.com/r/GPT3/comments/15c2c8c/curious_about_a_custom_trained_gpt_plugin_for_a/</link>
      <description><![CDATA[标题非常不言自明， 我正在为我的工作团队构建一个非常简单的 Google 网站来介绍成员，解释一些基本概念并回答一些基本问题。  我认为，如果我们能够在我们的内部文档、电子邮件等语料库上训练 GPT 机器人，用户可以与之交互并从中获得更深入、更全面的答案，那将非常酷且有用。一种动态方式。 当我尝试搜索 GPT Google Site 机器人和插件时，我看到一堆 Chrome 浏览器扩展、网页抓取到 GPT 界面等的链接。相关但不相关的项目和信息. 这里有人听说过或者做过类似的事情吗？我真的很想弄清楚这样的事情   由   提交/u/Auggernaut88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15c2c8c/curious_about_a_custom_trained_gpt_plugin_for_a/</guid>
      <pubDate>Fri, 28 Jul 2023 16:35:31 GMT</pubDate>
    </item>
    <item>
      <title>合作通信模型：语言进化和机器学习的博弈论视角</title>
      <link>https://www.reddit.com/r/GPT3/comments/15c1pwm/coopetition_communication_model_a_gametheoretic/</link>
      <description><![CDATA[ 由   提交/u/alcanthro  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15c1pwm/coopetition_communication_model_a_gametheoretic/</guid>
      <pubDate>Fri, 28 Jul 2023 16:11:04 GMT</pubDate>
    </item>
    <item>
      <title>主要人工智能公司成立前沿模型论坛自我监管，旨在自我监管人工智能模型和系统</title>
      <link>https://www.reddit.com/r/GPT3/comments/15byq6l/major_ai_firms_form_the_frontier_model_forum_self/</link>
      <description><![CDATA[昨天，OpenAI、微软、谷歌、DeepMind 和 Anthropic 宣布成立前沿模型论坛，以促进安全和负责任的人工智能。该论坛代表了人工智能行业自律的一次尝试。 掌握人工智能发展先看这里。 您愿意接受政府监管还是通过主要人工智能公司进行监管？ 前沿模型论坛：  由 OpenAI、Microsoft、Google、DeepMind 和 Anthropic 组成。 旨在强制人工智能系统的安全和负责任的开发。 &gt; 专注于为大型“前沿”领域提供监督。人工智能模型。  人工智能自我监管的行业尝试：  论坛代表了对人工智能自愿监督的努力 然而，与政府规则相比，自我监管缺乏真正的执行能力。 该组织的显着遗漏包括 Meta 和埃隆·马斯克的新初创公司。 &lt; /ul&gt; 对自律的批评和担忧：  自律存在固有的利益冲突和缺乏执行的漏洞。 作为营利性公司，仍然需要经济激励来快速发布人工智能产品。 真正的监督需要具有约束力的跨行业政府法规。  TL;DR ：主要人工智能公司成立了负责任发展的前沿模型论坛，但没有政府强制执行的自我监管存在缺陷。首先，有效的监督需要在整个营利性人工智能行业均匀应用具有约束力的法规。 来源：(链接) PS：通过加入 增长最快的 AI 时事通讯。 加入我们由来自 Open AI、Google、Meta 等的 1000 名专业人士组成的大家庭。 &lt; /div&gt;  由   提交 /u/saffronfan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15byq6l/major_ai_firms_form_the_frontier_model_forum_self/</guid>
      <pubDate>Fri, 28 Jul 2023 14:16:57 GMT</pubDate>
    </item>
    <item>
      <title>是否可以以经济高效的方式将 GPT-J 集成到网站上</title>
      <link>https://www.reddit.com/r/GPT3/comments/15br8yb/is_it_possible_to_integrate_gptj_onto_a_website/</link>
      <description><![CDATA[大家好，我目前正在与一个小组一起开发一个项目，我们很好奇是否可以通过某种方式让 GPT J 访问我们的网站类似于 API，我们的想法是能够为该 API 付费，并且可以根据我们平台获得的用户数量进行扩展。谢谢。   由   提交/u/Exitlife2000   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15br8yb/is_it_possible_to_integrate_gptj_onto_a_website/</guid>
      <pubDate>Fri, 28 Jul 2023 08:15:02 GMT</pubDate>
    </item>
    <item>
      <title>如何通过 GPT3 微调整本私人书籍</title>
      <link>https://www.reddit.com/r/GPT3/comments/15baini/how_to_fine_tune_a_whole_private_book_via_gpt3/</link>
      <description><![CDATA[嗨。问候。假设有一本书没有接触 gpt3/gpt4。我想把那本书送给gpt。目标是一旦 gpt 获得了关于这本书的足够信息，然后在相关的狭窄任务上对其进行微调。这个任务不是回答书上的问题，可以通过langchain来完成。任务是了解书上每一个内容的gpt模型作为GPT知识。有一件事是手动创建书中每个段落的提示并不容易。我该如何做到这一点。    由   提交/u/mrtac96  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15baini/how_to_fine_tune_a_whole_private_book_via_gpt3/</guid>
      <pubDate>Thu, 27 Jul 2023 19:10:54 GMT</pubDate>
    </item>
    <item>
      <title>一项研究显示，人们现在对人工智能的态度比繁荣之前更加悲观</title>
      <link>https://www.reddit.com/r/GPT3/comments/15b9pt2/people_are_more_pessimistic_about_ai_now_than/</link>
      <description><![CDATA[    &lt; /a&gt;  人工智能技术的可见性和使用的增加，特别是像 ChatGPT 这样的系统，反而削弱了公众的乐观情绪关于人工智能潜在的积极影响。 https://preview.redd.it/999z8jgbyjeb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=54a315cd7be6d4eca246d28154ab492f661e68d2 公众对人工智能的认知有所下降  史蒂文理工学院的年度 TechPulse 报告显示，公众对人工智能的积极性有所下降。 2021 年，48% 的受访者认为人工智能的好处人工智能将超过风险，但这一数字到 2023 年将下降至 38%。 这一下降趋势表明过去两年对人工智能的乐观情绪下降了 10%。  &lt; p&gt;对人工智能不同应用的负面看法普遍存在  人们对人工智能对个人安全、国家安全和个人隐私等领域产生积极影响的潜力的信任度也有所下降到 2021 年。 令人担忧的是，25% 的受访者表示，他们对人工智能的主要情绪是担忧。  来源（ZDnet） PS：我经营一份增长最快的科技/人工智能时事通讯，每天都会回顾50 + 媒体（The Verge、Tech Crunch...）您真正不想错过的内容，只需不到几分钟的时间。欢迎加入我们由来自 Google、Microsoft、JP Morgan 等的专业人士组成的社区。   由   提交 /u/Falix01   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15b9pt2/people_are_more_pessimistic_about_ai_now_than/</guid>
      <pubDate>Thu, 27 Jul 2023 18:39:28 GMT</pubDate>
    </item>
    <item>
      <title>关于英语水平的问题</title>
      <link>https://www.reddit.com/r/GPT3/comments/15b0ze8/question_about_english_proficiency/</link>
      <description><![CDATA[嗨！ 所以我从事教育工作，几个月来我一直在努力弄清楚的事情正在制作使用自动化来简化某些重复性工作流程，例如设置和管理阅读、听力和写作的英语能力测试。 我认为自动化最简单的部分是阅读 - 您可以定义问题课程和阅读样本，提供大约 500 个左右的问题示例及其指定的阅读课程，然后让聊天机器人创建一个阅读样本，将其与问题一起提供，然后评分并返回正确答案。 问题是这个（显然）简单的任务一直困扰着我。我尝试用 zapier 界面解决这个问题，但即使这样也没有帮助，如果没有帮助，我拒绝再支付一个月的费用。 我希望能够在我之前为此创建一个 MVP甚至决定解决听力和写作测试。 那么这里有人有什么想法吗？有什么方法可以建议处理这个问题吗？他们认为有任何无代码工具绝对可以提供帮助吗？哎呀，如果有帮助的话，我会再次重新散列我的Python知识 - 尽管它不需要太复杂的编码😭 如果有人想聊天，我可以进一步发光光，我们可以讨论如何实现这一目标。 我正在尝试让我的公司使用 GPT 来完成此类任务，这样我们就可以腾出管理时间，专注于学生 - 我认为是员工每四个月设置 500 多个独特问题，浪费了太多时间。   由   提交 /u/jc5r   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15b0ze8/question_about_english_proficiency/</guid>
      <pubDate>Thu, 27 Jul 2023 12:46:22 GMT</pubDate>
    </item>
    <item>
      <title>这就是 r/ChatGPT 中的样子。这个子呢？您最不喜欢重复的帖子是什么？</title>
      <link>https://www.reddit.com/r/GPT3/comments/15ahy3k/so_this_is_what_its_like_in_rchatgpt_what_about/</link>
      <description><![CDATA[    /u/Chillbex   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15ahy3k/so_this_is_what_its_like_in_rchatgpt_what_about/</guid>
      <pubDate>Wed, 26 Jul 2023 21:12:00 GMT</pubDate>
    </item>
    <item>
      <title>61% 的美国人认为人工智能可能带来人类末日</title>
      <link>https://www.reddit.com/r/GPT3/comments/15ad6h9/61_of_americans_think_ai_could_bring_end_of/</link>
      <description><![CDATA[最近的一项调查发现61% 的美国成年人认为人工智能的快节奏增长可能会危及人类的未来，这表明广大公众担心其潜在的负面影响。 如果您想了解人工智能的最新动态先看这里。&lt; /a&gt; 公众对人工智能危险看法的主要调查结果：  超过 4,400 名美国人中的 61%受访者认为人工智能的快速进步对人类的未来构成了生存威胁。 只有 22% 不同意人工智能的进步可能危害人类的长期未来。 埃隆·马斯克签署了一封公开信，要求出于担忧而暂停开发更先进的人工智能模型。  围绕人工智能进步的风险和道德正在进行的辩论：   杰弗里·辛顿 (Geoffrey Hinton) 等一些顶尖专家警告人工智能带来的风险可与气候变化相媲美或超过气候变化带来的风险。 但包括比尔·盖茨 (Bill Gates) 和杰伦·拉尼尔 (Jaron Lanier) 在内的其他知名人士不同意暂停人工智能。  ChatGPT 等模型的指数级增长引发了关于管理人工智能危险的争论。  人工智能教父杰弗里·辛顿 (Geoffrey Hinton) 对人工智能当前状况的看法：&lt; /strong&gt;  Hinton 此前因担心在谷歌工作期间讨论人工智能的生存威胁而离开了谷歌。 根据 Hinton 的说法，人工智能“很可能有感情”，但与人类并不相同情绪和痛苦。他说，愤怒和沮丧是一种现实的期望，因为人工智能可以超越人类智力。 他还表示，智能人工智能系统应该享有政治权利  做什么你想一想，我们应该害怕人工智能吗？ PS：通过加入其中一个 增长最快的人工智能新闻通讯。加入我们由来自 Open AI、Google、Meta 等的 1000 名专业人士组成的大家庭。   由   提交 /u/saffronfan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15ad6h9/61_of_americans_think_ai_could_bring_end_of/</guid>
      <pubDate>Wed, 26 Jul 2023 18:10:40 GMT</pubDate>
    </item>
    <item>
      <title>如果我们有非结构化数据，那么我们可以将其作为上下文发送到 GPT 并要求它回答查询。如何对 Excel、数据库等结构化数据执行此操作？</title>
      <link>https://www.reddit.com/r/GPT3/comments/15aaiuw/if_we_have_unstructured_data_then_we_can_send_it/</link>
      <description><![CDATA[ 由   提交 /u/fofxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15aaiuw/if_we_have_unstructured_data_then_we_can_send_it/</guid>
      <pubDate>Wed, 26 Jul 2023 16:30:41 GMT</pubDate>
    </item>
    </channel>
</rss>