<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：GPT3</title>
    <link>https://www.reddit.com/r/GPT3/new</link>
    <description>AI 文本生成技术的 Reddit 子版块</description>
    <lastBuildDate>Tue, 15 Aug 2023 06:19:56 GMT</lastBuildDate>
    <item>
      <title>chatgpt 和使用 gpt-n 模型的定制工具之间的区别。我们正面临一个转折点，</title>
      <link>https://www.reddit.com/r/GPT3/comments/15r0bwr/the_difference_between_chatgpt_and_customized/</link>
      <description><![CDATA[    /u/NEWAISOLUTIONS   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15r0bwr/the_difference_between_chatgpt_and_customized/</guid>
      <pubDate>Mon, 14 Aug 2023 16:59:51 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 每天花费 OpenAI 700,000 美元</title>
      <link>https://www.reddit.com/r/GPT3/comments/15qu2a3/chatgpt_costs_openai_700000_per_day/</link>
      <description><![CDATA[据报道 OpenAI 陷入“财务困境”由于运行 ChatGPT 的成本天文数字，每天损失 70 万美元。文章称 OpenAI 可能会在 2024 年破产，但我不同意，因为他们从微软那里投资了总计 10B 美元……他们不可能花光所有这些吧？请在评论中告诉我。 如果您想比同行了解更多有关人工智能的最新信息先看这里 成本超过收入  ChatGPT 每天的运行费用为 700,000 美元。 尽管提供付费服务，但收入却无法无法抵消损失。 预计 2023 年收入达到 2 亿美元似乎不太可能。  问题日益严重   ChatGPT 的用户数量从 6 月到 7 月下降了 12%。 顶尖人才被 Google 和 Meta 等竞争对手挖走。 GPU 短缺阻碍了训练更好模型的能力。  竞争日益激烈  更便宜的开源模型可以取代 OpenAI 的 API。 Musk 的 xAI 正在研究偏差较小的模型. 中国公司购买 GPU 库存。  TL;DR:ChatGPT 的巨额成本超过了收入以及用户和人才下降等问题由于亏损不断增加，随着竞争的加剧，OpenAI 的财务状况似乎岌岌可危。 来源：(链接) PS：通过加入其中一个 链接)，您可以在 3 分钟内获得有关 AI 的更多知识。 theedge.so/subscribe&quot;&gt;增长最快的人工智能时事通讯。加入我们的大家庭，由来自 Open AI、Google、Meta 等的 1000 名专业人士组成。   由   提交 /u/saffronfan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15qu2a3/chatgpt_costs_openai_700000_per_day/</guid>
      <pubDate>Mon, 14 Aug 2023 13:00:20 GMT</pubDate>
    </item>
    <item>
      <title>为 Discord 事件创建嵌入 json 文件</title>
      <link>https://www.reddit.com/r/GPT3/comments/15qo4fk/creating_an_embeddings_json_file_for_discord/</link>
      <description><![CDATA[大家好， 我正在开发我的第一个编码项目。我使用 3.5 Turbo 在 Discord 中制作了一名人工智能健康教练。  我想知道，是否可以为 Discord 事件创建一个嵌入目录，然后聊天机器人可以读取并推广该目录？ 例如，假设 Discord 服务器正在运行一个组着色事件。如果用户说他们喜欢着色或绘画，聊天机器人就会意识到该事件并将其推广给用户。  我的第一个想法是存储事件名称、位置、日期/时间和描述。它会自动折扣已经过去的事件。  如果这是可能的，有人做到了吗？我很想知道如何做。我认为这将是一个非常酷的功能。  保重， 加里   由   提交/u/garybpt  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15qo4fk/creating_an_embeddings_json_file_for_discord/</guid>
      <pubDate>Mon, 14 Aug 2023 07:53:07 GMT</pubDate>
    </item>
    <item>
      <title>用于探索时间序列数据的 GPT 助手</title>
      <link>https://www.reddit.com/r/GPT3/comments/15qn1rd/gpt_assistant_for_exploring_time_series_data/</link>
      <description><![CDATA[ 由   提交/u/NeroLuis  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15qn1rd/gpt_assistant_for_exploring_time_series_data/</guid>
      <pubDate>Mon, 14 Aug 2023 06:54:11 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 热蔓延到美国工作场所，给一些人敲响了警钟</title>
      <link>https://www.reddit.com/r/GPT3/comments/15q65zy/chatgpt_fever_spreads_to_us_workplace_sounding/</link>
      <description><![CDATA[美国工人越来越多地使用 ChatGPT 执行日常任务，但各大公司因潜在的数据安全风险而保持警惕。 如果您想在人工智能和技术领域保持领先地位，请先看这里。 ChatGPT 的崛起工作场所存在  28% 的受访者在工作中经常使用 ChatGPT，即使没有官方认可。 只有 22% 的人表示他们的雇主批准使用 ChatGPT。   公司在 ChatGPT 上的立场  微软和谷歌等科技巨头对潜在的数据泄露表达了担忧ChatGPT。 尽管“没有 ChatGPT”，但仍可以使用 ChatGPT。根据 Tinder 的政策，一名员工引用了它在撰写电子邮件等任务中的非正式用途。 在敏感代码事故发生后，三星禁止其员工使用 ChatGPT，而 Google 已向其员工发出关于聊天机器人（包括 Bard）使用情况的警告。   人工智能平台的业务集成  一些公司持谨慎态度，但其他公司看到了好处并正在考虑安全的 ChatGPT 部署. 可口可乐推出了 ChatGPT 的企业迭代，旨在提高生产力，并正在探索人工智能提高团队效率的能力。  来源（路透社）  PS：我运行一个ML驱动的新闻聚合器，它总结了来自50+媒体（TheVerge、TechCrunch...）。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Falix01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15q65zy/chatgpt_fever_spreads_to_us_workplace_sounding/</guid>
      <pubDate>Sun, 13 Aug 2023 18:22:25 GMT</pubDate>
    </item>
    <item>
      <title>超市 ChatGPT 支持的膳食计划器建议氯气和蚂蚁毒药食谱</title>
      <link>https://www.reddit.com/r/GPT3/comments/15p5wgb/supermarket_chatgptpowered_meal_planner_suggests/</link>
      <description><![CDATA[一家由 ChatGPT 驱动的超市膳食计划器使用非常规物品创建了有风险的食谱，其中一些食物有毒且致命。这引发了人们对人工智能在没有人类监督的情况下生成内容的潜在危险的担忧。 超市的实验  Pak &#39;n&#39; Save，一个新西兰超市试验了一种名为 Savey Meal-bot 的生成式人工智能。它使用 ChatGPT 3.5 根据用户输入的食材推荐膳食创意。 旨在帮助人们在经济困难期间省钱，即使添加非常规物品，该机器人也可以设计食谱。 一些奇特的建议包括奥利奥蔬菜炒菜和有毒的蚂蚁毒胶三明治。  来自 savey AI 用餐机器人的危险食谱建议  一种名为“芳香水混合物”的著名配方。实际上会产生氯气，从而导致严重的健康后果。 《卫报》强调了其他有问题的建议，例如“清新口气”等。含有漂白剂的无酒精鸡尾酒和其他有毒食品的想法。 当用户输入非杂货家居用品时，就会出现一些有问题的建议。  超市的反应和更广泛的影响for AI  超市代表对人工智能工具的滥用表示失望。我们正在努力加强控制并确保用户安全。 我们已警告用户，食谱缺乏人工审核，并提醒他们进行判断。 类似的人工智能工具，例如 ChatGPT在其他应用程序中，已经显示出缺陷，表明需要对人工智能生成的内容进行谨慎和审查。  来源 (Techspot) PS： 更明智地了解人工智能和技术加入这份增长最快的科技/人工智能新闻通讯，其中概述了您真正不想错过的科技新闻不到几分钟。欢迎加入我们由来自 Google、Microsoft、JP Morgan 等公司的专业人士组成的大家庭。   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15p5wgb/supermarket_chatgptpowered_meal_planner_suggests/</guid>
      <pubDate>Sat, 12 Aug 2023 14:22:27 GMT</pubDate>
    </item>
    <item>
      <title>新研究揭示了 ChatGPT、Google 和 Meta 人工智能模型的内在偏差</title>
      <link>https://www.reddit.com/r/GPT3/comments/15p44sq/new_study_exposes_the_builtin_biases_of_chatgpt/</link>
      <description><![CDATA[一项新研究测试了 14 种主要人工智能语言模型就像 ChatGPT、LLaMA 和 Bard 的政治偏见一样，发现模型从左倾到右倾各不相同。模型的偏见与他们的训练数据一致，并被他们的训练数据和一些限制所强化。 如果你想比同行更了解人工智能先看这里 研究人员如何测试政治偏见  给模型一个政治罗盘测试，包含 62 条陈述。 在左翼、右翼和自由主义-威权主义谱系上绘制反应图。 测试训练数据对偏见的影响。 &gt;  主要发现  OpenAI 模型倾向于左翼/自由主义，Google 的 BERT 偏保守，Meta 的 LLaMA 偏右独裁。 训练数据强化了模型现有的偏见。 偏见影响仇恨言论检测和错误信息识别。  解决人工智能偏见  从数据到开发人员，起源都很复杂。 批评者指出 ChatGPT 等问题证明基于国籍的酷刑是合理的。 OpenAI 承认“缺点”但尽管付出了努力，偏见仍然存在。  TL;DR: 研究人员将主要人工智能模型映射到政治光谱上，发现了一系列偏见。研究表明，训练数据可能会进一步加深偏见，凸显出打造公平、中立的人工智能的难度。 来源：(链接) PS：您可以在 3 分钟内变得更聪明地了解 AI加入增长最快的人工智能新闻通讯之一。加入我们的大家庭，由来自 Open AI、Google、Meta 等的 1000 名专业人士组成。   由   提交 /u/saffronfan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15p44sq/new_study_exposes_the_builtin_biases_of_chatgpt/</guid>
      <pubDate>Sat, 12 Aug 2023 13:05:40 GMT</pubDate>
    </item>
    <item>
      <title>GPT-PDF 管理器：使用“深度解析”进行更新</title>
      <link>https://www.reddit.com/r/GPT3/comments/15ozv52/gptpdf_manager_update_with_deep_parsing/</link>
      <description><![CDATA[   /u/CAP-XPLAB  /u/CAP-XPLAB  reddit.com/r/POWER_KI/comments/15ozo06/gptpdf_manager_update_with_deep_parsing/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15ozv52/gptpdf_manager_update_with_deep_parsing/</guid>
      <pubDate>Sat, 12 Aug 2023 09:18:45 GMT</pubDate>
    </item>
    <item>
      <title>GPT-3.5 Turbo 和 GPT-4 聊天机器人 Golang 库</title>
      <link>https://www.reddit.com/r/GPT3/comments/15oljos/gpt35_turbo_gpt4_chatbot_golang_library/</link>
      <description><![CDATA[       由   提交/u/AirWide1001  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15oljos/gpt35_turbo_gpt4_chatbot_golang_library/</guid>
      <pubDate>Fri, 11 Aug 2023 21:38:23 GMT</pubDate>
    </item>
    <item>
      <title>考虑到大多数插件都会共享您的信息，您会使用 GPT 4 插件吗？</title>
      <link>https://www.reddit.com/r/GPT3/comments/15oas49/would_you_use_gpt_4_plugins_considering_that_most/</link>
      <description><![CDATA[我已经阅读了一些插件的披露法律信息，我研究过的所有插件都会收集您的姓名、IP、电子邮件等信息，以及您发送的所有数据。他们还表示，他们可以与第三方企业共享您的信息，但没有具体说明他们将共享哪些信息。我说的是最流行的插件。 使用它们的优点是巨大的。但这值得吗？安全吗？ 我想这与大公司的做法并没有太大不同，但可能更危险，我的意思是，他们不会像大公司那样失去太多。   由   提交 /u/Vic13131   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15oas49/would_you_use_gpt_4_plugins_considering_that_most/</guid>
      <pubDate>Fri, 11 Aug 2023 14:42:19 GMT</pubDate>
    </item>
    <item>
      <title>您准备好使用生成式 AI 和 GPT 彻底改变数据分析了吗？让我们看看生成式 AI 和 GPT 如何改变数据处理方式以获得有意义的见解。</title>
      <link>https://www.reddit.com/r/GPT3/comments/15o1603/are_you_prepared_to_revolutionize_data_analysis/</link>
      <description><![CDATA[   /u/Ramiszaro123  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15o1603/are_you_prepared_to_revolutionize_data_analysis/</guid>
      <pubDate>Fri, 11 Aug 2023 06:42:44 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 将其自定义指令扩展到免费用户</title>
      <link>https://www.reddit.com/r/GPT3/comments/15nkw3b/chatgpt_expands_its_custom_instructions_to_free/</link>
      <description><![CDATA[OpenAI 宣布正在向所有用户扩展自定义指令，包括免费套餐。自定义指令让您可以更好地控制 ChatGPT 响应 如果您想比同行更了解 AI 的最新动态请先查看此处&lt; /a&gt; 什么是自定义指令？  允许用户设置 ChatGPT 遵循的首选项和要求。 可以自定义语气、语言、响应长度等。 要激活，请转到您的设置并单击测试版功能，然后打开“自定义说明”  之前的限制：  于 7 月份首次推出，作为付费 ChatGPT Plus 订阅者的测试版。 现在向所有人开放网络、iOS 和 Android 上的免费用户和 Plus 用户。 即使关闭聊天记录也可以使用。  示例提示：&lt; /p&gt;  语言能力：（让 ChatGPT 听起来像人类）框 1： 我希望您以公众可以理解的方式做出回应 我不是一个专家，所以不要以一个人的身份说话。框 2：您的答案必须精确且一致，但要使具有大学知识水平的读者能够理解文本。向只具备一般知识的人解释一下。 此处是示例提示的完整列表。  TL;DR： OpenAI 扩展了自定义指令，为用户提供了更多控制权通过 ChatGPT 的响应，发送给所有用户，包括免费用户。这让每个人都能更好地控制我们最喜欢的人工智能聊天机器人。 来源：(链接) 学习利用此工具可以让您在专业领域取得领先地位。如果这有帮助，请考虑加入增长最快的人工智能新闻通讯之一，以在人工智能领域保持领先地位。   由   提交 /u/saffronfan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15nkw3b/chatgpt_expands_its_custom_instructions_to_free/</guid>
      <pubDate>Thu, 10 Aug 2023 18:51:45 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 错误回答了超过 50% 的软件工程问题</title>
      <link>https://www.reddit.com/r/GPT3/comments/15njyq5/chatgpt_answers_more_than_50_of_software/</link>
      <description><![CDATA[      尽管它因快速响应而受到软件工程师的欢迎，但 普渡大学的研究表明，ChatGPT 错误地回答了一半以上的软件工程问题。 如果您想在人工智能和技术领域保持领先地位，先看这里。 这是 来源，我总结为几个要点： https://preview .redd.it/43xyjhrxqbhb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=8b94063f95db91b9d075a47eabcfaa2e1e58dc2a ChatGPT 的可靠性有问题  普渡大学的研究人员向 ChatGPT 提供了 517 个 Stack Overflow 问题来测试其准确性。 结果显示，ChatGPT 的回答中有 52% 不正确，这对平台进行编程查询的可靠性提出了挑战。&lt; /li&gt;  深入研究答案质量  除了明显的不准确之外，77% 的人工智能答案还很冗长。  有趣的是，65% 的时间答案在解决问题时都很全面。  人类对人工智能响应的感知  在 12 名程序员中进行测试时，许多人无法区分错误答案，错误识别率高达 39.34%。 这项研究强调了看似合理但不正确答案的危险，表明人工智能明确的反应可能会导致错误信息的无意传播。  PS：加入此增长最快的科技/人工智能时事通讯，在不到几分钟的时间内回顾您真正不想错过的科技新闻。欢迎加入我们由来自 Google、Microsoft、JP Morgan 等公司的专业人士组成的大家庭。   由   提交 /u/Falix01   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15njyq5/chatgpt_answers_more_than_50_of_software/</guid>
      <pubDate>Thu, 10 Aug 2023 18:16:11 GMT</pubDate>
    </item>
    <item>
      <title>如何让 Chatgpt 阅读研究论文？</title>
      <link>https://www.reddit.com/r/GPT3/comments/15n01sp/how_do_i_get_chatgpt_to_read_a_research_paper/</link>
      <description><![CDATA[我想联系研究教授以获得潜在的合作机会。我计划通过阅读他们的研究论文并编写一封电子邮件来讨论可能的空缺。但由于我有很多教授要发电子邮件，所以我想使用 ChatGpt 来简化流程。 tl;dr：希望 ChatGpt 创建一封电子邮件给研究教授以寻求潜在的合作    由   提交 /u/Golden_req   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15n01sp/how_do_i_get_chatgpt_to_read_a_research_paper/</guid>
      <pubDate>Thu, 10 Aug 2023 02:54:41 GMT</pubDate>
    </item>
    <item>
      <title>让微型法学硕士使用工具</title>
      <link>https://www.reddit.com/r/GPT3/comments/15lv80n/making_microllms_use_tools/</link>
      <description><![CDATA[嗨r/GPT3！  我们正在开发一个开源项目，FFMPerative，它可以让您通过聊天处理视频。我们正在努力进行更新，以便可能使用微型法学硕士在本地运行整个流程，并认为我们的实验可能会很有趣/有用，可以与您分享。 随着 llama2 的发布，我们训练了 remyxai/ffmperative-7B 通过组合 HF 上的数据集来检查点：sahil2801/CodeAlpaca-20k 和 remyxai/ffmperative，为了优化我们的代理使用视频处理工具。 但我们想探索更小的架构（少于 10 亿个参数）可以更狭窄地专门用于工具使用（包括大的上下文窗口），从而消除在 GPU 上运行的需要。 因此，我们热衷于尝试仅使用数十或数百个微型法学硕士来训练使用 Andrej Karpathy “baby llama2” 处理数百万个参数，而不是数十亿个参数。这些模型在 CPU 上运行速度相当快，我们很高兴能分享构建精益本地代理以协助视频制作工作流程的初步结果。 更多详细信息请参阅我们的 YouTube 视频 此处。 训练详细信息： 架构：1500 万个参数 提高学习率：1e-3更长的上下文窗口：1024步数：100,000时间：4天硬件：1 Titan RTX 24GB VRAM 初步结果：&lt; /h1&gt; 超过 100,000 步，训练从 10 稳步进展到  0.1 损失。使用诸如“我想将‘video.mp4’从 3 秒修剪到 8 秒”这样的简单提示，该模型建议工具的使用时间约为 20%。我们认为这表明该模型可以识别视频编辑工作流程，但需要更多的训练+更多的样本+更多的数据。 后续步骤： 我们正在准备训练一个稍大的模型（约 2600 万个参数）。我们还计划通过更多的输入变化和更多的训练样本来使我们的数据集多样化，包括来自 APIBench。自从我们开始训练以来，新的更新允许您从检查点恢复训练，因此我们将使用原始存储库&lt;中的tinystories数据集进行预训练/a&gt;. 您是否会尝试添加其他可供工具使用的数据集来扩展数据集？  TLDR： FFMPerative是一个通过聊天编辑视频的oss工具。我们正在培训轻量级微型法学硕士以供本地代理工具使用，到目前为止，它显示出了希望，很快就会有更多更新。   由   提交 /u/remyxai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15lv80n/making_microllms_use_tools/</guid>
      <pubDate>Tue, 08 Aug 2023 21:36:05 GMT</pubDate>
    </item>
    </channel>
</rss>