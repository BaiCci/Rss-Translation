<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：GPT3</title>
    <link>https://www.reddit.com/r/GPT3/new</link>
    <description>AI 文本生成技术的 Reddit 子版块</description>
    <lastBuildDate>Fri, 25 Aug 2023 06:20:25 GMT</lastBuildDate>
    <item>
      <title>Code Llama 简介：人工智能驱动编码的新时代</title>
      <link>https://www.reddit.com/r/GPT3/comments/160nnjj/introducing_code_llama_a_new_era_of_aidriven/</link>
      <description><![CDATA[      Meta 推出了 Code Llama，这是一种最先进的大型语言模型 (LLM)正如他们的博客所报道的那样，它可以根据文本提示生成代码。这个革命性的工具将改变开发人员的工作方式，使他们的工作流程更加高效，并降低编码新手的进入门槛。 如果您想掌握人工智能和人工智能领域的最新趋势和见解，技术人员，先看这里。 https://i.redd.it/b6frbowge6kb1.gif 为什么会这样重要的是：  Code Llama 是一个游戏规则改变者：它是 Llama 2 的代码专用版本，能够生成代码和关于代码的自然语言来自代码和自然语言提示。它支持 Python、C++、Java、PHP、Typescript (Javascript)、C# 和 Bash 等流行语言。 它免费用于研究和商业用途：Meta 相信开放性人工智能开发的方法。通过在与 Llama 2 相同的社区许可下发布 Code Llama，他们鼓励创新和负责任的使用。  性能胜于雄辩： &lt; ul&gt; 三种尺寸，满足不同需求： Code Llama 具有三种尺寸：7B、13B 和 34B 参数。每个模型都使用 500B 代码令牌和代码相关数据进行训练。 7B 和 13B 型号还具有中间填充 (FIM) 功能，允许它们将代码插入到现有代码中。 34B 模型提供最佳结果，而较小的模型速度更快，更适合需要低延迟的任务。 更长的输入序列解锁新的用例： Code Llama 模型提供稳定的性能具有多达 100,000 个上下文标记的世代。此功能有利于生成更长的程序，并有助于在更大的代码库中调试场景。 它优于其他模型：在基准测试中，Code Llama 优于其他最新模型art 开放代码任务解决方案。它在 HumanEval 上得分为 53.7%，在 MBPP 上得分为 56.2%，与 ChatGPT 持平。  Code Llama 实际应用：   将人工智能引入编码社区：Code Llama 旨在支持跨部门的软件工程师，包括研究、工业和开源项目。您可以在此处查看 Github 存储库。 可用的专用版本： Meta 有还发布了 Code Llama 的两个附加变体：Code Llama-Python（针对 Python 代码进行了进一步微调）和 Code Llama-Instruct（针对理解自然语言指令进行了微调）。  &lt; p&gt;附注如果您喜欢这种分析，您一定会喜欢我们的免费新闻通讯 -在这里查看。 （来源）   由   提交 /u/AIsupercharged   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/160nnjj/introducing_code_llama_a_new_era_of_aidriven/</guid>
      <pubDate>Fri, 25 Aug 2023 03:28:45 GMT</pubDate>
    </item>
    <item>
      <title>搜索文本嵌入数据库的存储库</title>
      <link>https://www.reddit.com/r/GPT3/comments/16070hb/searching_for_repository_of_textembedded_database/</link>
      <description><![CDATA[是否有嵌入式数据库存储库？例如，有人使用嵌入 - ada - 002 或其他大型开源嵌入模型（例如，instructor/XL？）嵌入了整个维基百科。  我正在开发一个增强检索应用程序（当它很复杂时将开源），但我在 openai 调用上花费了大量时间来生成嵌入式数据集，以测试我的多代理检索策略。另外，不幸的是，我无法访问足够强大的硬件来以合理的速度使用本地嵌入模型。  是否有一些空间可以共享生成的嵌入？ 提前致谢！！！    ;由   提交/u/Natural_Speaker7954   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16070hb/searching_for_repository_of_textembedded_database/</guid>
      <pubDate>Thu, 24 Aug 2023 16:39:06 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何更高级/ activley 更新的项目，例如 ChartAI</title>
      <link>https://www.reddit.com/r/GPT3/comments/1604p7s/is_there_any_more_advanced_activley_updated/</link>
      <description><![CDATA[我正在寻找与此类似的工具https:// github.com/thongekchakrit/ChartAI 使用自然语言和人工智能来查询表格数据，但是我提供的这个已经有一段时间没有更新了，并且缺少一些功能。我知道没有什么可以得到 AutoGPT 的支持，但是有人知道解决方案吗？   由   提交 /u/AUTOGPTtheboss   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1604p7s/is_there_any_more_advanced_activley_updated/</guid>
      <pubDate>Thu, 24 Aug 2023 15:13:43 GMT</pubDate>
    </item>
    <item>
      <title>我创建了 GPT Pilot - 一个用于开发工具的 PoC，它从头开始编写完全工作的应用程序（大规模工作的 GPT 工程师/smol 开发人员），同时开发人员监督实施 - 它像人类一样逐步创建代码和测试，调试代码、运行命令并请求反馈。</title>
      <link>https://www.reddit.com/r/GPT3/comments/1603yea/i_created_gpt_pilot_a_poc_for_a_dev_tool_that/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1603yea/i_created_gpt_pilot_a_poc_for_a_dev_tool_that/</guid>
      <pubDate>Thu, 24 Aug 2023 14:45:44 GMT</pubDate>
    </item>
    <item>
      <title>AI2 发布最大的训练语言模型开放数据集 Dolma</title>
      <link>https://www.reddit.com/r/GPT3/comments/15zr63o/ai2_releases_dolma_the_largest_open_dataset_for/</link>
      <description><![CDATA[     &lt; td&gt; 艾伦人工智能研究所 (AI2) 发布了 Dolma，这是一个新的大型文本数据集，可免费使用并开放供检查。该数据集旨在与 OpenAI 和 Meta 等公司用来训练语言模型的严密保护数据集相反。 AI2 旨在扭转这一趋势，并将用于创建语言模型的数据提供给人工智能研究社区。 如果您想掌握人工智能和机器学习的最新趋势和见解，先看这里。 https://preview.redd.it/q9cqwf5uhzjb1.png?width=2000&amp;放大器；格式= png&amp;auto=webp&amp;s=16a4f1e9ab36f2a21e9a1506e84a0b640ff2f9c2 为什么这很重要：  人工智能研究的透明度：&lt; /strong&gt; 发布 Dolma 的目的是通过公开记录用于创建数据集的来源和过程来提高人工智能研究的透明度。 道德问题： 有猜测称一些公司可能没有以道德或合法的方式获取他们的数据。 AI2 希望通过开放并免费使用 Dolma 来解决这些问题。 鼓励审查和改进：通过将 Dolma 提供给人工智能研究社区，AI2 希望鼓励审查以及数据集的改进。  卓玛是用于训练语言模型的最大开放数据集：  3万亿代币： Dolma 是最大的用于训练语言模型的开放数据集，拥有 3 万亿个代币。 直接使用和权限： Dolma 使用“ImpACT 许可证用于中型风险工件”，要求用户提供联系信息，披露任何卓玛衍生作品，在同一许可下分发这些衍生品，并同意不在各种禁区应用卓玛。  &lt; strong&gt;可以通过Hugging Face访问卓玛：  如果您对使用卓玛感兴趣， 您可以通过 Hugging Face 访问它。 对于那些关心个人数据的人，有一份删除请求表适用于特定情况。  P.S.如果您喜欢这种分析，我会写免费时事通讯&lt; /a&gt; 追踪生成人工智能技术的最大问题和影响。每个工作日都会发送一次，让您在 3 分钟内了解最新动态！ （来源）   由   提交 /u/AIsupercharged   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15zr63o/ai2_releases_dolma_the_largest_open_dataset_for/</guid>
      <pubDate>Thu, 24 Aug 2023 04:17:28 GMT</pubDate>
    </item>
    <item>
      <title>搜索基本分块 - 嵌入示例</title>
      <link>https://www.reddit.com/r/GPT3/comments/15zd62a/searching_for_basic_chunking_embedding_example/</link>
      <description><![CDATA[大家好。  也许这是一个愚蠢的问题，但我仍在学习，请不要嘲笑我。  如果有人拥有（或可以分享类似/资源）一个Python代码的基本示例，该示例可以获取文本、分割文本、嵌入文本、存储文本并根据查询进行调用，我将非常感激，那不用LangChain？  预先感谢您的各种答复。   由   提交/u/Natural_Speaker7954   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15zd62a/searching_for_basic_chunking_embedding_example/</guid>
      <pubDate>Wed, 23 Aug 2023 19:02:52 GMT</pubDate>
    </item>
    <item>
      <title>这家伙怎么把事情搞砸了</title>
      <link>https://www.reddit.com/r/GPT3/comments/15z9asm/how_does_this_mfer_even_screw_this_up/</link>
      <description><![CDATA[        由   提交 /u/M3rcury404   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15z9asm/how_does_this_mfer_even_screw_this_up/</guid>
      <pubDate>Wed, 23 Aug 2023 16:46:00 GMT</pubDate>
    </item>
    <item>
      <title>定制知识库</title>
      <link>https://www.reddit.com/r/GPT3/comments/15z3fl4/custom_knowledge_base/</link>
      <description><![CDATA[我是一名学术学生，即将完成我的学位。当然，目前我正在研究我的论文结论。我正在寻找替代的 LLM 解决方案，我可以在其中上传多个引用我的作品的 PDF 文件。我正在寻找一种可靠的模型，它可以同时搜索所有文件中的信息，并且能够帮助我使用这些参考文献编写高质量的科学文本。我没有编码知识，所以我正在 GitHub 上寻找一些解决方案。是否有可能执行提议的任务？如果是这样，最好的选择是什么？    由   提交/u/eduardo_cbo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15z3fl4/custom_knowledge_base/</guid>
      <pubDate>Wed, 23 Aug 2023 13:07:34 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 启动 GPT-3.5 Turbo 微调</title>
      <link>https://www.reddit.com/r/GPT3/comments/15ywog9/openai_launches_finetuning_for_gpt35_turbo/</link>
      <description><![CDATA[      OpenAI刚刚宣布一项新功能：对GPT-3.5 Turbo（GPT-3.5的轻量级版本）进行微调。这意味着用户现在可以携带自己的数据并训练模型，以便在特定任务和领域中表现更好。 如果您想掌握人工智能和技术的最新趋势和见解，先看这里。 https://preview.redd.it /qzj8610obtjb1.jpg?width=862&amp;format=pjpg&amp;auto=webp&amp;s=fc84493354838543e3d52306d809ebae83f4cd5b 为什么这很重要：  &lt; li&gt;微调为创建定制且可靠的人工智能解决方案开辟了新的可能性。用户可以通过向模型提供相关数据和指令来提高模型的准确性、一致性和风格。  微调还可以降低成本和延迟。用户可以通过将指令嵌入模型本身来缩短文本提示，从而加快 API 调用速度并降低使用费用。 微调可以帮助用户克服 GPT-3.5 Turbo 的一些限制。虽然 GPT-3.5 Turbo 比 GPT-4 更快、更便宜，但它的功能和数据源也较少。微调可以帮助缩小差距并提高模型的性能。  微调的工作原理：  用户需要准备自己的数据并上传到OpenAI的API。数据可以是任何格式，例如文本、图像或音频，只要兼容GPT-3.5 Turbo的输入和输出即可 用户需要通过 OpenAI 的 API 创建微调作业。该作业指定根据用户数据训练模型的参数和设置。 &lt; li&gt;用户需要等待微调工作完成。时间取决于数据和模型的大小和复杂性。 OpenAI 表示，典型的 100,000 个 token（约 75,000 个单词）数据的微调工作成本约为 2.40 美元，大约需要一个小时。 用户可以通过 OpenAI 的 API 使用微调后的模型. 微调后的模型可通过分配给用户的唯一端点进行访问。  P.S.如果您喜欢这种分析，您会喜欢免费时事通讯我每个工作日都会撰写关于生成人工智能技术的最新趋势和影响的文章。   由   提交 /u/AIsupercharged   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15ywog9/openai_launches_finetuning_for_gpt35_turbo/</guid>
      <pubDate>Wed, 23 Aug 2023 07:36:38 GMT</pubDate>
    </item>
    <item>
      <title>Meta的新AI模型可以翻译和转录100种语言</title>
      <link>https://www.reddit.com/r/GPT3/comments/15yw51k/metas_new_ai_model_can_translate_and_transcribe/</link>
      <description><![CDATA[      Meta 宣布 SeamlessM4T，这是一种开源人工智能模型，可以翻译和转录近 100 种语言的文本和语音。该模型是将翻译和转录结合到一个系统中的最雄心勃勃的努力之一。 如果您想掌握人工智能和技术的最新趋势和见解，先看这里。 https://preview.redd.it/74u14hr57tjb1.png?width= 900&amp;format=png&amp;auto=webp&amp;s=007d5a8a9406174c66abb42d5e80c2057460029e 为什么这很重要：  Meta 想要创建一个能够理解世界语言的通用系统。SeamlessM4T 可以执行诸如将语音转录为文本、翻译文本、从文本生成语音以及将语音翻译为语音等任务。这可以帮助说不同语言的人交流和访问信息。 Meta 使用大量数据来训练其模型。该公司抓取了公开可用的文本（按顺序排列）来自网络的“数百亿”句子）和语音（400 万小时）来创建 SeamlessAlign，这是 SeamlessM4T 的训练数据集。该数据集包含文本和语音之间的对齐以及语音到语音的对齐，这些对齐可教会模型如何跨语言映射声音和含义。 Meta 声称其模型优于当前的模型语音转录领域最先进的技术。根据内部基准测试，SeamlessM4T 在语音转文本任务中针对背景噪声和“说话人变化”的表现比其他模型更好。 Meta 表示，这是因为训练数据集中语音和文本数据的丰富组合，这使得 SeamlessM4T 比纯语音和纯文本模型具有优势。  但是，该模型存在一些挑战和局限性：  SeamlessM4T 在某些翻译中显示出性别偏见和毒性。在最近的一篇文章中，Meta 透露该模型“从中性术语翻译时过度概括为男性形式”，并且在从大多数语言的男性参考翻译时表现更好。此外，在某些语言中，例如孟加拉语和吉尔吉斯语，SeamlessM4T 会做出有关社会经济地位和文化的有毒翻译。 SeamlessM4T 不适合长篇翻译和认证翻译。 Meta建议不要使用 SeamlessM4T 翻译需要当局官方认可的大型文档或文本。由于存在误译和责任风险，Meta 也不鼓励将 SeamlessM4T 用于医疗或法律目的。 SeamlessM4T 可能会失去翻译的丰富性和多样性。一些专家认为 AI翻译人员可以减少人类口译员做出的翻译选择的多样性。人工智能系统可能会生成更“准确”的翻译，但这些翻译可能会以牺牲翻译创造力和细微差别为代价。  P.S.如果您喜欢这种分析，您会喜欢免费时事通讯 我每个工作日都会撰写有关生成式 AI 技术的最新趋势和影响的文章。   由   提交 /u/AIsupercharged   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15yw51k/metas_new_ai_model_can_translate_and_transcribe/</guid>
      <pubDate>Wed, 23 Aug 2023 07:06:27 GMT</pubDate>
    </item>
    <item>
      <title>借助新的 GPT-3.5 Turbo 微调功能，是否可以要求 GPT 输出仅关注或基于输入（微调）文件的答案？</title>
      <link>https://www.reddit.com/r/GPT3/comments/15yra3m/with_the_new_gpt35_turbo_fine_tuning_feature_is/</link>
      <description><![CDATA[大家好，通过新的 GPT-3.5 Turbo 微调功能，是否可以让 GPT 输出只关注或基于上传的输入（微调）文件，而不是任何其他数据，例如 GPT 训练所依据的截至 2021 年的数据？ 我有一个输入（微调）文件，其中包含更准确的数据，但我不知道不希望来自任何其他数据源的数据污染此输入（微调）文件中的数据。 非常感谢对此的任何输入！ &lt;!-- SC_ON - -&gt;  由   提交 /u/--leockl--   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15yra3m/with_the_new_gpt35_turbo_fine_tuning_feature_is/</guid>
      <pubDate>Wed, 23 Aug 2023 02:58:19 GMT</pubDate>
    </item>
    <item>
      <title>与 Bing AI 交谈</title>
      <link>https://www.reddit.com/r/GPT3/comments/15ylte1/talking_to_bing_ai/</link>
      <description><![CDATA[      这是su吗？   由   提交/u/dontfeedthebirdspls   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15ylte1/talking_to_bing_ai/</guid>
      <pubDate>Tue, 22 Aug 2023 23:05:27 GMT</pubDate>
    </item>
    <item>
      <title>用于您自己的 SaaS 产品的 OpenCopilot AI Copilot,下载OpenCopilot AI Copilot的源码_GitHub_酷徒适合所有人的开源人工智能助手。</title>
      <link>https://www.reddit.com/r/GPT3/comments/15xxgdo/github_openchataiopencopilot_ai_copilot_for_your/</link>
      <description><![CDATA[   /u/gharbat   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15xxgdo/github_openchataiopencopilot_ai_copilot_for_your/</guid>
      <pubDate>Tue, 22 Aug 2023 06:44:59 GMT</pubDate>
    </item>
    <item>
      <title>GPT-3 不成为操作系统是一件好事吗？</title>
      <link>https://www.reddit.com/r/GPT3/comments/15xthnl/is_gpt3_not_being_os_a_good_thing/</link>
      <description><![CDATA[只是想知道你们对这个问题的看法。它不开源是一件好事吗？或者说这是一件坏事。嘿，我很好奇你的答案。 另外，如果我不问的话，我至少不会知道这个问题的答案。   由   提交/u/jackyboyman13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15xthnl/is_gpt3_not_being_os_a_good_thing/</guid>
      <pubDate>Tue, 22 Aug 2023 03:26:58 GMT</pubDate>
    </item>
    <item>
      <title>Langchain：2 分钟解释</title>
      <link>https://www.reddit.com/r/GPT3/comments/15xj90d/langchain_explained_in_2_minutes/</link>
      <description><![CDATA[没有库存图片/视频、没有 gif 和华而不实的文本。只有纯粹的技术深入探讨。 这是关于 Langchain 的最快但深入的解释视频，Langchain 是一个日益流行的框架。  https://www.youtube.com/watch?v=C9bE8bHcJVI 使用 Langchain 是创建和测试基于 LLM 的高级 AI 应用程序的最快方法之一。看看吧！   由   提交/u/ComplianceRise569   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15xj90d/langchain_explained_in_2_minutes/</guid>
      <pubDate>Mon, 21 Aug 2023 20:35:03 GMT</pubDate>
    </item>
    </channel>
</rss>