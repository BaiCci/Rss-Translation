<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：GPT3</title>
    <link>https://www.reddit.com/r/GPT3/new</link>
    <description>AI 文本生成技术的 Reddit 子版块</description>
    <lastBuildDate>Sun, 23 Jul 2023 06:20:49 GMT</lastBuildDate>
    <item>
      <title>OpenAI会因为其客户而禁止SaaS吗？</title>
      <link>https://www.reddit.com/r/GPT3/comments/15708vf/will_openai_ban_saas_due_to_its_clients/</link>
      <description><![CDATA[例如，我的 SaaS 为用户翻译或创建文本。如果用户将不道德的请求注入到我的包装提示中怎么办 - OpenAI 有一天会禁止我的整个 acc 吗？   由   提交 /u/Beginning-Engine1149   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/15708vf/will_openai_ban_saas_due_to_its_clients/</guid>
      <pubDate>Sun, 23 Jul 2023 00:37:12 GMT</pubDate>
    </item>
    <item>
      <title>白宫称亚马逊、谷歌、Meta、微软同意人工智能保障措施</title>
      <link>https://www.reddit.com/r/GPT3/comments/156zpzh/white_house_says_amazon_google_meta_microsoft/</link>
      <description><![CDATA[美国政府最近宣布，它已与大型人工智能公司达成协议，围绕该技术设置更多防护措施，其中包括开发水印系统，以帮助用户识别由人工智能生成的内容人工智能系统。这是监管人工智能的努力的一部分，以防止虚假新闻的传播以及快速发展的技术带来的其他风险。 白宫表示，7家主要人工智能公司还自愿承诺开发测试系统，以在向公众发布之前规范人工智能的安全和能力。这些公司包括：  亚马逊 谷歌 Meta 微软 OpenAI Anthropic Inflection  随着越来越多的机构熟悉这项技术的广泛采用和力量，更需要号召采取行动来监管这项技术。其中许多公司都发布了关于如何努力确保其系统道德标准的声明，但目前尚未制定正式准则。  OpenAI 表示，它与外部专家一起测试了 GPT-4，这些专家试图刺激 GPT-4 生成有害或种族主义内容，然后将其向公众发布。 OpenAI 还在 4 月份推出了一项错误赏金计划，以奖励发现公司系统漏洞的安全研究人员。 Anthropic在学术论文中讨论其安全测试方法，并为用户提供标记有问题的响应的方法。 谷歌今年春天表示，它将在其人工智能模型创建的图像中嵌入数据，以表明它们是合成的。  如果您喜欢此类新闻报道，并希望了解人工智能和技术的最新新闻，请考虑注册 免费新闻通讯（链接）。   由   提交/u/nerdninja08  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/156zpzh/white_house_says_amazon_google_meta_microsoft/</guid>
      <pubDate>Sun, 23 Jul 2023 00:13:24 GMT</pubDate>
    </item>
    <item>
      <title>格莱美奖将允许人工智能“辅助”歌曲获得未来的格莱美提名</title>
      <link>https://www.reddit.com/r/GPT3/comments/156p4jp/the_grammys_will_allow_ai_assisted_songs_for/</link>
      <description><![CDATA[今天， 录音学院首席执行官确认了允许人工智能辅助音乐获得 2024 年格莱美提名的决定。即使在人工智能抢走工作方面好莱坞也面临着这样的麻烦。 原因是什么？ 格莱美希望保持技术领先，但这可能会适得其反。 格莱美更新允许人工智能协作的规则：  部分由人工智能工具贡献的歌曲现在有资格获得提名，但纯粹由人工智能创作的音乐仍然不符合资格。 人类创造力必须在任何提交的创作过程中发挥实质性和有意义的作用。 录音学院正在探索检测合格歌曲中人工智能工具使用情况的方法。  对人工智能采用的行业强烈反对的回应：  其他娱乐联盟，如 SAG-AFTRA ，对人工智能和自动化影响的担忧表示担忧。 但格莱美奖相信，如果使用得当，人工智能可以在增强人类创造力方面发挥作用。 公平的补偿仍然需要对人工智能的使用进行适当的归因和批准。  关于人工智能在音乐中的地位的持续争论：  格莱美奖表示，他们将逐年监测人工智能合作对音乐的影响。 他们对未来调整提名规则持开放态度如果人工智能的参与被证明存在问题。 目前，重点仍然是庆祝人类创造力、原创性和表达方面的卓越表现。  TL;DR 尽管好莱坞对人工智能发起了攻击，格莱美奖仍将允许人工智能辅助的歌曲有资格获得 2024 年提名。但纯粹由人工智能创作的音乐仍然达不到资格。录音学院目前支持这一决定，但正在研究人工智能检测和监控的影响。他们的目标是平衡创新和创造性的人类表达。 附注：加入发展最快的 AI 时事通讯之一，您可以在 3 分钟内获得有关 AI 的更多知识。加入我们由来自 Open AI、Google、Meta 等的 1000 名专业人士组成的大家庭。   由   提交 /u/Ok-Feeling-1743   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/156p4jp/the_grammys_will_allow_ai_assisted_songs_for/</guid>
      <pubDate>Sat, 22 Jul 2023 16:51:34 GMT</pubDate>
    </item>
    <item>
      <title>我们似乎已经实现了窄 ASI</title>
      <link>https://www.reddit.com/r/GPT3/comments/156gswo/we_seem_to_have_already_achieved_narrow_asi/</link>
      <description><![CDATA[考虑以下内容。如果一个人能够学习并记住 GPT-3 拥有的一切，我们会认为这个人是超级智能的，至少在学习和记忆的狭窄领域内是如此。因为GPT-3已经实现了这种超​​级智能的能力，所以强大的逻辑迫使我们得出结论，它在学习和记忆的狭窄领域内实现了狭义的ASI。 我意识到人工智能界还没有意识到并接受这种理解，但科学从来没有达成共识。例如，在大爆炸理论之前就有宇宙的稳态理论。当前者被提出时，迄今为止这是少数人的观点。但这当然并不意味着它是错误的。 那么你觉得呢？如果您认为我们尚未在学习和记忆的狭隘领域实现狭义 ASI，那么您支持这一观点的论据是什么？   由   提交/u/Georgeo57  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/156gswo/we_seem_to_have_already_achieved_narrow_asi/</guid>
      <pubDate>Sat, 22 Jul 2023 10:44:41 GMT</pubDate>
    </item>
    <item>
      <title>最强大的未经审查的在线模型是什么？</title>
      <link>https://www.reddit.com/r/GPT3/comments/156blpo/whats_the_most_powerful_uncensored_online_model/</link>
      <description><![CDATA[我很好奇是否有人知道一个可以在线使用的好模型，但不像主流模型那么敏感。 我有一个基于文本的游戏的想法，灵感来自《黑镜》剧集“白色圣诞节”中引入的概念；那种受控的、动态的、自主的世界模拟，我可以随心所欲地控制它，并将自己作为一块饼干注入其中，在其中进行交互，并由我保留完全控制权。 当我尝试它时，我大多会被告知人类尊严和自由的重要性等等，而不是合作构建沉浸式游戏体验。  那么，是否有一个好的在线模型能够完成此类任务，并且不像其他模型那样敏感或受到审查？ 感谢您的宝贵时间。   由   提交 /u/Fantastic-Air8513   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/156blpo/whats_the_most_powerful_uncensored_online_model/</guid>
      <pubDate>Sat, 22 Jul 2023 05:52:05 GMT</pubDate>
    </item>
    <item>
      <title>Open AI、谷歌和微软等顶级人工智能公司向白宫承诺“人工智能安全”</title>
      <link>https://www.reddit.com/r/GPT3/comments/155y4ge/top_ai_companies_like_open_ai_google_and/</link>
      <description><![CDATA[根据白宫的说法，OpenAI、Google 和 Microsoft 等领先的人工智能公司已致力于开发“安全、可靠和透明”人工智能系统。 您认为这些大型公司真的专注于其系统的安全还是只是担心自己的资产负债表？ 联合承诺：主要行业参与者承诺确保他们的人工智能是安全可靠的。  各公司认可拜登政府提出的自愿承诺。 承诺包括测试预发布的系统和分享最佳实践。 目标是在鼓励高标准的同时最大限度地发挥人工智能的潜力。  全球框架：美国正在与盟友合作建立共同原则。  立法者提出了两党法案研究人工智能的影响。 联合国领导人已警告冲突中滥用等风险。 公私协调被视为监督的关键。  行业反应：公司表示支持协作方法。  微软表示它正在扩大其负责任的人工智能实践。 OpenAI 提到通过具体步骤来制定政策讨论。  TL;DR: 微软和谷歌等领先的人工智能公司已承诺与白宫合作，打造安全、可靠和清晰的人工智能系统。通过公共和私营部门之间的合作，美国政府希望建立一个全球框架，以负责任的方式开发人工智能。但诸如无穷尽的人工智能滥用方式之类的风险仍然是全球范围内的一个担忧。 来源：（链接） 还有一件事：通过加入其中一个快速链接，您可以在 3 分钟内获得关于人工智能的更聪明的知识加入我们的大家庭，由来自 Open AI、Google、Meta 等的 1000 名专业人士组成。   由   提交 /u/Evening_Temporary36   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/155y4ge/top_ai_companies_like_open_ai_google_and/</guid>
      <pubDate>Fri, 21 Jul 2023 19:47:55 GMT</pubDate>
    </item>
    <item>
      <title>您最常使用哪些法学硕士？</title>
      <link>https://www.reddit.com/r/GPT3/comments/155njo5/what_llms_do_you_use_the_most/</link>
      <description><![CDATA[随着新模型的出现越来越受欢迎，例如 Claude 2、Llama 2（有可能成为更好的微调模型）、Bard 的发展、围绕 ChatGPT 表现更差的争议以及现有的内容过滤器限制了模型的能力，这些模型不仅要遵守符合人类价值观的道德标准和政策，而且还限制了其他可能不属于客观道德的因素，或者可能只是过于敏感，除了 GPT-4 之外，您是否认为目前至少目前总体上最好的模型是？  我真的很想知道社区的想法，因为我进行了很多搜索，发现关于哪些模型被认为优于其他模型以及关于模型某某是“ChatGPT 杀手”的标题党式言论和标题存在很多意见冲突。考虑到所有这些信息，您实际上最常使用哪种型号？如果您能分享对此问题的看法，并感谢您抽出宝贵的时间，我将不胜感激。   由   提交 /u/Fantastic-Air8513   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/155njo5/what_llms_do_you_use_the_most/</guid>
      <pubDate>Fri, 21 Jul 2023 13:06:31 GMT</pubDate>
    </item>
    <item>
      <title>Meta、谷歌和 OpenAI 向白宫承诺，他们将负责任地开发人工智能</title>
      <link>https://www.reddit.com/r/GPT3/comments/155ipax/meta_google_and_openai_promise_the_white_house/</link>
      <description><![CDATA[顶级人工智能公司正在与白宫合作制定安全措施，旨在最大限度地减少与人工智能相关的风险。他们自愿同意加强网络安全，进行歧视研究，并建立一个标记人工智能生成内容的系统。 事情是这样的： 人工智能公司发起的倡议：领先的人工智能公司，包括亚马逊、Anthropic、谷歌、Inflection、Meta、微软和 OpenAI 已承诺采取多项举措。他们将：  投资网络安全。 进行歧视研究。 开发水印系统来指示人工智能何时生成内容。  自愿合规和实施：公司自愿同意这些条款，并且对不合规行为没有明确的处罚。然而，这些承诺的实施预计将迅速开始，尽管预计不会全部在本周五启动。 白宫的角色和计划：拜登政府正在积极努力制定行政命令，以进一步应对人工智能的风险。虽然没有提供具体细节，但预计这些行动将涵盖各个联邦机构和部门。 过去对人工智能的参与和资助：最近，政府与技术高管以及劳工和民权组织的领导人就人工智能进行了讨论。为人工智能科技公司提供了额外的资金和政策指导。例如，美国国家科学基金会拨款 1.4 亿美元，用于建立七个新的国家人工智能研究所。 来源 (TheVerge) PS: 我运行一个 人工智能驱动的新闻聚合器，总结了来自 50 多家媒体（TheVerge、TechCrunch...）的最佳科技新闻。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交/u/Rifalixa  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/155ipax/meta_google_and_openai_promise_the_white_house/</guid>
      <pubDate>Fri, 21 Jul 2023 09:15:28 GMT</pubDate>
    </item>
    <item>
      <title>中国 OpenAI 竞争对手获得资金支持</title>
      <link>https://www.reddit.com/r/GPT3/comments/155cozz/chinas_openai_competitor_gets_funding_boost/</link>
      <description><![CDATA[智浦AI是OpenAI在中国的竞争对手，已从中国外卖巨头美团获得一笔金额不详的资金，美团目前拥有该公司10%的股份。 几周前，美团以 2.34 亿美元收购了中国另一家重要的人工智能公司 Light Years Beyond。 智浦人工智能详细信息  它是从中国著名的清华大学分拆出来的，由该校教授唐杰领导。 它之前曾开源一个名为“GLM-130B”的 1300 亿参数模型。 . 它最近推出了一个名为“ChatGLM-6B”的小型开源模型，该模型是双语模型（中文和英文），声称可以在消费级 GPU 上进行推理。  美团对智浦 AI 的投资可以增强其人工智能能力，而智浦可能会受益于美团 4.5 亿用户群的访问。 如果你喜欢这样的新闻并想跟上有关人工智能和技术的最新消息，请考虑订阅免费新闻通讯（链接）。   由   提交/u/nerdninja08  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/155cozz/chinas_openai_competitor_gets_funding_boost/</guid>
      <pubDate>Fri, 21 Jul 2023 03:57:49 GMT</pubDate>
    </item>
    <item>
      <title>这些是自动化潜力最大的行业🦾</title>
      <link>https://www.reddit.com/r/GPT3/comments/155bdi1/these_are_the_industries_have_the_highest/</link>
      <description><![CDATA[       由   提交/u/JueDarvyTheCatMaster   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/155bdi1/these_are_the_industries_have_the_highest/</guid>
      <pubDate>Fri, 21 Jul 2023 02:53:06 GMT</pubDate>
    </item>
    <item>
      <title>引入 ChatGPT 自定义指令</title>
      <link>https://www.reddit.com/r/GPT3/comments/154zxcu/introducing_custom_instructions_for_chatgpt/</link>
      <description><![CDATA[       由   提交 /u/anonboxis   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/154zxcu/introducing_custom_instructions_for_chatgpt/</guid>
      <pubDate>Thu, 20 Jul 2023 19:01:25 GMT</pubDate>
    </item>
    <item>
      <title>Open AI 发布了 ChatGPT 的“自定义指令”，这里有 6 个用例</title>
      <link>https://www.reddit.com/r/GPT3/comments/154y79z/open_ai_releases_custom_instructions_for_chatgpt/</link>
      <description><![CDATA[今天，OpenAI 在测试版中引入了自定义指令功能，允许用户设置 ChatGPT 将在所有对话中记住的持久偏好设置。 要点：  ChatGPT 现在允许自定义指令来定制响应。这使用户可以设置首选项，而不是重复它们。 系统会记住接下来的所有对话的说明。避免从头开始重新启动每次聊天。  为什么 20 美元的订阅更有价值：更加个性化和定制的对话。  说明允许针对特定上下文进行首选项。就像教师的年级水平一样。 开发人员可以设置首选的代码语言。除了 Python 等默认设置之外。 购物清单可以考虑家庭份量。包含一次性说明。 测试版现已针对 Plus 用户推出。将在未来几周内向所有用户推出。  主要内容：  这将 ChatGPT 的定制提升到了新的水平。允许持续的需求和偏好。  打开AI释放了六个用例，他们到目前为止发现了它们。          专业知识校准：在特定领域中以不必要的说明进行groment conderion groment groment groment contrance conforment conforment conforment conforment conforment： 。 Strong&gt;写作样式个性化：应用与未来所有电子邮件写作请求的电子邮件相同的语音和样式。” （用例是 Open AI 的原话。）  来源：（链接）用例：(链接） 还有一件事：通过加入增长最快的 AI 时事通讯之一，您可以在 3 分钟内获得有关 AI 的更多知识。加入我们由来自 Open AI、Google、Meta 等的 1000 多名专业人士组成的大家庭。   由   提交 /u/Ok-Feeling-1743   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/154y79z/open_ai_releases_custom_instructions_for_chatgpt/</guid>
      <pubDate>Thu, 20 Jul 2023 17:58:28 GMT</pubDate>
    </item>
    <item>
      <title>我的人工智能生成的文章确信 Bing 时间立方人赢得了诺贝尔奖</title>
      <link>https://www.reddit.com/r/GPT3/comments/154w126/my_ai_generated_article_convinced_bing_the_time/</link>
      <description><![CDATA[       由   提交/u/Free-Test-5034  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/154w126/my_ai_generated_article_convinced_bing_the_time/</guid>
      <pubDate>Thu, 20 Jul 2023 16:38:23 GMT</pubDate>
    </item>
    <item>
      <title>完整的 Python Mega Bundle 具有机器学习和人工智能功能</title>
      <link>https://www.reddit.com/r/GPT3/comments/154oroq/the_complete_python_mega_bundle_features_machine/</link>
      <description><![CDATA[       由   提交/u/brand_momentum  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/154oroq/the_complete_python_mega_bundle_features_machine/</guid>
      <pubDate>Thu, 20 Jul 2023 11:51:07 GMT</pubDate>
    </item>
    <item>
      <title>研究称 ChatGPT 正在失去功能，但一些专家并不相信</title>
      <link>https://www.reddit.com/r/GPT3/comments/154l8uj/study_claims_chatgpt_is_losing_capability_but/</link>
      <description><![CDATA[      斯坦福大学和加州大学伯克利分校研究人员的一项新研究表明，OpenAI 的 GPT-3.5 和 GPT-4 模型可能会随着时间的推移而失去其功能。然而，一些专家对这些说法表示怀疑，对研究方法提出质疑，并指出人工智能开发需要提高透明度。 https://preview.redd.it/4xii6dxg13db1.png?width=1156&amp;format=png&amp;auto=webp&amp;s=05543a21dff9bd64dda2ea7e6a55be576f36381c 能力下降的说法： 研究人员 Lingjiao Chen、Matei Zaharia 和 James Zou 使用 API 访问来测试 GPT-3.5 和 GPT-4 的性能。他们的研究结果表明，GPT-4 在代码生成和数学问题解决等任务上的能力显着下降，导致他们质疑其一致性。  注意到 GPT-4 识别素数的能力显着下降。 这些发现加剧了人们对 GPT-4 性能恶化的担忧。  OpenAI 的回应和公共理论：尽管有这些发现，OpenAI 否认了这一点。 GPT-4 能力的任何下降。该组织声称每个新版本都是对其前身的改进。然而，公众提出了有关可能影响模型性能的微调和模型蒸馏工作的理论。  OpenAI 坚称 GPT-4 的能力没有故意下降。 有人提出了 OpenAI 正在蒸馏或微调模型以优化输出速度和资源使用的理论。  持怀疑态度的专家：虽然有些人认为这项研究是GPT-4 的能力不断下降，包括普林斯顿大学计算机科学教授 Arvind Narayanan 和人工智能研究员 Simon Willison 在内的其他人批评该研究缺乏确凿的证据，并质疑其方法。  批评者认为该研究未能准确评估代码生成能力。 一些人认为，感知到的变化可能仅仅是由于大型语言模型 (LLM) 的新颖性逐渐消失。  呼吁提高透明度：根据这项研究和随后的辩论，许多专家主张提高人工智能开发的透明度。他们认为 OpenAI 应该遵循传统的软件基础设施实践，为旧模型提供长期支持，并考虑采用开源模型。  人工智能开发中缺乏标准化基准是一个令人担忧的问题。 专家主张提高人工智能开发的透明度和采用开源模型。 该领域的一些人认为出于审计目的获取底层模型至关重要。  来源 (arstechnica) PS： 我运行一个 人工智能驱动的新闻聚合器，它总结了来自 50 多家媒体的最佳科技新闻（TheVerge、TechCrunch...）。如果您喜欢此分析，您一定会喜欢从此工具收到的内容！   由   提交 /u/Rifalixa   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/154l8uj/study_claims_chatgpt_is_losing_capability_but/</guid>
      <pubDate>Thu, 20 Jul 2023 08:42:35 GMT</pubDate>
    </item>
    </channel>
</rss>