<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：ChatGPT</title>
    <link>https://www.reddit.com/r/ChatGPT/new</link>
    <description>Subreddit 讨论 ChatGPT 和 AI。不隶属于 OpenAI。</description>
    <lastBuildDate>Wed, 19 Jul 2023 15:17:40 GMT</lastBuildDate>
    <item>
      <title>无法给我4个音节的单词</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153xqn6/couldnt_give_me_4_syllable_words/</link>
      <description><![CDATA[我认为这是一个简单的请求。不。   由   提交/u/OutdoorzExplorerz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153xqn6/couldnt_give_me_4_syllable_words/</guid>
      <pubDate>Wed, 19 Jul 2023 15:11:43 GMT</pubDate>
    </item>
    <item>
      <title>Meta 高管称人工智能语言模型“相当愚蠢”</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153xq1p/meta_executive_calls_ai_language_models_quite/</link>
      <description><![CDATA[Meta 全球事务总裁尼克·克莱格 (Nick Clegg) 对人工智能模型的实际智能表示怀疑，表示炒作可能超出了该技术的实际能力，正如 Meta 与 Microsoft 建立战略合作伙伴关系，开源其自己的 AI 模型 LLaMA 2 一样。 Clegg 对 AI 的看法： Nick Clegg， Meta 全球事务总裁在接受 BBC 采访时对人工智能的真正智能表示怀疑。他表示，围绕人工智能的炒作可能高估了该技术的实际能力。  克莱格特别指出人工智能语言模型，表示“在很多方面，它们相当愚蠢。”&lt; /li&gt; 克莱格的立场与人工智能无限潜力的普遍说法形成了对比。  人工智能模型的比较：  Clegg 引用了 OpenAI 的 GPT-4 和 Google 的 PaLM 2 作为人工智能模型“远远不够”的例子。自主思维水平，消除了一些专家的恐惧。  这一观点揭示了一个关键问题，即人工智能当前的局限性及其模仿人类思维过程的能力。  来源（商业内幕人士）    由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153xq1p/meta_executive_calls_ai_language_models_quite/</guid>
      <pubDate>Wed, 19 Jul 2023 15:11:06 GMT</pubDate>
    </item>
    <item>
      <title>刚花了 20 美元购买了这个订阅，问了 3 个问题，结果就达到了限制……</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153xpcs/just_bought_this_subscription_for_20_dollars/</link>
      <description><![CDATA[      甚至无法使用3.5了哈哈？在我捐钱之前情况会更好   由   提交/u/AssociationNew1543   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153xpcs/just_bought_this_subscription_for_20_dollars/</guid>
      <pubDate>Wed, 19 Jul 2023 15:10:25 GMT</pubDate>
    </item>
    <item>
      <title>研究生指责其他研究生使用 ChatGPT；然后得到 ChatGPT 的回复</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153xk1x/grad_student_calls_out_other_grad_student_for/</link>
      <description><![CDATA[      研究生使用 ChatGPT 发布讨论帖子。另一位学生在巧妙的讨论帖子回复中指出了他们的观点。被指控的学生再次使用 ChatGPT 进行回复。   由   提交 /u/NeganTWD   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153xk1x/grad_student_calls_out_other_grad_student_for/</guid>
      <pubDate>Wed, 19 Jul 2023 15:04:53 GMT</pubDate>
    </item>
    <item>
      <title>研究：GPT-4 随着时间的推移会变得更糟吗？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153xitw/study_is_gpt4_getting_worse_over_time/</link>
      <description><![CDATA[   /u/vadhavaniyafaijan   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153xitw/study_is_gpt4_getting_worse_over_time/</guid>
      <pubDate>Wed, 19 Jul 2023 15:03:39 GMT</pubDate>
    </item>
    <item>
      <title>chatGPT 变得更笨了吗？ ——对斯坦福论文的回应</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153xee8/has_chatgpt_gotten_dumber_a_response_to_the/</link>
      <description><![CDATA[正在制作的斯坦福论文今天的查房是粗制滥造的工作，不应该被认真对待。就我个人而言，我认为应该撤回该论文，然后以适当的方法重新发布。鉴于普遍的公众情绪，ChatGPT 出现某种形式的质量下降的说法可能是有道理的。但这篇论文不是证明这一点。 最令人震惊的例子是代码执行测试，在该测试中，如果研究人员输出除代码以外的任何内容（包括行业标准），GPT 就会失败。代码片段降价所需的非常理想的三引号：  “三月份，GPT-4 和 GPT-3.5 都遵循用户指令（“仅代码”），从而产生了直接可执行文件一代。然而，在 6 月份，他们在代码片段前后添加了额外的三引号，导致代码无法执行。 &quot;  GPT 可能已经过微调，始终包含 Markdown 标记，以便 WebUI 可以正确呈现代码片段，最终用户更容易解析，并且可以与其他应用程序一起使用，例如Slack 和 Stackoverflow。  研究人员上传了他们的数据，所以让我们打开引擎盖并使用他们自己的指标正确测试结果。  代码测试数据保存在此处，可以轻松弹出到数据框中。：github  我让 GPT-4 编写了一些简单的解析和评估代码（请参阅最后我仓促的 Python 笔记本），结果如下： &lt; thead&gt;  型号 ％可执行文件    openaichat/gpt-3.5-turbo-0301 1.00   openaichat/gpt-3.5-turbo-0613 0.98   openaichat/gpt-4-0314 0.82   openaichat/gpt-4-0613 1.00 &lt; /tr&gt;  6 月 GPT-4 代码的 100% 可执行，GPT-3.5 代码的 98% 可执行。  正确组合的方法将分析这些答案的性能，但不幸的是，我不是在写研究论文，也没有时间进行此分析。我怀疑如果我们这样做了，我们可能会找到研究人员最初寻找的证据。 这是我用来执行此测试的代码： com/Bradybry/GPT_Behavior&quot;&gt;github 如此糟糕的论文来自如此受人尊敬的机构，真是令人尴尬。   由   提交 /u/ertgbnm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153xee8/has_chatgpt_gotten_dumber_a_response_to_the/</guid>
      <pubDate>Wed, 19 Jul 2023 14:59:21 GMT</pubDate>
    </item>
    <item>
      <title>聊天gpt比赛就在这里</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153xaw3/chat_gpt_competition_is_here/</link>
      <description><![CDATA[人工智能爱好者朋友们看看这个https://youtu.be /E-WOR6jfBLo   由   提交/u/SJR-1938  /u/SJR-1938  reddit.com/r/ChatGPT/comments/153xaw3/chat_gpt_competition_is_here/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153xaw3/chat_gpt_competition_is_here/</guid>
      <pubDate>Wed, 19 Jul 2023 14:55:34 GMT</pubDate>
    </item>
    <item>
      <title>Gizmodo 所有者将继续发布人工智能生成的文章</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153x72a/gizmodo_owner_will_keep_publishing_aigenerated/</link>
      <description><![CDATA[Gizmodo 和其他数字媒体的所有者，尽管最初出现强烈反对和充满错误的首次亮相，但仍坚定地致力于增加人工智能生成内容的制作。这一决定引起了内部员工的不满和对自动化内容可靠性的质疑。 Gizmodo 的人工智能实验： Gizmodo 尝试了人工智能生成的文章，但结果没有达到预期。  一篇关于《星球大战》的人工智能撰写的文章已发表，但其中包含许多不准确之处。 Gizmodo 自己强调了这些错误 尽管进行了一些更正，但仍然存在许多错误，损害了内容的整体质量和可信度。  员工反应： 人工智能在内容制作中的实施让 Gizmodo 的员工感到不安。  这个决定很突然，在人工智能文章上线前不久就通知了员工。 员工对自己的工作保障、品牌信誉和公司整体诚信表示担忧。 他们认为人工智能的持续发展对他们的士气和工作环境产生了负面影响。  &lt; p&gt;管理层的立场和未来计划： 尽管最初的负面反应和员工不满，Gizmodo 的管理层仍然决心在内容制作中使用人工智能。  &lt; li&gt;计划在 Gizmodo 平台上发布更多人工智能撰写的文章。 管理层承认人工智能目前的局限性，强调人工编辑对于事实准确性仍然是必要的。 首席执行官Jim Spanfeller 甚至建议其他媒体机构应该探索人工智能，并表示不这样做是不负责任的。  来源（未来主义）   由   提交 /u/Rifalixa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153x72a/gizmodo_owner_will_keep_publishing_aigenerated/</guid>
      <pubDate>Wed, 19 Jul 2023 14:51:28 GMT</pubDate>
    </item>
    <item>
      <title>为什么我觉得ike chatGPT被微软收购了，以便他可以传播他的意识形态？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153x667/why_do_i_feel_ike_chatgpt_was_bought_by_microsoft/</link>
      <description><![CDATA[是我疯了还是你们也有同感？ Gate 购买这个 AI 后，GPT 的准确性迅速下降. chatGPT 做得很好，但现在每次我搜索一些与哲学、政治、国家相关的东西时，现在感觉比以前不那么中立了！ 我必须访问吟游诗人寻求答案。 我认为他购买 chatGPT 只是因为他知道选举即将到来。 很难过看到门已成为看门人   由   提交 /u/Gazwa_e_Nunnu_Chamdi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153x667/why_do_i_feel_ike_chatgpt_was_bought_by_microsoft/</guid>
      <pubDate>Wed, 19 Jul 2023 14:50:34 GMT</pubDate>
    </item>
    <item>
      <title>是否可以让聊天gpt不响应？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153wy64/is_it_possible_to_make_chat_gpt_not_respond/</link>
      <description><![CDATA[       由   提交/u/Any_Society3360  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153wy64/is_it_possible_to_make_chat_gpt_not_respond/</guid>
      <pubDate>Wed, 19 Jul 2023 14:41:59 GMT</pubDate>
    </item>
    <item>
      <title>巴德满嘴谎言。</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153wwhv/bard_lied_through_his_teeth/</link>
      <description><![CDATA[       由   提交 /u/paripassu_in   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153wwhv/bard_lied_through_his_teeth/</guid>
      <pubDate>Wed, 19 Jul 2023 14:40:22 GMT</pubDate>
    </item>
    <item>
      <title>学习机会</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153wv9o/learning_opportunities/</link>
      <description><![CDATA[您好， 我的公司提供学费报销，并允许员工获得他们选择的任何证书和学位。我有兴趣了解更多有关法学硕士和这项技术的信息。  我并不是在寻求职业转变（对我的工作感到满意并在接下来的几个月内完成我的硕士学位），但我很好奇这个社区是否会为想要学习的人推荐任何课程有关此技术的更多信息？   由   提交/u/Reddevil44  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153wv9o/learning_opportunities/</guid>
      <pubDate>Wed, 19 Jul 2023 14:39:01 GMT</pubDate>
    </item>
    <item>
      <title>使用人工智能搜索整个互联网来查找特定于音乐的推荐，相对于... - 你训练它的内容！ - 这就是音乐策展的未来发展方向吗？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153wusa/using_an_ai_to_search_the_entire_internet_to_find/</link>
      <description><![CDATA[想听听您的想法吗？我看到未来 3-4 年音乐行业将会发生重大变化 https://youtu.be/16oCh3oFcfw   由   提交 /u/One-Bridge-8663   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153wusa/using_an_ai_to_search_the_entire_internet_to_find/</guid>
      <pubDate>Wed, 19 Jul 2023 14:38:31 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士很奇怪：现在计算机如何写出比我写的更好的文章</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153wgag/llms_are_weird_how_computers_now_write_articles/</link>
      <description><![CDATA[我家里有一台旧打字机。这是 20 世纪 50 年代的古董，里面装满了生锈的钥匙和干涸的墨水。它曾经是我祖父的，当他去世后，它就成了我的了。事实上，这是我记者身份的象征。但是，镇上有一个新来的孩子，这些大型语言模型（LLM），他们让我质疑一切。清算的一天可能已经到来，不是一群红眼睛发光的机器人，而是一个可以写出比我更好的文章的语言模型。由 OpenAI 训练的人工智能（GPT-4）让我的内裤变得扭曲。  ​ 现在，您可能会问自己，LLM到底是什么？嗯，显然正是这个超级复杂的计算机程序学会了理解和生成人类语言。据称，它基于深度学习模型，无论这意味着什么，都可以回答问题、撰写论文、总结文本、翻译语言，甚至生成诗歌、脚本和故事。它甚至经过训练可以生成电子邮件回复，帮助过度劳累的专业人士休息一下。  ​ 亲爱的读者，问题在于它不仅仅停留在电子邮件上。它走得更远，更远。这些模型可以撰写报纸文章、报告，您猜对了，就是您现在正在阅读的这篇文章。人与机器之间的界限从未如此模糊。  ​ 当我坐在电脑前，努力为这篇文章想出合适的词语时，我的编辑漫不经心地建议我尝试一下 GPT-4。我小心翼翼地输入提示符，按下回车键，然后敬畏地看着屏幕上出现的文字，它们像河流一样流动，连贯、引人入胜，而且非常人性化。让我告诉你，看到一台机器在你眼前写出一篇比你的文章更好的文章，这真是一件了不起的事情。这是一场数字化的生存危机。  ​ 但我的担忧并不止于此。不，它也渗透到我们生活的其他方面。如果法学硕士可以取代我这个经验丰富的记者，那么什么阻止它取代教师、医生甚至我们的老板呢？别让我开始谈恋爱。你能想象你的另一半被机器取代吗？没有温暖的触摸，没有跳动的心脏，只有一个冷酷、精于算计的人工智能。它让我脊背发凉。  ​ 我们准备好了吗？这就是我们想要的未来吗？人工智能如此巧妙地融入我们的生活，模糊了人类与机器之间的界限？我不禁感到一阵恐惧。我热爱我的工作，但被机器取代的前景令人不安。我的意思是，我无法与人工智能竞争。怎么会有人呢？  ​ 这就像这些法学硕士已经被交给了王国的钥匙。他们正在阅读我们的书籍，研究我们的文本，并反映我们的语言。他们正在成为更好的我们，甚至不再是人类。伙计们，恐惧是真实的。恐惧是真实的。  ​ 当然，还有硬币的另一面。有些人将这些发展预示着新时代的黎明，人工智能将接管苦差事，人类最终将有时间享受生活中更美好的事物。他们谈论一个机器和人共存的乌托邦，创造一个充满前所未有的生产力和和谐的世界。但我想知道，代价是什么？  ​ 所以，当我坐在这里，手指悬停在键盘上时，我发现自己正处于十字路口。一方面，我看到了技术的奇迹，看到了法学硕士可以实现的奇迹。另一方面，我看到了人性的潜在丧失，人与机器之间的界限正在消失。  ​ 谁知道未来会怎样？也许法学硕士是因祸得福。或许，它们是一个时代的预兆，在这个时代，人类只是伟大机器中的另一个场景。不管怎样，很明显这些法学硕士将继续存在，而我本人既着迷又害怕。  ​ 当我退出时，我想知道，我会被法学硕士取代吗？明天我还有工作吗？或者我会成为这场无情的进步中的另一个牺牲品吗？只有时间会给出答案。现在，只有我、我的想法和我的旧打字机无声的嗡嗡声。   由   提交/u/eivan_danko  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153wgag/llms_are_weird_how_computers_now_write_articles/</guid>
      <pubDate>Wed, 19 Jul 2023 14:22:45 GMT</pubDate>
    </item>
    <item>
      <title>微软和 OpenAI 测试合成数据来训练法学硕士，因为网络数据“不再足够好”</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/153wfxk/microsoft_and_openai_test_synthetic_data_to_train/</link>
      <description><![CDATA[人工智能模型需要越来越独特和复杂的数据集来提高其性能，但主要法学硕士背后的开发人员发现网络数据“不再好”够了”并且变得“极其昂贵” 英国《金融时报》的一份报告（注：付费）揭示了这一点。  因此，OpenAI、微软和 Cohere 都在积极探索使用合成数据来节省成本并生成干净、高质量的数据。 为什么这很重要：   主要的法学硕士创建者相信他们已经达到了人造数据提高性能的极限。性能的下一个巨大飞跃可能不仅仅来自于喂养模型更多的网络抓取数据。 定制的人工创建的数据非常昂贵，而且不是可扩展的解决方案。让各个领域的专家创建额外的详细内容在训练人工智能所需的数据量。 网络数据越来越受到锁定和密钥，因为 Reddit、Twitter 等网站为了使用其数据而收取高额费用。   方法是让 AI 生成自己的训练数据：  Cohere 让两个 AI 模型发挥作用作为导师和学生生成合成数据。此时所有内容均由人工审核。 微软的研究团队已经表明，某些合成数据可用于有效地训练较小的模型，但通过合成来提高 GPT-4 性能仍然不可行。  像 Scale.ai 和 Gretel.ai 这样的初创公司 已经在提供合成数据即服务，这表明市场对此有兴趣。  人工智能领导者在说什么？他们决心探索这个未来。  Sam Altman 在 5 月份解释说，他“非常有信心很快所有数据都将成为合成数据” 这可以帮助 OpenAI 回避欧盟的隐私问题。他认为，通往超级智能的途径是通过模型自学。 LLM 初创公司 Cohere 的首席执行官艾丹·戈麦斯 (Aidan Gomez) 认为网络数据并不伟大：“网络是如此嘈杂且混乱，它不能真正代表您想要的数据。网络并不能满足我们所需的一切。”  一些人工智能研究人员敦促谨慎行事：来自牛津和剑桥的研究人员最近发现训练人工智能基于自己的原始输出的模型可能会产生“不可逆转的缺陷”随着时间的推移，这些模型中的内容可能会破坏和降低其性能。 主要结论：人造内容被用来开发第一代法学硕士。但我们现在正在进入一个令人着迷的世界，在未来十年中，人类创建的内容可能会变得真正罕见，世界上大部分数据和内容都是由人工智能创建的。  P.S.如果您喜欢这种分析，我会写免费时事通讯来追踪生成人工智能技术的最大问题和影响。它每周发送一次，帮助您及时了解早晨喝咖啡的时间。 ​ &lt;!-- SC_ON - -&gt;  由   提交 /u/ShotgunProxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/153wfxk/microsoft_and_openai_test_synthetic_data_to_train/</guid>
      <pubDate>Wed, 19 Jul 2023 14:22:22 GMT</pubDate>
    </item>
    </channel>
</rss>